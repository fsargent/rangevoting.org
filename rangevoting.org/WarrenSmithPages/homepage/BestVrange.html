<html>
<head>
<link rel="stylesheet" href="/assets/css/original-layout.css">

<title>
RangeVoting.org - Best Rank-Order-Ballot voting systems versus Range Voting
</title>
</head>
<body style="font-family: Arial, sans-serif">

<a name="sec1"></a>
<h1>
The Best Rank-Order Voting System versus Range Voting 
</h1>
<p>
By Warren D. Smith.  Email comments to: warren.wds AT gmail.com.
</p>
<p>
Draft#1: 20 June 2008. 
Draft#2: 31 July 2008.
Draft#3: 21 August 2008. 
Draft#4 (essentially final): 25 Sept. 2008. 
Draft#5: 26 Sept.
Declaring it final 27 January 2009.
<!-- Uh... max derivative for any curve from any matrix pair??? Best v Worst?
Monster formulas, #candidates remarks -- need to update.
-->
</p>

<h3>Abstract</h3>
<p>
I contend the only correct
objective mathematical way to measure
the "quality" of a voting system is "Bayesian Regret" (BR).
Contrary to common mythology about Arrow's Impossibility Theorem,
"best" voting systems can exist under this metric.
This paper 
<ol>
<li>
Evaluates the BRs of several voting systems (including
Borda, plurality, antiplurality, approval, and range voting) in
a mildly-realistic probabilistic setting,
the "random normal elections model" (RNEM),
in closed form.
</li><li>
Identifies the best rank-order voting system.  
In the 3-candidate case it is Borda voting. With &ge;4 candidates it is new.
</li><li>
Proves that both "approval voting" and "range voting" 
equal or better the best rank-order voting system,
for both honest and strategic voters (or any mixture) in 3-candidate RNEM elections.
For range voting this superiority is strict.
</li><li>
Identifies the best voting system based on ratings-type ballots 
in 3-candidate RNEM elections with honest voters.
This new system has the same vote-scores as range voting to within 7.5%
but differs from hence is even better than range voting.  However, it
only is better if over &asymp;91% of the voters are honest.  
For that and other reasons we do not 
recommend it over plain range voting.
</li></ol>
Range voting is: each voter awards a real score in [-1, 1] to
each candidate, and the one with greatest average score wins.
Although the paper is long, there is a concise summary 
<a href="#BigResultsTable">table</a> and 
<a href="#RegPlot">plot</a>
in sections 7 and 8 respectively.  There also is a 
<a href="#AppD">glossary</a>.
</p>

<h3>Longer Abstract</h3>
<p>
Ken Arrow's <i>impossibility theorem</i>
(1956) misled political science into a bad direction for half a century.
It is commonly claimed that Arrow "showed that no 'best' voting system could exist" 
and
then genuflections are made toward Arrow's Nobel Prize in Economics and the matter 
is considered closed.
<blockquote>
<small><b>Example:</b>
Paul Samuelson wrote in 1972: "What Kenneth Arrow proved once and for all is that there cannot 
possibly be found such an ideal voting scheme: The search of the great minds of recorded 
history for the perfect democracy; it turns out, is the search for a chimera, for a 
logical self-contradiction."
<br><br>
This quote is simply
invalid because as worded it refers to all voting schemes, not just
the subclass Arrow's theorem pertained to. 
Further, we need to distinguish between "ideal" and "best."
If by "ideal" we mean "meeting impossible conditions" then there is no
ideal voting scheme. However, there could still be a "best" one.
Bayesian Regret (BR) offers an objective way to try to
measure voting system quality and  produces a true ordering of
all voting methods by quality.   There then exist best (or co-best) voting
methods.
Samuelson and Arrow were unaware of BR.
Arrow unfortunately has explicitly rejected the use of "utilities" in economics (even in quotes 
published as late as 2008) and led a harmful fixation on rank-order voting methods.
The "properties" based approach which Arrow pushed, leads to
a random-like directed network of contradictory preference relations
among voting methods, <i>not</i> an ordering by quality.  
</small>
</blockquote>
But this claim is false.
Arrow actually showed that single-winner voting systems based on <i>rank-order ballots</i> 
must have at least one of three bad-seeming properties.
He showed nothing about voting
systems <i>not</i> based on rank-order ballots.
Also, Bayesian statistics offers a framework  ("Bayesian Regret" <a href="#BayRegDefn">BR</a>)
within which  the "goodness" of any single-winner voting system can be 
objectively defined and measured to arbitrary accuracy,
and in which best voting systems <i>can</i> exist.
<p><p>
In the present paper, for the first time, the BRs of several voting systems are evaluated,
in a simplistic &ndash;
but reasonable and oft-used &ndash;
probabilistic setting, in closed form.  (In some cases, we merely prove a closed form exists
and show how to write it down, but actually 
only express the result in a less-expanded form because some of the closed forms are
very long.)
The <i>best</i> voting system based on rank-order ballots is <i>explicitly found</i> in this setting.
It then is shown that <i>range voting</i> (RV) is superior to that best rank-order system
in 3-candidate elections with <i>either</i> honest or strategic voters (or any mixture).
Range voting, a.k.a. score voting, is: each voter awards a real score in [-1, +1] to
each candidate, and the one with greatest average score wins.
This almost-utterly destroys the relevance of Arrow's theorem.  (Arrow was about
a class of voting systems every member of which is known to be strictly worse than RV.
It is approximately as relevant, therefore, as a theorem about hitchhiking on snails as a means
of transportation; the common wrong-interpretations of Arrow's 
results are entirely unforgivable;
and political scientists' collective fixation on rank-order voting methods is a 
100-year-long mistake.)
</p><p>
We also are able to explicitly find the best voting system 
(in 3-candidate elections with honest voters)
based on <i>ratings</i>-ballots (such as those employed by RV).  This best-rating-based
voting system is approximately (the scores are the same to "within 7.5%")
the same as 
RV but  <i>not</i> the same as it, hence is even "better."
However for practical reasons (e.g. voters are not necessarily honest, our
underlying probabilistic setting does not perfectly match reality,  real elections
have a variable number of candidates,
and the best system is a good deal
more complicated and morally-dubious-sounding than RV) range voting probably still is
a better choice.  We indeed show that this new 3-candidate system degenerates in the presence of 
<i>strategic</i> voters to become equivalent to strategic plurality voting, whereas
range voting degenerates to approval voting, causing range voting to be superior to
the "better" system if the fraction of honest voters is below about 91%.
</p><p>
Our results do not exclude the possibility that some unknown voting system based
on something other than rank-order and ratings-type ballots, could exist that is superior
(measured by Bayesian Regret) to all the systems we have mentioned.
</p><p>
The author's 8-year-old computerized measurements of BR already had indicated RV
outperformed all the commonly-proposed (at that time) voting systems &ndash; and in a far wider
class of probabilistic settings than we are capable of analysing in this paper.  But the 
computer could only measure BR for <i>already-invented</i> voting systems.  The present paper
shows RV's superiority over <i>every</I> rank-order-based voting system.
</p><p>
This is the first in a planned 3-paper sequence.
<a href="Best4.html">Part II</a>
will handle more-than-3 candidates under the RNEM.
<a href="BestVot2.html">Part III</a>
will examine other underlying models, different from the RNEM, e.g.
"issue-based politics."
</p>


<a name="Sec0"></a>
<h3>0. Plan/Overview (and a little motivation)
</h3>

<p>
<a href="#AppD">Appendix D</a>
 is a "glossary" of terminology we employ and provides background knowledge.
The reader will want to understand everything in it before beginning.
In <a href="#Sec1">section 1</a>, 
we explain the underlying idea enabling us to identify best voting systems.
<nobr><a href="#Sec2">Section 2</a></nobr>
then defines the "random normal elections model" (RNEM) &ndash; the
setting for most of our results &ndash; and proves some initial results.
The overarching Bayesian Regret and best-voting-systems 
frameworks in no way depend on the RNEM and in principle apply in <i>any</i> probabilistic setting,
work for either honest or strategic voters, in the presence of voter "ignorance," etc etc.
However, the RNEM has the advantage of being 
clearly defined and simple and hence
highly reproducible, mildly realistic,
and the "impartial culture" special case of it
was previously
used by many political-science authors.
It is simple enough to allow us to evaluate many quantities in closed form.
Nobody has evaluated those quantities before in any setting; it is important to do so;
and hence we shall focus on the RNEM in this paper.
</p><p>
In 
<a href="#Sec">section 3</a>, 
as a warm up and paper-in-microcosm, we compute the Bayesian regret of
(honest) 2-candidate plurality voting in closed form; and <a href="#Sec4">section 4</a>
does both strategic N-candidate 
plurality voting and (undemocratic) "random winner" and "worst winner" elections.
<a href="#Sec5">Section 5</a> 
then explains a highly general <a href="#ProcReg">procedure</a>,
the "correlation-based method," for
computing Bayesian regrets of many kinds of voting systems in the
limit V&rarr;&infin;
of a large number of voters.   
If carried all the way through to the bitter end, this procedure will yield 
closed formulas, involving 
<A href="#AppC">Schl&auml;fli functions</a>, for the regrets.
However, it also is possible to do less. Specifically, certain symbolic integrations can be replaced by
numerical integrations carried out by, e.g. Monte-Carlo methods.  In that case, the procedure returns
approximate numerical answers instead of exact closed formulas (and the approximation may be made 
arbitrarily good by running the computer longer).
It also states the important underlying 
<a href="#GaussCorrLemma">Gaussian correlation lemma</a>.
Subsections then begin running that procedure by 
computing the "correlations" for many kinds of voting systems in closed form.
One surprising counterintuitive
finding (<a href="#Thm10">theorem 10</a>) is that weighted positional systems
have the <i>same</i> Bayesian regrets as their "reversals," for example
plurality and antiPlurality voting have asymptotic Bayesian regrets (for V honest voters in
the V&rarr;&infin; limit; but for finite V the two regrets will differ).
<a href="#Sec6">Section 6</a>
then finds the <i>best</i> rank-order-based and ratings-based voting systems
(in the random normal elections model when  V&rarr;&infin;) and computes their 
correlations.
The best rank-order system is Borda if there are &le;3 candidates, but (for honest voters)
it is superior to Borda in N-candidate elections whenever N&ge;4.
</p><p>
The next step of the procedure, which we embark on in <a href="#Sec7">section 7</a>, is to use
the correlations to compute Bayesian Regrets.
Doing so yields so-called "Schl&auml;fli functions" which may be evaluated either
by numerical integration or (in low-enough dimensions) analytically.
We shall see that analytic closed forms exist for the RNEM Bayesian Regrets of every voting
system considered in this paper whenever the number of candidates is at most 3.
(For numbers exceeding 3, we have closed forms in some cases but in others are forced to resort
to numerical integration; indeed 
closed forms <a href="#Sec82">also</a> are available for 4 candidates if we accept "trilogs."
But unfortunately even in the 3- and 4-candidate cases
the closed formulas often are so immense
that we still employ approximate numerical methods even though this is in principle avoidable;
see <a href="#FormLen">discussion</a> of "formula length" in section 3 of appendix C.)
We shall do so to at least 5-decimal accuracy for all regrets 
whenever the number of candidates is at most 3;
the big <a href="#BigResultsTable">table 2</a> 
in section 7 states the answers.
One astonishing finding from table 2 was that
(with honest voters in 3-candidate RNEM elections)  approval voting
and Borda voting have <i>exactly the same</I> BR values (and also exactly the same
"wrong-winner probabilities") to at least 5 significant figures!
A proof was then sought, and eventually found as <a href="#Thm14">theorem 14</a>.
</p><p>
<a href="#Sec8">Section 8</a>
then discusses how to handle honest+strategic voter <i>mixtures</i> (or, in principle,
arbitrary multicomponent mixtures).
From the result that 3-candidate approval and Borda have the same BR for honest voters,
plus the fact approval has lower BR for strategic voters, one would guess that approval
"therefore" must be superior to Borda for any honest+strategic voter mixture
(excluding 100% honest)
in 3-candidate RNEM elections.  And since honest range voting is superior (i.e. lower BR)
to them both while with strategic voters range becomes equivalent to approval voting, 
one would guess that range 
"therefore" must be superior to both approval and Borda for any
voter mixture (excluding 100% strategic).
We verify these guesses by numerical work,
i.e. we simply 
<a href="#RegPlot">plot</a> 
BR versus mixture composition and verify one curve lies above the other.
A sufficiently determined reader could
use our closed formulae, a computer, and available automated methods for 
"rigorous global minimum finding" 
to convert this numerical finding into a <i>fully rigorous proof</i> that
range is superior to the best rank-order voting method (i.e. Borda), as well as
to approval voting, at every mixture composition.
The proof would simply be the plots we just mentioned but adorned with
"bells and whistles":
specifically the use of "interval arithmetic" to evaluate all numbers with rigorous
upper and lower bounds throughout the intervals between the plot points.
It is slightly trickier in cases where the two curves actually touch at
their endpoints (this issue fortunately does not arise for the most important case,
range versus Borda); then also the 
<i>derivatives</i> as well as the functions need to be plotted.
</p><p>
I admittedly have not actually carried out these final tedious mechanical computations to
rigorously verify the final decimal places,
but have drawn the plots to high accuracy.
I think that ought to be good enough
for political science readers.
<!--, and an argument,
titled "lazy man's interval arithmetic,"
is offered 
that the computation we went through to compute these plots actually is good enough
to be regarded as a "probabilistic proof" with very tiny failure probabability.  UPDATE???
-->
</p><p>
<a href="#Sec9">Section 9</a>
concludes by discussing some issues readers have asked about such as
"why Bayesianism?" and "what about more than 3 candidates?"
asking some open questions, and suggesting some future work.
</p><p>
A seperate follow-up paper ("<a href="Best4.html">part III</a>") shall 
attempt to break free of the limitations of the RNEM and/or of the kind
of voter "strategy" considered in this paper, by now considering some
other models.
</p><p>
In principle the mathematics in this paper is elementary, i.e. can be understood
by midlevel undergraduate math majors (except perhaps for the Schl&auml;fli-function material
sketched in <a href="#AppC">appendix C</a>), and the underlying ideas are simple.
The entire paper can be regarded (if you are so inclined) as merely evaluating some integrals.
However, unfortunately, there are a lot of integrals, and they mostly are multidimensional
and difficult. 
2008-era automated symbolic manipulation systems are usually incapable of doing them
without a great deal of human assistance.
We therefore provide several long appendices to help.
</p><p>
<a href="#AppA">Appendix A</a> discusses "normal order statistics."
That is, given N independent standard normal deviates, what is the behavior
(especially its expectation value G<sub>K</sub><sup>(N)</sup>) of the <i>K</i>th-largest?
This can be regarded
as a certain multidimensional integration problem.
It also, of course, is a problem in probability and statistics, and it has been 
studied for about 100 years.
We explain the theory of this kind of integral, 
provide literature references,
and provide tables of the
G<sub>K</sub><sup>(N)</sup>.  They are known in closed form whenever N&le;5, and
we go further by showing that closed forms also must exist
when N&le;9 (although neither I nor anybody else has ever done the large
computation required to work them out when N=8,9; and when I did it for N=6,7 I got
formulas each about 4 pages long, which seems too long to be useful).
The asymptotics are also known; and we again go further by pointing out how,
in principle, arbitrarily many terms of "asymptotic series" could be worked out.
</p><p>
<a href="#AppB">Appendix B</a> provides a table of about 100 specific definite integrals and 
outlines procedures for evaluating every integral of their ilks in closed form.
<!--
(Probably many of these integrals are new, but I've made no effort to decide which.)
-->
</p><p>
<a href="#AppC">Appendix C</a> discusses Schl&auml;fli and related functions.
These again can be regarded merely as a
specific class of  multidimensional integration problems.
But because these integrals happen to have <i>geometrical meaning</i> (measures and moments of
"nonEuclidean simplices") there is a large and beautiful theory of them dating back to 
Ludwig Schl&auml;fli in
the mid-1800s (and even before).
We do not have room to explain that entire theory &ndash; that would require 
at least an entire book
(at least two are available, but both are out of date) 
&ndash; but we at least explain the basics of
the situation, provide literature references, and extend that theory to handle 
the "moment problems" encountered here and to rewrite the key results
of that theory in a sensible notation (which, incidentally, is a considerable contribution since
no good notation had been used previously).   As part of the effort to write and check
<a href="#AppC">appendix C</a>, we wrote the first 
<a href="SchlafliProgram">computer program</a> for exact evaluation of 
these functions up through S<sub>5</sub>(X).  This appendix currently is the best 
source of information
(beyond the information
available in books) available about Schl&auml;fli functions.
</p><p>
Finally, <a href="#AppD">appendix D</a>
defines terminology (such as "Bayesian Regret," "Borda,"
"Strategic Voting," and "Approval Voting")
and provides background.   There are several lists of literature references at
the end of certain sections (because the literature happened to  split up
conveniently into disjoint lists) &ndash; including <i>this</i> section.
</p>
<h3>0.1. A Little Motivation and Background</h3>
<p>
It is quite likely crucial for the survival
of civilization that we make good collective decisions.
"Voting systems" are collective decision-making methods.
"Bayesian Regret" (BR) is the correct way (and, I claim, the <i>only</i>
correct way) to measure "good."
With this tool we can (and I already did in previous works) attempt to show
that democracy is better than certain non-democratic types of government
(and quantify by how much), and to measure the relative goodness of various
kinds of voting system.  Unfortunately, as essentially every student of this area already
knows and agrees, the currently most-used voting system,
"plurality voting," is quite bad.  
A far-superior system is "range voting," and computerized
BR measurements done by me during 1999-2000 showed empirically that it
was extremely-robustly superior
to all commonly proposed rival single-winner voting systems.
The size of RV's superiority and its robustness were both comparable to
plurality-based democracy's superiority versus the nondemocratic "random winner" system.
</p><p>
The <i>name</i> "range voting" was coined
by the author in 1999-2000 (albeit more recently advocates have preferred "score voting").
However, this kind of voting
was not invented by me.   Indeed, I realized in 2006 that <i>honeybees</I>
and at least one species of <i>ants</i> have been using a procedure mathematically
equivalent to range voting to make certain important collective decisions,
and this has been going on for millions of years and hundreds of trillions of elections.
The Ancient Spartans also employed 
range voting as the basis of the (arguably) 
longest-lasting substantially-democratic government in world history.
<!--Most political scientists today are, unfortunately, unaware of all that.-->
</p><p>
"Bayesian Regret" also was not invented by me (the concepts date back to 
Daniel Bernoulli, Thomas Bayes, and Jeremy Bentham in the 1700s), and
while I <i>did</i> invent the idea of applying BR to comparing voting systems,
this was only a rediscovery since at least two others (Samuel Merrill and
Robert F. Bordley) had already independently published essentially the same idea.
All three of us did BR-based computerized comparative studies of voting systems,
but since Merrill and Bordley did not include range voting among their
"contestants," they found inconclusive results.   My (much larger) study in 1999-2000
was the first to include range voting and found it very robustly superior to all the
other systems in the study ("robustly" with respect to changing modelling
assumptions and parameters, that is).  My old election-simulation/BR-measuring
program has been publicly
available as source code ever since &ndash; and a new program called "IEVS" is now
also available on the Center for Range Voting web page
and undergoing continual development.
(Jan Kok and I co-founded the CRV in 2005 after he realized that, non-obviously, range 
voting could be used on <i>every</i> voting machine in the world capable
of handling multiple plurality races &ndash; zero modification or reprogramming required &ndash;
while I saw that the USA's <i>party primaries</I> would provide a setting in which
all major power-players would be <i>motivated</i> out of self-interest to adopt RV.)
Several other investigators in the meantime have also run their own (unpublished)
computerized studies, confirming my 1999-2000 results.
I also pointed out in the 1999-2000 work that range voting evaded "Arrow's impossibility theorem."
This elementary observation continues to be rediscovered by various people all the time,
and apparently was
first published by Economics Nobelist John C. Harsanyi almost immediately after Arrow
in the mid-1950s.  But unfortunately most economists ignored and/or were unaware of that.
</p><p>
But from the standpoint of a mathematician, it was unappetizing that these old results
on the "superiority" of range voting 
</p>
<ol type="a">
<li>
Depended on computer simulations,
</li><li>
Were only in comparison to a fixed finite set of (perhaps rather crude and ad hoc) rival voting systems
proposed by various political scientists and hobbyists over the decades.
</li>
</ol>
<p>
In 2007
I was able to prove (and Forest W. Simmons proved a simpler and weaker similar result
almost immediately after I did it) that range voting was both "clone proof"
and immune to "favorite betrayal" whereas it was <i>impossible</i> for
<i>any</i> rank-order-ballot-based voting system to achieve both those desiderata.
(See <a href="#AppD">appendix D</a> for these desiderata, and see my 2007 paper for the precise
statement and proof of the theorem.)
Some interesting axiomatic characterizations of range voting
were also proven by myself, 
and by Dhillon &amp; Mertens, both in 1999.
These results, while mathematically more pleasant,
unfortunately were about "properties" rather than the superior
"Bayesian Regret" measure.
</p><p>
The present paper fills that gap.
<!--, in what is, in my (admittedly biased) opinion, 
one of the most important developments in voting theory in the last 200 years.-->
We are able to <i>prove</i> the superiority
of range voting over <i>every</i> rank-order voting method under the RNEM
for either honest or strategic (or any mixture) voters in the (&le;3)-candidate case;
do everything in the correct
(Bayesian Regret) framework; evaluate BRs in closed form in terms of fundamental
mathematical constants like &pi;;
and we are able to identify best voting systems explicitly.
None of these were ever accomplished before;
and furthermore much conventional wisdom &ndash;
unfortunately based on a substantial
community being misled by Arrow's theorem for 50+ years &ndash;
is overthrown.
</p>

<blockquote>
<b>References for introduction:</b>
<br>
Robert F. Bordley: A pragmatic method for evaluating election schemes through simulation, 
Amer. Polit. Sci. Rev. 77 (1983) 123-141.
<br><br>
Amrita Dhillon &amp; J-F. Mertens: Relative Utilitarianism,
Econometrica 67,3 (May 1999) 471-498.
<br><br>
Samuel Merrill: Making multicandidate elections more democratic, Princeton Univ. Press 1988.
<br><br>
Papers by Warren D. Smith are available online here
<a href="http://www.math.temple.edu/~wds/homepage/works.html">
http://www.math.temple.edu/~wds/homepage/works.html</a>
including
<i>Range Voting</i> (#56, 2000),
<i>Ants, Bees, and Computers agree Range Voting is best single-winner system</i> (#96, 2006),
and 
<i>Range Voting satisfies properties that no rank-order system can</i> (#98, 2007).
<br><br>
The Center for Range Voting website
(<a href="../../index.html">http://rangevoting.org</a> &amp;
<a href="http://scorevoting.net">http://scorevoting.net</a>,
written by myself with numerous
other authors contributing)
is currently one of the best sources of information on the internet about 
voting methods and especially range voting.  For example, the subpage
<a href="../../RVstrat.pdf">http://rangevoting.org/RVstrat.pdf</a>
gives an axiomatic characterization of range voting,
the subpage
<a href="../../ArrowThm.html">http://rangevoting.org/ArrowThm.html</a>
is about Arrow's impossibility theorem, 
<a href="../../PuzzlePage.html">http://rangevoting.org/PuzzlePage.html</a>
gives over 100 math+democracy-related puzzles (with answers),
<a href="../../UtilFoundns.html">http://rangevoting.org/UtilFoundns.html</a>
tells you about utility theory,
<a href="../../BayRegDum.html">http://rangevoting.org/BayRegDum.html</a>
about Bayesian Regret,
<a href="../../PuzzCondProb.html">http://rangevoting.org/PuzzCondProb.html</a>
derives exact and asymptotic formulae for the probability a "Condorcet winner" exists under
the RNEM,
and so on.
This website has over 800 subpages and a search engine.
</blockquote>

<a name="Sec1"></a>
<h3>1. The germ of the idea
</h3>
<p>
Using <a href="#BayRegDefn">Bayesian Regret</a> methodology, one can via computer election
simulations show (subject to modeling assumptions,
which can be varied, and subject to numerical error, which can 
be made arbitrarily small by using better random number generators and running 
the computer longer) that range voting is a better
single-winner voting method than certain other methods &ndash;
including all the most common proposals.
["Better" measured by Bayesian Regret.]
</p><p>
Fine.  But that does not prove range is superior to <i>every</i> voting
system;  it only proves it is better than some small set of the ones
we programmed and tested.  And indeed, some other voting system might be
superior to range voting.
</p><p>
We now explain a new approach which would enable a computer-aided proof
(or disproof) that range is superior to <i>every</I> rank-order voting
system &ndash; whether anybody previously invented it, or not.
</p><p>
Program your election simulator for range and rank-order voting
systems as usual, with your favorite variable utility-generators,
voter-strategy generator, etc.
Run it on a zillion elections.
</p><p>
Now here is the new twist:
make a giant table <i>remembering</i>, for every election situation, the
expected utility of each candidate.  After enough data builds up,
by the "<a href="#ProbBackgnd">strong law</a> 
of large numbers" this table's entries will become reliable.
("Election situation" means the number of each kind of rank-order
vote, which for an N-candidate election is N! numbers.)
</p><p>
Then the <i>best</i> rank-order voting system is this:
look up the N! vote-totals in the giant table, find out which
candidate has the best expected utility (over all historical
simulated experience whenever that election situation came up),
and enthrone him.  (Note, this is true <i>whatever</i> the 
"historical simulated experience" probability distribution is.
The best voting system will be distribution-dependent, but
we here are imagining fixing some one distribution.)
</p><p>
Now we can compare the best rank-order system versus
range voting to find out which has
smaller regret. 
You also can examine the best rank-order
system to try to see what
it is &ndash; Condorcet? Something new? What?
</p><p>
Now because the giant table is going to be too large, this
computer experiment would only seem feasible in 3-candidate
elections &ndash; perhaps 4-candidate if very clever "data compression"
is used to store the table.
</p><p>
Because table entries will never be 100% reliable, the best rank-order
voting system will never be completely found,  but we will be able to
estimate, using statistics, a high-confidence upper bound how far off
we are; and we might be able to identify a much more human-friendly
definition of what the best system is.
</p>

<h3>1.1. The idea proper </h3>
<p>
The preceding explained how one could compare range voting versus
the <i>best</i> rank-order voting system (and identify that system) &ndash; 
in principle.
</p><p>
The purpose of the rest of this paper is to 
actually do it &ndash; and without need of a computer!  
Specifically, we don't need to do the difficult
computer simulations because we can figure out, using the human brain, 
what would happen if we did.  However, the theorems we shall get 
in this way, are only valid in certain particular and simple 
probability models.
</p>

<hr>

<a name="Sec2"></a>
<h3>2. The Random Normal Elections/Utilities Model (RNEM) and related models &amp; initial results
</h3>
<!--
By Warren D. Smith, 20 June 2008.
-->
<p>
<b>DEFINITION</b> of <i>RANDOM NORMAL UTILITIES (or ELECTIONS) MODEL [RNEM]:</i>
Each voter Y gets a random standard normal variate as her utility for 
the election of candidate X (and this happens independently for all
candidate-voter XY pairs).   The centers of the normals do not need to all be 0;
they could be voter-dependent constants.
</p><p>
<b>DEFINITION</b> of (the more general) <i>RANDOM EVEN-SYMMETRIC UTILITIES MODEL:</i>
Same thing, except in place of "standard normal variate,"
say a variate from <i>any</i> fixed even-symmetric probability density (perhaps offset
by arbitrary voter-dependent constants, i.e. the centers of symmetry do not have to be
at utility=0).
</p><p>
<b>REMARK ON TIES:</b>
In some proofs below, we shall assume that there are enough
voters that perfect-tie elections can be regarded as neglectibly uncommon.
</p>
<a name="Thm1"></a>
<p>
<b>THEOREM 1</b> <b>(3-candidate Borda uniquely optimal for honest voters):</b><br>
For 3-candidate elections with 100% honest voters in a random even-symmetric
utilities model: Borda voting is the best of all
possible rank-order-ballot voting systems ("best" meaning 
least Bayesian regret), and indeed Borda is generically <i>uniquely</i> best.
</p><p>
<b>Proof sketch:</b>
Given that an honest voter says "A>B>C," there is an conditioned-expected 
utility for her for A, for B, and for C;
call these numbers W<sub>1</sub>, W<sub>2</sub>, W<sub>3</sub>
respectively.
Then we claim the best rank-order-ballot based voting system consists of 
adding up the scores for each candidate (i.e. you get score W<sub>1</sub>
if a voter ranks you top, W<sub>2</sub> if middle, and W<sub>3</sub> if a voter ranks you last)
and the highest score wins.  That is because due to the independence
assumptions and voter- and candidate-permutation symmetries of the model, this
precisely maximizes the expected utility of the winner
(summed over all voters).  This proves the best voting system is
"weighted positional."  
Now we claim due to <i>even symmetry</i>
that W<sub>1</sub>-W<sub>2</sub> = W<sub>2</sub>-W<sub>3</sub>, 
and hence the voting system is Borda.
<b>QED.</b>
</p>
<a name="Thm2"></a>
<p>
<b>THEOREM 2</b> <b>(3-candidate Borda also optimal for strategic voters):</b><br>
For 3-candidate elections with 100% strategic voters &ndash; all of
whom rank the two frontrunners top and bottom [where two of the three
candidates get randomly chosen by <a href="#GodDefn">God</a>
at the start of the election to be
the two "frontrunners" and all voters &ndash; but <i>not</i> the voting system &ndash;
know which two they are] &ndash;
in a random even-symmetric utilities model: Borda voting is the best of 
all possible rank-order-ballot voting systems ("best" meaning 
lowest Bayesian regret).  However it is not uniquely best.
Many other systems including IRV, Condorcet, and plain 
plurality are coequally best, tied with Borda.
</p><p>
<b>Proof sketch:</b>
First note that only two strategic votes are
possible, not 6, call them wlog A>B>C and C>B>A.
Given that a strategic voter says "A>B>C"... 
there is an conditioned-expected utility for her
for A, for B, and for C, call these numbers W<sub>1</sub>, W<sub>2</sub>, W<sub>3</sub>
respectively.
Again the best rank-order-ballot based voting system consists of 
adding up the scores for each candidate (i.e. you get score W<sub>1</sub>
if a voter ranks you top, W<sub>2</sub> if middle, and W<sub>3</sub> if a voter ranks you last)
and the highest score wins.  That is because due to the independence
assumptions and the voter- and candidate-permutation symmetries of the model, this
precisely maximizes the expected utility of the winner
(summed over all voters).   Now if necessary, please refer back to section 1 outlining
the conceptual idea. Plainly B cannot be the best-expectation
winner because all three candidates have <i>independent identical</i> utility-probability 
distributions and hence the best among <i>two</i> {A,C} must generically yield
greater expectation value (historically averaged) than the best among one {B} given
that God's choice of the "non-frontrunner"
B here was random and unrelated to the utilities of A,B,C
(an assumption valid in our model).
So it must be A or C.  In that case the value of W<sub>2</sub> is irrelevant provided
2&middot;W<sub>2</sub>&le;W<sub>1</sub>+W<sub>3</sub>.  
(If 2&middot;W<sub>2</sub>=W<sub>1</sub>+W<sub>3</sub> we have Borda voting and the
B can only win in a perfect tie, which we have assumed away as negligibly unlikely.
If 2&middot;W<sub>2</sub>&gt;W<sub>1</sub>+W<sub>3</sub> then B wins with probability&rarr;100% 
in the infinite #voters limit in random even-symmetric models, so those
voting systems are suboptimal.)
And then any values of W<sub>1</sub> and W<sub>3</sub> with W<sub>1</sub>>W<sub>3</sub> work, 
it does not matter which;
they all yield the same winners, i.e. they all yield effectively equivalent
voting systems with probability&rarr;1 in the V&rarr;&infin; limit.
<b>QED.</b>
</p>
<a name="Thm3"></a>
<p>
<b>THEOREM 3</b> <b>(3-candidate Borda uniquely best for strat+honest mixtures):</b><br>
For 3-candidate elections with an arbitrary mixture of strategic and
honest voters (same strategy model as <a href="#Thm2">last</a>
theorem, but now an F-biased
coin is tossed independently for each voter to decide whether that voter is "honest"
or "strategic") in a random even-symmetric utilities model: Borda voting
is the uniquely best of all possible rank-order-ballot voting systems ("best" 
meaning lowest Bayesian regret).  [Here we assume the voting system has no way
to know which voters are "strategic" and which "honest" and must treat them all the same.
The theorem is valid for every value of F with 0&lt;F&lt;100%.]
</p><p>
<b>Proof sketch:</b>
Same methodology as above also works to prove this.
QED
</p>

<a name="Sec3"></a>
<h3>3. The Bayesian Regret of 2-candidate plurality voting </h3>

<p>
We shall see that it is possible to compute, in closed form,
the Bayesian Regret of Approval, Range, and Borda voting
for 3-candidate elections in the  RNEM &ndash;
and with fraction F strategic and 1-F honest voters, too.
However, 
the calculations involved in trying to do that seem 
enormous, making it attractive to
employ numerical integration instead of closed formulas.  (We'll discuss all that later.)
</p><p>
Therefore, I decided to retreat and first do some simpler regret calculations
all the way
to closed form.
As the first example, we compute
the Bayesian Regret of 2-candidate plurality voting.
This will be the first time the Bayesian Regret of any election method has been
computed in closed form.
Since pretty much <i>every</i> reasonable election method becomes
plurality voting  in the 2-candidate  case, this is of very great or
very little interest, 
depending on your point of view &ndash; but in any case, we shall compute it!
</p>
<p>
We begin with some useful lemmas.
</p>
<p>
<b>CORRELATION&rArr;SIGN LEMMA:</b>
If X and Y are correlated 0-mean standard normal deviates with correlation C
with |C|&lt;1,
then the probability Pr(C) that X and Y have the same sign is
<center>
Pr(C) 
&nbsp; = &nbsp;
1/2
+
arcsin(C)/&pi;.
</center>
The proof of the lemma is
<center>
Pr(C) =
&int;&int;<sub>[Cv+(1-C<sup>2</sup>)<sup>1/2</sup>w] has same sign as v</sub> P(v) P(w) dw dv
<br>
=
2&int;<sub>0&lt;v&lt;&infin;</sub>&int;<sub>-C(1-C<sup>2</sup>)<sup>-1/2</sup>v&lt;w&lt;&infin;</sub> 
P(v) P(w) dv dw
= 
1/2
+
&theta;/&pi;
= 
1/2
+
arcsin(C)/&pi;
<!--
P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);     
PC := 2 * int( int( P(v) * P(w) , w= -Q*v..infinity ), v = 0 .. infinity );
#find PC = 1/2 + arctan(Q)/Pi;
#C=0 ==> PC=1/2.  C=1/2 ==> PC=2/3.  C=1 ==> PC=1.
-->
</center>
<a href="assets/images/BestVotFig1.png"><img src="assets/images/BestVotFig1.png" align="right" width="20%"></a>
where 
P(x)=(2&pi;)<sup>-1/2</sup>exp(-x<sup>2</sup>/2) 
denotes the standard normal density function
and
where 
<nobr>tan(&theta;)=C(1-C<sup>2</sup>)<sup>-1/2</sup></nobr>
so that 
sin(&theta;)=C. 
[See also the next proof for a different
viewing angle on the same sort of technique,
and see the figure. The region of integration is one of the two wedges shown,
which is the reason for the factor of 2 in front.]
<b>QED.</b>
</p>
<p>
<b>CORRELATION&rArr;REGRET LEMMA:</b>
If X and U are correlated 0-mean standard normal deviates with correlation C
with |C|&lt;1,
then the expected "regret" got by taking U&middot;signX instead of |U|
(i.e the expected value of |U|-U&middot;signX)
is
<center>
BR = (2/&pi;)<sup>1/2</sup>(1-C).
<!-- sanity checks:
C=0: returns  int( P(x) * abs(x), x = -infinity .. infinity  ); = sqrt(2/pi)
C=1: return 0
-->
</center>
Proof:
The regret is zero if signU=signX.
We therefore need to integrate 2|U| over the entire XU plane
(weighted by the appropriate probability density)
except that the integrand is replaced by 0 where 
signU=signX.
We have
<center>
BR 
=
4
&int;<sub>0&lt;U&lt;&infin;</sub>
&int;<sub>-&infin;&lt;W&lt;-C(1-C<sup>2</sup>)<sup>-1/2</sup>U</sub> 
U P(U) P(W) dU dW
=
(2/&pi;)<sup>1/2</sup>(1-C)
<!--
P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);       
R := 2 * int( int( u * P(u) * P(W) , W= -infinity .. -Q*u ), u = 0 .. infinity );
subs(Q = C/sqrt(1-C^2), %);
simplify(%);
#find R = (1-C)/sqrt(2*Pi)
-->
</center>
<!--where 
tan(&theta;)=C(1-C<sup>2</sup>)<sup>-1/2</sup>
so that 
sin(&theta;)=C
and
cos(&theta;)=(1-C<sup>2</sup>)<sup>1/2</sup>.
-->

The integral arises by letting
X=CU+(1-C<sup>2</sup>)<sup>1/2</sup>W
where U and W are independent standard normal deviates (this gives the correct correlation C).
The factor
4=2&middot;2
in front of the integral is there because
the region in the UW plane where the utility winner is not equal to the vote winner is
a <i>double</i> wedge but we integrate over only one of the wedges;
and the regret U-(&plusmn;U) is either 0 or 2U.
<b>QED.</b>
</p>
<p>
Using these lemmas plus the <a href="#AppA">appendix A</a>
about normal order statistics, we now
straightforwardly
compute the answers for 2-candidate plurality voting.
</p>
<a name="Thm4"></a>
<p>
<b>THEOREM 4:</b>
<b>The correlation</b>
C between &Delta;U 
(the utility difference between the two candidates)
and &Delta;V 
(the plurality-vote-count difference between the two candidates)
is, in the 2-candidate RNEM,
</p>
<center>
C 
= 
2&int;<sub>0&lt;x&lt;+&infin;</sub> x P(x) dx = (2/&pi;)<sup>1/2</sup> 
&asymp; 
0.7978845605.
</center>
<a name="Thm5"></a>
<p>
<b>THEOREM 5:</b>
<b>The probabilities of a "correct" and "wrong winner" </b>
(i.e. the probability the vote-based and 
utility-based winners are the same, or disagree, respectively)
in the 2-candidate RNEM
in the limit of large number of plurality-voters,
are respectively
</p>
<center>
1/2 + arcsin([2/&pi;]<sup>1/2</sup>)/&pi;
&asymp;
0.7940475830
&nbsp;&nbsp;
and
&nbsp;&nbsp;
1/2 - arcsin([2/&pi;]<sup>1/2</sup>)/&pi;
&asymp;
0.2059524170.
</center
<a name="Thm6"></a>
<p>
<b>THEOREM 6:</b>
<b>The expected Bayesian regret BR</b>
of plurality voting
(in the 2-candidate RNEM
in the limit of large number V of voters)
is asymptotic to
</p>
<center>
BR 
=
<!-- [1/2 - arcsin([2/&pi;]<sup>1/2</sup>)/&pi;] this factor not here -->
(V/&pi;)<sup>1/2</sup>
[1-(2/&pi;)<sup>1/2</sup>]
&asymp;
0.1140314256
V<sup>1/2</sup>. 
</center>
Notes: 
Of course correlations between X and Y are unaffected by scaling X and/or Y.
The reason for the factor of (V/2)<sup>1/2</sup> present here but not 
in the Lemma is the fact that 
<ol type="a">
<li>
the 
<i>difference</i> between two
independent standard normal deviates is a zero-mean normal  2<sup>1/2</sup> 
times wider; 
</li><li>
Unlike in the lemma, if "U" really, as in (a), means the
utility <i>difference</i> between the two candidates, then the regret is not 0 or 2U,
but rather 0 or U;
</li><li>
we also scale by V<sup>1/2</sup>
since the utility summed over all V voters is 
a normal
with V<sup>1/2</sup> times the width (and note here it is key that, in the 
RNEM,
the V voters are 
<i>independent</I>).
</li></ol>
If one wants the <i>per capita</i> regret then the scaling by V<sup>1/2</sup>
should be replaced by a scaling by V<sup>-1/2</sup>.
</p>
<a name="Thm7"></a>
<p>
<b>THEOREM 7:</b>
<b>The expected utility of the winner</b>
of plurality voting
(in the 2-candidate RNEM
in the limit of large number V of voters)
is asymptotic to
</p>
<center>
E(U<sub>plur2 win</sub>)
=
(V/&pi;)<sup>1/2</sup> 
-
(V/&pi;)<sup>1/2</sup>
[1-(2/&pi;)<sup>1/2</sup>]
=
(2<sup>1/2</sup>/&pi;)
V<sup>1/2</sup>
&asymp;
0.4501581579 V<sup>1/2</sup>.  
</center>
<p>
In contrast, the expected utility of the <i>best</i> winner
is G<sub>1</sub><sup>(2)</sup>=&pi;<sup>-1/2</sup>&asymp;0.5641895835
(see <a href="#AppA">appendix A</a>); 
the difference between these two numbers is, of course,
the Bayesian regret from 
<a href="#Thm6">theorem 6</a>.
</p>
<p>
<b>CRUDE NUMERICAL CONFIRMATION:</b>
We generated 10000 standard normal deviates (five times)
and found the correlation between them and their signs
was 0.7987&plusmn;0.0012, confirming 
<a href="#Thm4">theorem 4</a>.
Then we generated 10000 <i>pairs</i> of standard normal deviates (five times)
and found the mean pair-maximum was
0.5648&plusmn;0.0098,
confirming the value of G<sub>1</sub><sup>(2)</sup>.
</p><p>
Next we ran 10000 elections, each with V=11 voters (four times), finding 
wrong-winner probabilities
0.194&plusmn;0.004
and mean regrets
(0.102&plusmn;0.004)&radic;V.
Then we ran 10000 elections, each with V=101 voters (thrice), finding
wrong-winner probabilities
0.201&plusmn;0.004
and mean regrets
(0.108&plusmn;0.004)&radic;V.
Finally we ran 10000 elections, each with V=201 voters (thrice), finding
wrong-winner probabilities
0.209&plusmn;0.004
and mean regrets
(0.116&plusmn;0.004)&radic;V.
These confirm 
theorems
<a href="#Thm5">5</a>  &amp; <a href="#Thm6">6</a> 
while making it clear that V=11 is not large enough
for asymptopia, although (at least to within our level of statistical noise here) V=201 is.
</p>
<p>
For the regret value in
<a href="#Thm6">theorem 6</a>, see also the more-impressive
<a href="#OldMC">numerical confirmation</a> in section 7; 
that confirmed our figure to 0.23%
accuracy with 200 voters.
</p>
<!--
with(stats):
dt := 0; vx := 0; vy := 0;
do
for i from 0 to 10000 do
  x := stats[random, normald]();
  y := sign(x);
  dt := dt+x*y;
  vx := vx + x*x;
  vy := vy + y*y;
od;
print("corr=", evalf(dt/sqrt(vx*vy)));
od;
describe[meandeviation]( [0.7988118510, 0.7991208864, 0.7967651024, 0.8001771213,  0.7986564018] );
describe[mean]( [0.7988118510, 0.7991208864, 0.7967651024, 0.8001771213,  0.7986564018] );
describe[standarddeviation]( [0.7988118510, 0.7991208864, 0.7967651024, 0.8001771213,  0.7986564018] );

with(stats):
for j from 1 to 5 do
sx := 0;
for i from 1 to 10000 do
  x := max(stats[random, normald](2));
  sx := sx+x;
od;
print("meanmax=", sx/10000);
od;
describe[mean]( [ 0.5530623337, 0.5610449765 , 0.5798596199,  0.5662952076, 0.5636045278] );
describe[standarddeviation]([ 0.5530623337, 0.5610449765 , 0.5798596199,  0.5662952076, 0.5636045278] );

describe[mean]( [0.19666, 0.19256, 0.19216, 0.19836, 0.19036] );
describe[standarddeviation]( [0.19666, 0.19256, 0.19216, 0.19836, 0.19036] );
and mean regrets
describe[mean]( [0.20573, 0.20577, 0.21168, 0.21199, 0.20510] );
describe[standarddeviation]( [0.20573, 0.20577, 0.21168, 0.21199, 0.20510] );


with(stats):
do
ww := 1; rg := 0.0000000001;  zz := 1; NV := 201;
for j from 1 to 10000 do
sx := 0; sy := 0; 
for i from 1 to NV do
  qq := stats[random, normald](2);
  x := qq[1]-qq[2];  #util diff
  y := sign(x);
  sx := sx+x;
  sy := sy+y;
od;
if( sign(sx*sy) < 0 ) then
   ww := ww+1;    rg := rg+abs(sx);
fi;
if(j>zz) then
   print("#expts=", j, "wwprob=", (ww/(j+2)), "   scaledregret=", evalf(rg/j/sqrt(NV)) );
   zz := zz*2;
fi;
od;
print("NumVoters=", NV, "#expts=", j, "wwprob=", (ww/(10000+2)), evalf(ww/(10000+2)), "   scaledregret=", evalf(rg/10000/sqrt(NV)) );
od;

                                               1939
"NumVoters=", 11, "#expts=", 10001, "wwprob=", -----, 0.1938612278, "   scaledreg=0.1050273847
                                               10002

                                               934
"NumVoters=", 11, "#expts=", 10001, "wwprob=", ----, 0.1867626475, "   scaledreg=0.09824113609
                                               5001

                                               325
"NumVoters=", 11, "#expts=", 10001, "wwprob=", ----, 0.1949610078, "   scaledreg=0.1042569456
                                               1667

                                                332
"NumVoters=", 101, "#expts=", 10001, "wwprob=", ----, 0.1991601680, "   scaledreg=0.1091666355
                                                1667

                                                2027
"NumVoters=", 101, "#expts=", 10001, "wwprob=", -----, 0.2026594681, "   scaledreg=0.1074412854 
                                                10002

                                                1007
"NumVoters=", 101, "#expts=", 10001, "wwprob=", ----, 0.2013597281, "   scaledreg=0.1073715013
                                                5001

                                                687
"NumVoters=", 201, "#expts=", 10001, "wwprob=", ----, 0.2060587882, "   scaledreg=0.1108489595
                                                3334

                                                701
"NumVoters=", 201, "#expts=", 10001, "wwprob=", ----, 0.2102579484, "   scaledreg=0.1184387089
                                                3334

                                                354
"NumVoters=", 201, "#expts=", 10001, "wwprob=", ----, 0.2123575285, "   scaledreg=0.1184764869
                                                1667
-->

<a name="Sec4"></a>
<h3>4. The Bayesian Regret of N-candidate <i>strategic</i> plurality voting </h3>

<p>
We now consider <i>N</i>-candidate elections and postulate that the voters act <i>strategically</i>
as follows.  Two candidates are (randomly) named by God as the two "frontrunners."
The voters now vote for whichever of these two they prefer (acting, of course, on the theory 
that a vote for
a non-frontrunner would almost certainly be "wasted").
</p>
<a name="Thm8"></a>
<p>
<b>THEOREM 8:</b>
<b>The Bayesian Regret of strategic plurality voting</b>
in N-candidate V-voter random normal elections, in the limit V&rarr;&infin;
is asymptotically given by
<center>
BR<sub>strat plur</sub> = 
G<sub>1</sub><sup>(N)</sup>V<sup>1/2</sup> - 
E(U<sub>plur2 win</sub>)
</center>
where G<sub>1</sub><sup>(N)</sup> [tabulated in <a href="#AppA">appendix A</a>]
is the expectation of the maximum of N independent standard normal deviates
and 
<nobr>E(U<sub>plur2 win</sub>)</nobr> is given in <a href="#Thm7">theorem 7</a>.
</p>
<a name="RemAfterThm8"></a>
<p>
<b>Proof:</b>
The theorem statement is simply the difference betweenthe expected utilities of the best and 
actual winners, which is just the definition of "Bayesian Regret." <b>QED.</b>
</p>
<p>
<b>REMARK:</b>
For each N&ge;2,
Condorcet, Instant Runoff Voting (IRV), and plurality voting all have the <i>same</i>
regrets when V&rarr;&infin;
assuming voters always ("strategically") rank frontrunners top and bottom (because then
the non-frontrunner cannot win in untied elections, and ties are negligibly common in
the V&rarr;&infin; limit).
Furthermore, Borda <i>also</i>
has the same regret if
2&le;N&le;3, but Borda's regret should differ when N=4 (since its value will depend on
how the strategic voters rank the two <i>non</i>-frontrunners).
In the special case N=3 
<a href="#Thm8">theorem 8</a>
reduces to
</p>
<center>
BR<sub>3-canddt strat plur</sub> 
= 
[(3/2)&pi;<sup>-1/2</sup> - 2<sup>1/2</sup>/&pi;]
V<sup>1/2</sup>
&asymp;
0.3961262173 V<sup>1/2</sup>.
</center>
<a name="Thm9"></a>
<p>
<b>THEOREM 9:</b>
<b>The "wrong winner" probability for strategic plurality voting</b>
lies between (N-2)/N and (N-1)/N.
</p>

<h3>4.1. Regret of random- &amp; worst-winner for N-candidate RNEM elections</h3>

<p>
The "random winner" voting system (which could be claimed to model some non-democratic governments)
trivially has regret=G<sub>1</sub><sup>(N)</sup> 
in N-candidate RNEM elections (see <a hrf="#AppA">appendix A</a>), 
and elects a non-best candidate (N-1)/N of the time.
</p>

<a name="ObsSAP"></a>
<p>
<b>OBSERVATION:</b>
Strategic antiPlurality voting is equivalent to (more precisely, in the RNEM yields the same regret as)
random winner.
</p>
<p>
<b>Proof:</b>
Suppose, in antiPlurality voting, all voters act "strategically" as follows:
there are two candidates A and B randomly selected by God before the start of the election 
to be the two "frontrunners"; all voters know who A and B are; each voter votes against the 
frontrunner they dislike more.
</p><p>
In that case (in the RNEM in the infinite-voter limit) a random non-frontrunner will always win.
But since we have assumed the choice by God of who the frontrunners were, was itself random
and independent of everything else,
this is equivalent to random winner. 
<b>QED.</b>
</p>

<p>
The "worst winner" artificial voting system (useful as a benchmark)
also trivially has regret=2G<sub>1</sub><sup>(N)</sup> 
in N-candidate RNEM elections, and always elects a non-best candidate (except in the
zero-probability case where all candidates are exactly equal).
</p>

<a name="Sec5"></a>
<h3>5. The correlation-based method for computing Bayesian Regrets of voting systems
in the normal elections model when V&rarr;&infin;</h3>

<p>
We are now going to explain a <i>highly general</I> method for computing 
Bayesian Regrets.
The expected regret of a voting system in an N-candidate election with V voters 
can in general be written
as an integral over  NV-dimensional utility space, of the
summed (over voters) utility of candidate C (<i>maximized</i> over C)
minus the 
summed (over voters) utility of the <i>winning</i> candidate:
<center>
BR = &int;...&int; (U<sub>best canddt</sub> - U<sub>winner</sub>) &rho; du<sub>11</sub>...du<sub>NV</sub>
</center>
The integrand is weighted according to the probability density &rho; of that point in utility-space.
To define this we need:
</p>
<ol>
<li>
Some "voter strategic behavior model"
telling us how that voter would vote as a function of the candidate-utilities; 
</li><li>
"Voting-system rules" telling us the winner as a function of the votes;
</li><li>
A "utility model" telling us the probability density for each point in utility-space.
</li></ol>
<p>
The purpose of this section is to explain how in many voting systems
one can write the regret in the V&rarr;&infin; limit
as only a (&le;2N)-dimensional integral!
We shall need
</p>
<a name="GaussCorrLemma"></a>
<p>
<b>GAUSSIAN CORRELATION LEMMA:</b>
Let x be an m-vector of independent standard normal deviates.
Let C be an n&times;m matrix with <i>unit row norms</i>:
&sum;<sub>1&le;j&le;m</sub>(C<sub>ij</sub>)<sup>2</sup>=1.
Define the n-vector y by y=Cx.
Then each y<sub>i</sub> viewed in isolation
is normally distributed, with mean=0 and variance=1.
The correlation between y<sub>i</sub> and x<sub>j</sub>
is C<sub>ij</sub>.
The correlation between 
x<sub>i</sub> and x<sub>j</sub> is &delta;<sub>ij</sub>
(i.e. 1 if i=j, 0 otherwise).
Finally,
the correlation between 
y<sub>i</sub> and y<sub>j</sub> is 
(CC<sup>T</sup>)<sub>ij</sub>.
</p>
<a name="ProcReg"></a>
<p>
Now <b>the procedure</b> we suggest to express the scaled
Bayesian Regret V<sup>-1/2</sup>BR
as a low-dimensional integral
is:
</p>
<ol>
<li>
Compute (preferably analytically in closed form in the V&rarr;&infin; limit)
the <i>correlations</i> between each candidate's vote-total and his (and other candidates')
utility-totals.  
[Usually this is about 2N (or fewer) different numbers to compute individually.]
</li><li>
Compute (preferably analytically in closed form in the V&rarr;&infin; limit)
the correlations between the candidates' vote-totals.
[Usually only a few numbers need to be computed individually.]
</li><li>
Devise a N&times;2N constant matrix C whose lefthand N&times;N block C<sub>ij</sub>s give
the vote<sub>i</sub>utility<sub>j</sub> correlations and whose righthand N&times;N block is 
devised so
that (CC<sup>T</sup>)<sub>ij</sub>
gives the correct vote<sub>i</sub>-vote<sub>j</sub> correlations:
</p>
<center>
(CC<sup>T</sup>)<sub>ij</sub> = Correl(VoteTotal<sub>i</sub>, VoteTotal<sub>j</sub>).
</center>
<p>
It can be "devised" to be triangular by using
the <a href="#CholeskyDefn">Cholesky</a>
matrix factorization algorithm from linear algebra to find the lower
triangular matrix L with 
</p>
<center>
LL<sup>T</sup> 
&nbsp; = &nbsp;
(CC<sup>T</sup>)<sub>desired</sub>
&nbsp; - &nbsp;
(CC<sup>T</sup>)<sub>from utils from lefthand block only</sub>
</center>
<p>
then the initially-0 righthand C-block can be replaced by L.   (In some
cases where there is "rank deficiency" it is possible to use fewer  
than N extra columns, but N
always suffice.  Note also that both matrices on the right hand side are symmetric so it does
not matter whether they are transposed; and one can make the added block be either upper or
lower triangular, whichever you desire, by renumbering rows and columns.)
</li><li>
Compute the <i>variances</i> of the vote-totals; 
let D be the N&times;N diagonal matrix with
D<sub>ii</sub>=(variance of vote-total i).
[Actually, we do not need to know D; merely knowing a diagonal matrix <i>proportional</i>
to D suffices.
That trick often can save some work.]
</li><li>
We <i>assume</i> 
the voting system is such that each candidate gets some sort of personal "vote total"
and the candidate with the greatest total is elected.  In that case, the
regret is the <i>integral</i> over 2N-dimensional space
u<sub>1</sub>,
u<sub>2</sub>,
...
u<sub>2N</sub>,
<i>weighted</i> by
&prod;<sub>1&le;j&le;2N</sub>P(u<sub>j</sub>)
[where 
P(x)=(2&pi;)<sup>-1/2</sup>exp(-x<sup>2</sup>/2)
is the standard normal density function]
<i>of</i> the utility difference
<center>
&Delta;u = 
max(u<sub>1</sub>,
u<sub>2</sub>,
...
u<sub>N</sub>)
-
u<sub>winner</sub>
</center>
where the winner is k such that 
among the N vote totals, the maximum is the <i>k</i>th
(where the "N-vector of vote-totals" is, as a matrix-vector product, 
D<sup>1/2</sup>Cu).
(If this "total-based
assumption" is false then our whole procedure will not work; or in particularly nice
cases it might be possible still to make it work, but it will be trickier.)
</li><li>
Note that this integrand (before weighting)
is <i>piecewise linear</i> in
infinite convex-polytopal
regions which share the origin as a common vertex
(and this is the <i>only</i> vertex of each region).
And the weighting function is rotationally symmetric.
The "wrong-winner probability" (got by integrating 1 rather than &Delta;u to get the probability that a
candidate with non-maximal utility wins the election)
is therefore a "Schl&auml;fli function" (or finite sum thereof); and the "regret"
(got by integrating &Delta;u as described) is a Schl&auml;fli-related "pure-linear moment";
both of these are explained in <a href="#AppC">appendix C</a>.
</li></ol>
<p>
The <a href="#ProbBackgnd">central limit theorem</a>  and RNEM's independence assumptions 
cause every utility-total and vote-total to be normally distributed
in the V&rarr;&infin; limit, thus underlying the applicability of the
correlation lemma and hence the validity of this procedure.
</p>
<p>
<b>WHY the Cholesky factorization inside that <a href="#ProcReg">procedure</a> works:</b>
A real Cholesky factor L with positive diagonal entries
exists and is unique (and is found by 
Cholesky's algorithm) if the known symetric matrix M to be factored as 
M=LL<sup>T</sup> is positive-definite.
But L does <i>not</i> exist if M has a negative eigenvalue.
In the borderline case where M is merely positive <i>semi</I>definite,
L also exists by considering appropriate limiting processes which approach M 
along a path of matrices which all are positive definite.
</p><p>
<i>How do we know</i> that our M will always be positive (semi)definite?
Here is some nice <b>linear algebra</b> about that. 
<ol type="a">
<li>
One of the "Schur complement" 
identities about matrices partitioned into 4 sub-blocks is that
<pre>
    [ A B ]
det [ C D ] = det(A - BD<sup>-1</sup>C) det(D).
</pre>
where A and D are square but B and C are allowed to be rectangular.
In particular (where <tt>I</tt> is an identity matrix)
<pre>
    [ A  B ]
det [ B<sup>T</sup> I ] = det(A - BB<sup>T</sup>).
</pre>
</li><li>
The "Sylvester critierion" states that a symmetric n&times;n matrix 
is positive definite if and only if
all <i>n</i> of its trailing principal minors 
(the m&times;m submatrices with m&isin;{1,2,...,n} that are flush against the
bottom-right corner)
have positive determinants.
</li>
<li>
Warning:
It is <i>not</i> true that a symmetric matrix is nonnegative-definite iff its trailing
principal minors all have nonnegative determinant.
Ghorpade &amp; Limaye 2007 give a 2&times;2 counterexample matrix 
and demonstrate that
the correct extension of Sylvester is that nonnegative definiteness is
equivalent to <i>all</i> 2<sup>n</sup>-1 principal
minors ("trailing" or not) having nonnegative determinant.
</ol>
Combining these (and noting that principal minors in the small N&times;N matrix corresponds
to the same principal minor in the large 2N&times;2N matrix <i>except</i> that <i>all</i> the last
N rows and columns are <i>added</I>)
immediately proves
</p>
<a name="PosDefLemma"</a>
<p>
<b>LEMMA about positive definiteness:</b> The blocked matrix
<pre>
    [ A  B ]
    [ B<sup>T</sup> I ]
</pre>
is positive definite 
if and only if
A-BB<sup>T</sup> is.
Also, if the big matrix is <i>non-negative</i> definite, that implies that
A-BB<sup>T</sup> is too (but this time the implication is not bidirectional).
</p>
<p>
The joint distribution of utilities and votes is a 2N-dimensional normal distribution
with 0-mean, which is wholy described by its 2N&times;2N
correlation matrix and
2N individual variance values.
This matrix is viewable as consisting of four 
N&times;N blocks just as in the lemma, where A gives
the vote-vote correlations and B gives the vote-utility correlations
(and the N&times;N identity matrix I gives the utility-utility correlations).  
Since correlation and covariance matrices are by definition always positive-definite 
(or semidefinite in degenerate cases where we really have a lower-dimensional normal distribution)
the lemma shows that 
A-BB<sup>T</sup> must be too.
</p><p>
<b>Validity:</b>
This proves that the step in our
<a href="#ProcReg">procedure</a> based on Cholesky-factorizing 
A-BB<sup>T</sup> will always work.
</p>
<p>
In the rest of this section, we now embark on steps 1,2, and 4 of this 
<a href="#ProcReg">procedure</a> 
for numerous voting systems in the RNEM.
</p>

<a name="Sec51"></a>
<h3>5.1. Variances and Correlations for <i>honest weighted positional</i> voting</h3>
<a name="stdizeWts"></a>
<p>
We assume wlog that the weights W<sub>k</sub> defining the voting system
(where 
W<sub>1</sub>&ge;W<sub>2</sub>&ge;...&ge;W<sub>N</sub>
for an N-candidate election)
are <i>standardized</i>
so that
&sum;<sub>k</sub>W<sub>k</sub>=0
and
(1/N)&sum;<sub>1&le;k&le;N</sub>(W<sub>k</sub>)<sup>2</sup>=1.
(See <a href="#AppD">appendix D</a>
for definitions of terminology such as "weighted positional voting system.")
The candidate with the greatest summed-score (where you get score W<sub>k</sub>
for being ranked <i>k</i>th by some voter) wins.
</p>
<p>
<b>LEMMA (WPV correlations 1):</b>
<b>The vote<sub>i</sub>vote<sub>j</sub> correlation</b>
in the RNEM is
<ul>
<li>
(1/N)&sum;<sub>1&le;k&le;N</sub> (W<sub>k</sub>)<sup>2</sup> = 1 &nbsp; if &nbsp; i=j
</li><li>
(1/N)&sum;<sub>j</sub> &sum;<sub>k&ne;j</sub> W<sub>j</sub>W<sub>k</sub>/(N-1) 
= 
(1/N)&sum;<sub>1&le;j&le;N</sub> W<sub>j</sub>(-W<sub>j</sub>)/(N-1) 
= 
-1/(N-1)
&nbsp; if &nbsp; i&ne;j.
</li></ul>
</p>
<p>
<b>LEMMA  (WPV correlations 2):</b>
<b>The vote<sub>i</sub>utility<sub>j</sub> correlations</b>
in the RNEM obey
<ul>
<li>
C<sub>ii</sub> 
= 
(1/N)&sum;<sub>1&le;k&le;N</sub> G<sub>k</sub><sup>(N)</sup>W<sub>k</sub> &nbsp; if &nbsp; i=j
</li><li>
C<sub>ij</sub> 
=
(1/N)&sum;<sub>j</sub> &sum;<sub>k&ne;j</sub> G<sub>j</sub><sup>(N)</sup>W<sub>k</sub>/(N-1)
=
(1/N)&sum;<sub>j</sub> G<sub>j</sub><sup>(N)</sup>(-W<sub>j</sub>)/(N-1)
=
(-1/N)&sum;<sub>1&le;j&le;N</sub> G<sub>j</sub><sup>(N)</sup>W<sub>j</sub>/(N-1)
=
-C<sub>ii</sub>/(N-1) 
&nbsp; if &nbsp; i&ne;j.
</li></ul>
where note that the variance of each vote is 1 and the variance of each utility 
(since it is a standard normal deviate) also is 1, which simplifies the correlation calculations.
</p>
<p>
<b>LEMMA (Variances):</b>
The N vote-variances (honest voting in the RNEM) all are equal, i.e. we may take D to be the N&times;N
identity matrix.
</p>
<P>
Here G<sub>k</sub><sup>(N)</sup>
denotes the expected value of the <i>k</i>th largest of N independent standard
normal deviates, see 
<a href="#AppA">appendix A</a> on "normal order statistics."
</p>
<p>
<b>NOTES:</b>
All N-weight systems have the <i>same</i> 
vote<sub>i</sub>vote<sub>j</sub> correlations.
Among all standardized N-weight systems, the one which uniquely maximizes
C<sub>ii</sub>
(while also minimizing
C<sub>ij</sub> if j&ne;i)
has
W<sub>k</sub>&prop;G<sub>k</sub><sup>(N)</sup>.
[That maximization is a consequence of the Cauchy-Schwartz inequality.]
This is exactly the system that we shall argue in
<a href="#Thm11">theorem 11</a> 
is the 
<b>best</b>,
i.e. Bayesian-regret minimizing, rank-order-based 
voting system for honest voters in the RNEM.
</p>

<p>
<b>BORDA SPECIAL CASE:</b>
For honest Borda voting (as usual, see 
<a href="#AppD">appendix D</a>
for definitions of this and other terminology), 
in an N-candidate election, the weights (after 
<a href="#stdizeWts">standardization</a>) are
</p>
<center>
W<sub>k</sub> = [(N+1)/2 - k] [(N-1)(N+1)/12]<sup>-1/2</sup>
&nbsp;&nbsp;
for 
&nbsp;&nbsp;
1&le;k&le;N.
</center>

<p>
<b>PLURALITY SPECIAL CASE:</b>
For honest plurality voting
in an N-candidate election, the weights (after standardization) are
</p>
<center>
W<sub>k</sub> = &plusmn;(N-1)<sup>&plusmn;1/2</sup> 
</center>
<p>
where + signs are to be used if k=1, but - signs if 2&le;k&le;N.
</p>

<p>
<b>ANTIPLURALITY SPECIAL CASE:</b>
For honest antiPlurality voting
in an N-candidate election, use the same weights as for plurality voting,
except negated and in reverse order.
Because negating the G<sub>k</sub><sup>(N)</sup> is the same thing as reversing their order
(see <a href="#AppA">appendix A</a>),
we get <i>the same</i> vote-utility (and of course, vote-vote)
correlations for antiPlurality as for plurality voting.
Consequently (because of the correlation-based 
<a href="#ProcReg">procedure</a>) they have the same regret
in the V&rarr;&infin; limit.
</p>

<p>
This is quite surprising, because nobody doubts that antiPlurality 
voting is worse than plurality voting either with strategic voters, or
with honest ones if there are any finite number of voters.
But in the infinite-voter limit they (with honest voters) have the same
performance in the RNEM!
More generally, we have
</p>

<a name="Thm10"></a>
<p>
<b>THEOREM 10 (Reversal Symmetry):</b>
Reversing the order of, and negating, the weights in a (standardized) 
weighted positional voting system, yields the <i>same</i> 
vote-utility (and vote-vote)
correlations as for the original voting system; and hence the 
<i>same</i> wrong-winner probabilities and regret values arise in the 
#voters&rarr;&infin; limit (for any fixed number N of candidates).
</p>

<a name="Sec52"></a>
<h3>5.2. Variances and Correlations for <i>honest</i> (normalized) <i>range</i> voting 
for 3-candidate random normal elections </h3>

<p>
We assume that "honest normalized" range voters rate their favorite maximum
(i.e. +1 if the score-range is <nobr>[-1,+1]</nobr>), their most-hated
candidate minimum, and rate the remaining candidate with an intermediate score arising by
linearly interpolating its utility between these two; and we use a 
zero-centered score-range.
</p><p>
From sections 5 and 6 of the table of integrals in 
<a href="#AppB">appendix B</a>, we find that
the mean square value of an
honest normalized range vote is
</p>
<center>
S<sub>hnrv</sub> 
= 
(6C<sub>8</sub>+1+1)/3 
= 
(32&pi;<sup>1/2</sup>+12-3ln3)&pi;<sup>-1/2</sup>/48
&asymp;
0.7689749618.
</center>
<p>
Next we evaluate the
the vote<sub>i</sub>utility<sub>j</sub> correlation
between an honest normalized range vote, and utility, getting
</p>
<ul>
<li>
C<sub>ii</sub> = 
(6/3) (C<sub>4</sub> + &pi;<sup>-1/2</sup>/4 + &pi;<sup>-1/2</sup>/4 )
&middot;(S<sub>hnrv</sub>)<sup>-1/2</sup>
=
4&pi;<sup>-1/4</sup>3<sup>1/2</sup>(32&pi;<sup>1/2</sup>+12-3ln3)<sup>-1/2</sup>ln3
&asymp;
0.7068274659
</li><li>
C<sub>ij</sub> = 
(6/6) (-C<sub>4</sub>/2 - C<sub>4</sub>/2 - &pi;<sup>-1/2</sup>/4 - &pi;<sup>-1/2</sup>/4 + 0 + 0)
&middot;(S<sub>hnrv</sub>)<sup>-1/2</sup>
=
-2&pi;<sup>-1/4</sup>3<sup>1/2</sup>(32&pi;<sup>1/2</sup>+12-3ln3)<sup>-1/2</sup>ln3
=
(-1/2)C<sub>ii</sub> 
&asymp;
<nobr>-0.3534137330</nobr>
if j&ne;i.
</li>
</ul>
<p>
The vote<sub>i</sub>vote<sub>j</sub> correlation
is
</p>
<ul>
<li>
1 if i=j
</li><li>
(0+0-1) / (3S<sub>hnrv</sub>)
=
-16&pi;<sup>1/2</sup>/(32&pi;<sup>1/2</sup>+12-3ln3)
=
-(3S<sub>hnrv</sub>)<sup>-1</sup>
&asymp;
-0.4334774861
if j&ne;i.
</li>
</ul>
<p>
Finally, the three vote-total <i>variances</i> all are equal due to candidate-permutation symmetry.
</P>

<p>
<b>NUMERICAL CONFIRMATION:</b>
We computed 20000 triples of standard normal deviates (5 times),
finding the mean-square honest normalized range vote for every candidate was
0.76941&plusmn;0.00037.  
This confirms the theoretical value of S<sub>hnrv</sub>.
The same Monte Carlo experiment also estimated
C<sub>ii</sub>=0.70925&plusmn;0.00235.
</p>
<!--
with(stats):
for j from 1 to 5 do
sx := 0; vudot := 0; VVdot := 0;
for i from 1 to 20000 do
  xx := sort( [ stats[random, normald](3) ] );
  sx := sx + ((2*xx[2]-xx[1]-xx[3])/(xx[3]-xx[1]))^2 + 1 + 1;
  vudot := vudot + ((2*xx[2]-xx[1]-xx[3])/(xx[3]-xx[1]))*xx[2] + 1*xx[3] - 1*xx[1];
  VVdot := VVdot + 0 + 0 - 1;
od;
MS[j] := sx/60000;
Cii[j] := vudot/60000/sqrt(0.7689749618);
VVij[j] := VVdot/60000/0.7689749618;
print( "MS=", MS[j], "Cii=", Cii[j], "VVij=", VVij[j] );
od;

describe[mean]( [0.7695307155,  0.7688688477,  0.7696358945,  0.7692325397, 0.7697935928] );
describe[standarddeviation]([0.7695307155,  0.7688688477,  0.7696358945,  0.7692325397, 0.7697935928] )*sqrt(1.2);

describe[mean]( [0.7129932450, 0.7099098720,  0.7066261748,  0.7081707200, 0.7085735493] );
describe[standarddeviation]([0.7129932450, 0.7099098720,  0.7066261748,  0.7081707200, 0.7085735493] )*sqrt(1.2);

describe[mean]( [ -0.4334774862, -0.4334774862, -0.4334774862,  -0.4334774862, -0.4334774862] );
describe[standarddeviation]( [ -0.4334774862, -0.4334774862, -0.4334774862,  -0.4334774862, -0.4334774862] );
-->

<a name="Sec53"></a>
<h3>5.3. Variances and Correlations for <i>honest</i> (mean-as-threshold) <i>approval</i> voting
for 3-candidate random normal elections </h3>

<p>
We assume that the approval voters approve their
favorite, disapprove their most-hated
candidate, and approve or disapprove the remaining candidate 
depending on whether they consider its utility to be
above or below the mean of the three.
</p><p>
From sections 5 &amp; 7
of the table of integrals (<a href="#AppB">appendix B</a>), we find that 
the vote<sub>i</sub>utility<sub>j</sub> correlation
between an honest approval vote and utility is
</p>
<ul>
<li>
C<sub>ii</sub> = 
(6/3) (&pi;<sup>-1/2</sup>/4 + &pi;<sup>-1/2</sup>/4 + 2C<sub>3</sub>)
=
2(3&pi;)<sup>-1/2</sup>
&asymp;
0.6514700160
</li><li>
C<sub>ij</sub> 
= 
(12C<sub>5</sub>+12C<sub>6</sub>-3&pi;<sup>-1/2</sup>)/6
=
-(3&pi;)<sup>-1/2</sup>
= -C<sub>ii</sub>/2
&asymp;
-0.3257350080
if j&ne;i.
</li>
</ul>
<p>
The vote<sub>i</sub>vote<sub>j</sub> correlation
is
</p>
<ul>
<li>
1 if i=j
</li><li>
(0+0-1)/3
=
-1/3
&asymp;
-0.3333333333
if j&ne;i.  <!--1 & -1/3 have been rechecked.WDS.-->
</li>
</ul>
<p>
Finally again, the three vote-total <i>variances</i> all are equal due to candidate-permutation symmetry.
</P>

<p>
<b>NUMERICAL CONFIRMATION:</b>
We computed 20000 triples of standard normal deviates (9 times),
finding 
C<sub>ii</sub>=0.65102&plusmn;0.0022
and
C<sub>ij</sub>=-0.32666&plusmn;0.0019
for i&ne;j.
</p>

<!--
with(stats):
for j from 1 to 5 do
dd := 0; zz := 0;
for i from 1 to 20000 do
  xx := sort( [ stats[random, normald](3) ] );
  if(xx[2]*2>xx[1]+xx[3]) 
  then dd := dd + xx[3]-xx[1]+xx[2]; zz := zz + 2*xx[1]; 
  else dd := dd + xx[3]-xx[1]-xx[2]; zz := zz - 2*xx[3];
  fi;
od;
Cii[j] := dd/60000;
Cij[j] := zz/120000;
print( "Cii=", Cii[j],  "Cij=", Cij[j] );
od;

     "Cii=", 0.6510326507, "Cij=", -0.3234258544
     "Cii=", 0.6531142068, "Cij=", -0.3294689658
     "Cii=", 0.6518943213, "Cij=", -0.3272012067
     "Cii=", 0.6564995395, "Cij=", -0.3282120397
     "Cii=", 0.6496678670, "Cij=", -0.3262432377

                 
describe[mean]( [ 0.6523404412,  0.6526747143,  0.6520952877,  0.6485175223, 0.6512652773,
 0.6496678670,  0.6470846110,  0.6527839592,  0.6499344503, 0.6538383155 ] );
describe[standarddeviation]( [ 0.6523404412,  0.6526747143,  0.6520952877,  
 0.6485175223, 0.6512652773,
 0.6496678670,  0.6470846110,  0.6527839592,  0.6499344503, 0.6538383155 ] );

describe[mean]( [  -0.3262432377, -0.3261932132, -0.3284865972, -0.3251014972, -0.3255729881,
 -0.3234258544,-0.3294689658,-0.3272012067 ,-0.3282120397 ] );
describe[standarddeviation]([-0.3262432377, -0.3261932132, -0.3284865972, -0.3251014972, 
 -0.3255729881, -0.3234258544,-0.3294689658,-0.3272012067 ,-0.3282120397 ] );
-->

<a name="Sec54"></a>
<h3>5.4. Variances and Correlations for <i>strategic</i> approval (or range)
voting for 3-candidate random normal elections
</h3>

<p>
We now assume there are two 
candidates chosen randomly by God before the election to be "frontrunners."
Every voter knows who the two frontrunners are and each approves one and disapproves the other.
Finally, each voter approves 
or disapproves the remaining candidate
depending on whether that voter regards its utility as
above or below the mean of the three. 
Here are the results (arising from integrals in sections 3 &amp; 8 of
the table of integrals in <a href="#AppB">appendix B</a>
as well as from the work in our earlier <a href="#Sec3">section 3</a> 
on 2-candidate-plurality voting):
</p>
<ul>
<li>
The vote<sub>i</sub>utility<sub>i</sub> correlation for <i>i</i> a frontrunner candidate is
G<sub>1</sub><sup>(2)</sup>=&pi;<sup>-1/2</sup> &asymp; 0.5641895835
(see <a href="#AppA">appendix A</a>).
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for i,j being two different frontrunner candidates is
-&pi;<sup>-1/2</sup> &asymp; -0.5641895835.
</li><li>
The vote<sub>i</sub>utility<sub>i</sub> correlation for <i>i</i> not a frontrunner candidate is
2(3&pi;)<sup>-1/2</sup> &asymp; 0.6514700159.
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for <i>i</i> a non-frontrunner candidate and
<i>j</i> a frontrunner is
-(3&pi;)<sup>-1/2</sup> &asymp; -0.3257350080.
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for <i>i</i> a frontrunner and
<i>j</i> not, is 0.
</li><li>
The vote<sub>i</sub>vote<sub>i</sub> correlation is 1.
</li><li>
The vote<sub>i</sub>vote<sub>j</sub> correlation for i and j different frontrunners is -1.
</li><li>
The vote<sub>i</sub>vote<sub>j</sub> correlation for i not a frontrunner while j is, is 0. 
</li><li>
The vote variances all are equal to 1.  (For frontrunners, each vote is &plusmn;1 with 50-50 percentage;
for the non-frontrunner, the same is true for a different reason.)
</li></ul>

<p>
<b>NUMERICAL CONFIRMATION:</b>
We computed 20000 triples of standard normal deviates (10 times),
confirming all the above numbers to &plusmn;0.002.
</p>
<!--
with(stats):
for j from 1 to 5 do
Fii := 0; Fij := 0; Nii := 0; Nij := 0; VV := 0;
for i from 1 to 20000 do
  xx :=  stats[random, normald](3);
  Fii := Fii + xx[1]*sign(xx[1]-xx[3]);
  Fij := Fij + xx[3]*sign(xx[1]-xx[3]);
  Nii := Nii + xx[2]*sign(2*xx[2]-xx[1]-xx[3]);
  Nij := Nij + xx[1]*sign(2*xx[2]-xx[1]-xx[3]);
  VV := VV + sign(xx[1]-xx[3])*sign(2*xx[2]-xx[1]-xx[3]);
od;
print( "Fii=", Fii/20000, "Fij=", Fij/20000,  "Nii=", Nii/20000, "Nij=", Nij/20000, "VV=", VV/20000. );
od;

"Fii=", 0.5716775245, "Fij=", -0.5660646090, "Nii=", 0.6517121150, "Nij=", -0.3179001416, "VV=",   0.0049
"Fii=", 0.5692493135, "Fij=", -0.5635330470, "Nii=", 0.6509696270, "Nij=", -0.3228286702, "VV=",   0.0097
"Fii=", 0.5649771295, "Fij=", -0.5583991390, "Nii=", 0.6594339910, "Nij=", -0.3108689610, "VV=",  -0.0019
"Fii=", 0.5596941075, "Fij=", -0.5625135625, "Nii=", 0.6526572290, "Nij=", -0.3190172256, "VV=",   0.0025
"Fii=", 0.5587464790, "Fij=", -0.5546521525, "Nii=", 0.6579715870, "Nij=", -0.3137223251, "VV=",   0.0023
"Fii=", 0.5699678450, "Fij=", -0.5624540955, "Nii=", 0.6423635010, "Nij=", -0.3287119980, 
"Fii=", 0.5576223640, "Fij=", -0.5655143890, "Nii=", 0.6464686830, "Nij=", -0.3312779271, 
"Fii=", 0.5545011005, "Fij=", -0.5739224085, "Nii=", 0.6573349260, "Nij=", -0.3298671790, 
"Fii=", 0.5593132825, "Fij=", -0.5777101135, "Nii=", 0.6608779245, "Nij=", -0.3251525622, 
"Fii=", 0.5562487475, "Fij=", -0.5680262010, "Nii=", 0.6583736790, "Nij=", -0.3189548075, 
-->

<a name="Sec55"></a>
<h3>5.5. Variances and Correlations for <i>strategic</i> plurality=Borda
voting for 3-candidate random normal elections 
</h3>

<p>
Again we assume there are two 
candidates chosen randomly by God before the election to be "frontrunners."
Every voter votes for the best (to her) among the two frontrunners.
</p>
<p>
It is best 
to use the fact,
mentioned in the
<a href="#RemAfterThm8">remark after theorem 8</a>,
that strategic 3-candidate plurality voting is <i>equivalent</i> to
strategic 3-candidate Borda {-1, 0, +1} 
voting in the sense that both always elect the same winner 
(except in the negligibly-unlikely case of a perfect tie).
This simplifies the computations.  Then:
</p>

<!--
If do not use this trick...   ugly...
For convenience we view 3-candidate plurality as a standardized weighted positional system:
a candidate by getting a vote is awarded +2<sup>1/2</sup> points, while the
two candidates not getting a vote are awarded -2<sup>-1/2</sup>
points each. 
<ul>
<li>
The vote<sub>i</sub>utility<sub>i</sub> correlation for <i>i</i> a frontrunner candidate is
3(8&pi;)<sup>-1/2</sup> &asymp; 0.5984134205.
<br>
[From section 2 of table of integrals in 
<a href="#AppB">appendix B</a> and use the fact that 
(2<sup>1/2</sup>+2<sup>-1/2</sup>)/2=8<sup>-1/2</sup>3.]
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for i,j being two different frontrunner candidates is
-3(8&pi;)<sup>-1/2</sup> &asymp; -0.5984134205.
</li><li>
The vote<sub>i</sub>utility<sub>i</sub> correlation for <i>i</i> not a frontrunner candidate is
0.
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for <i>i</i> a non-frontrunner candidate and
<i>j</i> a frontrunner is
0.
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for <i>i</i> a frontrunner and
<i>j</i> not, is 0.
<br>
</li><li>
The vote<sub>i</sub>vote<sub>i</sub> correlation is 1.  
</li><li>
The vote<sub>i</sub>vote<sub>j</sub> correlation for i and j different frontrunners is -4/5=-0.8.
<blockquote>
This is 2(-2<sup>1/2</sup>2<sup>-1/2</sup>)/[(2<sup>1/2</sup>)<sup>2</sup>+(2<sup>-1/2</sup>)<sup>2</sup>],
which simplifies to -4/5.
</blockquote>
</li><li>
The vote<sub>i</sub>vote<sub>j</sub> correlation for i not a frontrunner while j is, is 0. 
</li><li>
The vote-total variances are as follows:
for each frontrunner, a positive constant variance (it does not matter what it is
since D needs only to be computed up to a proportionality constant); 
for the non-frontrunner, zero (since always gets  zero votes).
</li></ul>
<p>
<b>NUMERICAL CONFIRMATION:</b>
20000 random normal utility-triples were generated (5 times), and 
the two non-obvious vote-utility correlations above were found to be
0.59985&plusmn;0.0034
and
-0.59912&plusmn;0.0032
respectively.
</p>
-->

<ul>
<li>
The vote<sub>i</sub>utility<sub>i</sub> correlation for <i>i</i> a frontrunner candidate is
G<sub>1</sub><sup>(2)</sup>=&pi;<sup>-1/2</sup> &asymp; 0.5641895835 
(see <a href="#AppA">appendix A</a>).
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for i,j being two different frontrunner candidates is
-&pi;<sup>-1/2</sup> &asymp; -0.5641895835.
</li><li>
The vote<sub>i</sub>utility<sub>i</sub> 
correlation for <i>i</i> not a frontrunner candidate is
0.  (More precisely, <i>i</i>'s vote is always 0.)
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for <i>i</i> a non-frontrunner candidate and
<i>j</i> a frontrunner is
0.   (More precisely, <i>i</i>'s vote is always 0.)
</li><li>
The vote<sub>i</sub>utility<sub>j</sub> correlation for <i>i</i> a frontrunner and
<i>j</i> not, is 0.
<br>
</li><li>
The vote<sub>i</sub>vote<sub>i</sub> correlation is 1.  
(Albeit, if i is the non-frontrunner, then we get 0/0, which undefined ratio 
is not really the same thing as 1.)
</li><li>
The vote<sub>i</sub>vote<sub>j</sub> correlation for i and j different frontrunners is -1.
</li><li>
The vote<sub>i</sub>vote<sub>j</sub> correlation for i not a frontrunner while j is, is 0. 
(More precisely, <i>i</i>'s vote is always 0.)
</li><li>
The vote-total variances are as follows:
for each frontrunner, 1;
for the non-frontrunner, zero (since always gets  zero votes).
</li></ul>

<!--
with(stats):
for j from 1 to 100 do
rt2 := sqrt(2.0);
a1 := 0; a2 := 0; reg := 0; yy := [0,0,0]; vt1 := 0; vt2 := 0;
for i from 1 to 2000 do
  xx := [ stats[random, normald](3) ];
  yy := yy + xx;
  mx := sort(xx)[3];
  if(xx[1] > xx[2]) then
     a1 := a1 + rt2*xx[1] - xx[2]/rt2; #front with itself
     a2 := a2 + rt2*xx[2] - xx[1]/rt2;  #front with other front
     reg := reg + mx - xx[1];
     vt1 := vt1+1;
  else
     a1 := a1 + rt2*xx[2] - xx[1]/rt2; #front with itself
     a2 := a2 + rt2*xx[1] - xx[2]/rt2;
     reg := reg + mx - xx[2];
     vt2 := vt2+1;
  fi;
od;
zz[j] := a1/4000;
qq[j] := a2/4000;
rg[j] := reg/2000;
my := sort(yy)[3];                          
if(vt1>vt2) then r2T[j] := my-xx[1]; else rgT[j] := my-xx[2]; fi;
od;
print(zz);
print(qq);
print(rg);
print(rgT/sqrt(2000.0));

describe[mean]([ 0.5995872990, 0.5993367845,  0.5961079960,  0.6055832432, 0.5986126762 ]);
describe[standarddeviation]([ 0.5995872990, 0.5993367845,  0.5961079960,  0.6055832432, 0.5986126762 ])*sqrt(1.2);

describe[mean]([ -0.5968873380, -0.5973073578, -0.6001657765, -0.6044333200, -0.5968254492 ]);
describe[standarddeviation]([ -0.5968873380, -0.5973073578, -0.6001657765, -0.6044333200, -0.5968254492 ])*sqrt(1.2);

rg := [ 0.2853024655,  0.2834894764,  0.2809179580, 0.2818969888,  0.2830332459];
rgT := [ 25.41112456,  22.68715826,  -2.803625126,  108.5706361,  98.63910615,  59.44358524,  6.908105836,
     70.19748332,  61.07766366,  38.60447279,  4.361177121,  1.951861050,  59.32501531, -12.76250777    ];
describe[mean]( rgT ) / sqrt(2000.0);            #0.865
describe[standarddeviation]( rgT ) * sqrt(25/24/2000.0);            #0.844
-->

<blockquote>
<b>References for Section 5:</b>
<br>
<!-- George T. Gilbert:
Positive Definite Matrices and Sylvester's Criterion,
American Mathematical Monthly 98,1 (Jan. 1991) 44-46. -->
Roger A. Horn &amp; Charles R. Johnson: Matrix Analysis, Cambridge Univ. Press 1990.
<br>
Sudhir R. Ghorpade &amp; Balmohan V. Limaye:
Sylvester's Minorant criterion, Lagrange-Beltrami identity, and nonegative definiteness,
The Mathematics Student, special centenary volume (2007) 123-130.
<br>
Fuzhen Zhang: The Schur Complement and Its Applications, Springer 2005.
</blockquote>

<a name="Sec6"></a>
<h3> 6. The <i>best</i> voting systems (and their correlations) </h3>

<a name="Thm11"></a>
<p>
<b>THEOREM 11:</b>
<b>The best voting system based on <i>rank-order</i> ballots</b> 
(for 100% <i>honest</i> voters in an N-candidate election,
"best" meaning minimizing Bayesian Regret in the RNEM)
is the weighted positional system with weights 
W<sub>k</sub>&prop;G<sub>k</sub><sup>(N)</sup> 
for
k=1,2,&hellip;,N, where 
G<sub>k</sub><sup>(N)</sup> is the expected value of the 
<i>k</i>th
largest of N independent standard normal deviates 
(see <a href="#AppA">appendix A</a> on "normal order statistics").
</p>
<p>
<b>Proof:</b>
Refer back to the 
<a href="#Sec1">first section</a>,
in which we explain how to find "best"
rank-order voting systems.
It then is plain from the definition of the 
RNEM that the best system must be weighted positional.
The weights must be such that picking "the winner" is the same as picking
the candidate with the greatest expected (summed over voters) utility (conditioned
on the vote-totals); and this is achieved if and only if those weights 
are proportional to G<sub>k</sub><sup>(N)</sup>.
</p><p>
To discuss this in a little more detail:
imagine the "historical past" is infinitely long.  Over that infinite
history of "previous use" of this voting system under the RNEM,
by the <a href="#ProbBackgnd">strong law</a> of large numbers with probability&rarr;1
we know that whenever the vote, using the
here-advocated weighted positional voting system, has said "candidate A has a greater
vote total than candidate B" it has been the case that the expected utility
(averaged over all instances of that over historical time)
for A has exceeded that of B.  Therefore the optimum voting system, optimizing
expected utility of the winner, 
must be to elect the candidate 
with the greatest vote total using precisely this weighted positional
system.
<b>QED.</b>
<p>

<p>
<b>REMARK:</b>
We have already discussed the N=2 (Plurality) and N=3 (Borda) special cases of this theorem.
</p>
<p>
<b>CORRELATIONS:</b>
From our general results in section <a href="#Sec51">5.1</a>
about weighted positional voting systems we find for this voting system,
that the vote<sub>i</sub>vote<sub>j</sub> correlation
in the RNEM is
<ul>
<li>
1 if i=j,
</li><li>
-1/(N-1)
if i&ne;j.
</li></ul>
and
the vote<sub>i</sub>utility<sub>j</sub> correlation
in the RNEM is
</p>
<ul>
<li>
C<sub>ii</sub>
=
(&#9723;<sub>N</sub>)<sup>1/2</sup>
<!--
[(1/N)&sum;<sub>1&le;k&le;N</sub> (G<sub>k</sub><sup>(N)</sup>)<sup>2</sup>]<sup>1/2</sup>
/ square_N
-->
if i=j
(and note C<sub>ii</sub>&rarr;1-
in the limit N&rarr;&infin; of a large number of candidates)
</li><li>
C<sub>ij</sub> 
=
-C<sub>ii</sub>/(N-1) 
= -(&#9723;<sub>N</sub>)<sup>1/2</sup>/(N-1)
if i&ne;j
</li></ul>
where
&#9723;<sub>N</sub>=&sum;<sub>1&le;k&le;N</sub>[G<sub>k</sub><sup>(N)</sup>]<sup>2</sup>/N,
see <a href="#AppA">appendix A</a>.
<p>
<b>VARIANCES:</b>
The N vote-total variances all are equal due to candidate-permutation symmetry in our model.
</p>
<a name="Thm12"></a>
<p>
<b>THEOREM 12:</b>
<b>The <i>best</i> voting system for 
3-candidate elections based on <i>ratings</i>-type ballots</b> 
(for <i>100% honest</i> voters,
"best" meaning minimizing Bayesian Regret in the RNEM,
"honest" meaning they rate the favorite +1, the worst -1, and the other linearly
interpolated between based on utility)
is the same as range voting <i>except</i> that votes (-1, v, 1) are
multiplicatively <i>weighted</i> by W(v) 
and then the candidate with the greatest weighted sum of
scores wins.
The magic weighting function is
</p>
<a href="assets/images/BestVotFig2.png"><img src="assets/images/BestVotFig2.png" align="right" width="20%"></a>
<center>
W(v) = (3&pi;)<sup>1/2</sup>(3+v<sup>2</sup>)<sup>-1/2</sup>,
&nbsp;&nbsp;&nbsp; |v|&lt;1.
</center>
<p>
<b>REMARKS:</b>
The factor (3&pi;)<sup>1/2</sup> is irrelevant since the theorem is equally true with
any other positive constant replacing it.  This particular value was chosen because it yields
unbiased estimates of expected utility
(revealed in the proof) but using "1" of course would have been simpler.  
Some important particular values of this weighting function are
</p>
<center>
min<sub>v</sub>W(v)=W(&plusmn;1)=(3&pi;)<sup>1/2</sup>/2&asymp;1.535,
<br>
W(&plusmn;&frac12;)=1.703,
<br>
max<sub>v</sub>W(v)=W(0)=&pi;<sup>1/2</sup>&asymp;1.772,
<br>
W(0)/W(1)=2/3<sup>1/2</sup>&asymp;1.1547.
</center>
<p>
Consequently, the weighting factor W(v) is <i>constant</i>,
W(v)&asymp;(&pi;/2)<sup>1/2</sup>3<sup>1/4</sup>&asymp;1.64945
up to a multiplicative error of
2<sup>1/2</sup>3<sup>-1/4</sup>&asymp;1.07457.
Therefore this best system is "approximately the same (to within 7.5%) as plain range voting"
but not exactly the same.
</p>
<p>
<b>Proof:</B>
A perfect (regret=0) voting system would be "honest utility voting" where each voter rates
each candidate with her true utility for his election and the candidate with the greatest summed-score wins.
However, range voting, and indeed voting based on 
scores in any restricted range &ndash; for us the range is [-1,+1] &ndash;
is not perfect because, if the voters cast "normalized" (max=1, min=-1) votes,
then these perfect votes necessarily are distorted via scaling and translation.
The scaling factor is the "normalization factor"; call
its reciprocal the <i>de</i>normalization factor.
In the RNEM the expected translation is always 0.
Our magic W(v) function in 
<a href="#Thm12">theorem 12</a> 
is precisely the expected
denormalization factor conditioned on the honest vote being v, |v|&le;1, for the middle candidate.
To get the formula for W(v) we let u=(1+v)/2 so that 0&le;u&le;1 and
then because of the transformation of variables x,y,z&rarr;x,u,y mentioned in the explanations
about part 4 of the table of integrals in <a href="#AppB">appendix B</a>, we find
</p>
<!--
<center>
R = &int;&int; P(x) P(uy+[1-u]x) P(y) (x-y)<sup>2</sup> dx dy
</center>
-->
<center>
W(v) 
= 
&int;&int; P(x) P(uy+[1-u]x) P(y) (x-y)<sup>2</sup> dx dy 
<font size="+2">/</font>
&int;&int; P(x) P(uy+[1-u]x) P(y) |x-y| dx dy
</center>
<p>
where
P(y)=(2&pi;)<sup>-1/2</sup>exp(-y<sup>2</sup>/2) is the standard normal density,
and where both integrals are over the whole xy plane.
Consulting the table of integrals in <a href="#AppB">appendix B</a> we find
</p>
<!--
<center>
R = 3(16&pi;)<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-3/2</sup>
</center>
<center>
T = &pi;<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-1/2</sup>/2
</center>
<p>
and (after splitting it into x&lt;y and x&gt;y parts) 
</p>
<center>
S = 3<sup>1/2</sup>/(2 &pi; (1+u<sup>2</sup>-u))
</center>
<p>
so that 
    ratio  = 3 / sqrt(16*Pi) / sqrt(3) * 2*Pi;
</p>
-->
<center>
W(v) 
= (3&pi;)<sup>1/2</sup>(1+u<sup>2</sup>-u)<sup>-1/2</sup>/2 
= (3&pi;)<sup>1/2</sup>(3 + v<sup>2</sup>)<sup>-1/2</sup>.
</center>
<p>
Using this W(v), and only it, causes each canddidate's vote total to be the same as 
his expected utility (conditioned on the votes) hence this voting system is optimal
in that it maximizes the expected utility of the winner.
<b>QED.</b>
</p>

<p>
<b>CORRELATIONS:</b>
From the explanation of the
x,y,z&rarr;x,u,y change of variables mentioned in the explanations
of the table of integrals  in <a href="#AppB">appendix B</a>, we find that
the mean square value S<sub>bw</sub> of an honest <i>weighted</i> vote in this system is
</p>
<center>
S<sub>bw</sub> 
=
B/(3A)
=
5&pi;/6 - 3<sup>1/2</sup>/4
&asymp;
2.18498117609927504200367456736
</center>
<p>
where 
</p>
<center>
B
=
&int;&int;&int;<sub>-&infin;&lt;x&lt;z&lt;y&lt;&infin;</sub>
W(v)<sup>2</sup> [1+1+v<sup>2</sup>]
P(x) P(z) P(y) 
dx dz dy
<br>
=
&int;<sub>0&lt;u&lt;1</sub>&int;&int;<sub>-&infin;&lt;x&lt;y&lt;&infin;</sub>
(y-x) W(2u-1)<sup>2</sup> [1+1+(2u-1)<sup>2</sup>]
P(x) P(ux+[1-u]y) P(y) 
dx dy du
&asymp;
1.0924905880496375210018372837
</center>
<p>
where v=(2z-x-y)/(y-x)=2u-1, and
</p>
<center>
A
=
&int;&int;&int;<sub>-&infin;&lt;x&lt;z&lt;y&lt;&infin;</sub>
P(x) P(z) P(y) 
dx dz dy
=
1/6.
</center>
<p>
The integral defining B may be done by 
<!--
expanding 
</p>
<center>
4(3&pi;)<sup>-1</sup>W(v)<sup>2</sup> 
= 
4/(3+[2u-1]<sup>2</sup>)
=
1
+ u
- u<sup>3</sup>
- u<sup>4</sup>
+ u<sup>6</sup>
+ u<sup>7</sup>
- u<sup>9</sup>
- u<sup>10</sup>
+ u<sup>12</sup>
+ u<sup>13</sup>
- u<sup>15</sup>
-...
</center>
<p>
in series and then integrating term by term using a formula in <a href="#AppB">appendix B</a>
part 4,
--
series attack:
1/(3+v^2) = 1/(3+(2*u-1)^2) = (1/4) * (1+u-u^3-u^4+u^6+u&7-u^9-u^10+u^12+u^13-u^15...)

P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);       
W := (v) -> sqrt( 3*Pi/(3+v^2) );
WS := (v) -> 3*Pi/(3+v^2);
assume(u>0);
assume(u<1);
int(int( (y-x) * expand(1+1+(2*u-1)^2) * P(x) * P(y) * P(u*y+(1-u)*x), 
  x=-infinity..y), y=-infinity..infinity );
simplify(%);
int(int( (y-x) * expand(1+1+(2*u-1)^2) * P(x) * P(y) * P(u*x+(1-u)*y), 
  x=-infinity..y), y=-infinity..infinity );
simplify(%);
int( WS(2*u-1)*simplify(%), u=0..1);
#result=5*Pi/12 - sqrt(3)/8 = 1.092490588
S := 5*Pi/6 - sqrt(3)/4;

 int(int( (y-x) * f(u) * (y-x+(2*u-1)*(u*y+(1-u)*x)) * P(x) * P(y) * P(u*y+(1-u)*x), 
  x=-infinity..y), y=-infinity..infinity );
 int(int( (y-x) * f(u) * (y-x+(1-2*u)*((1-u)*y+u*x)) * P(x) * P(y) * P(u*x+(1-u)*y), 
  x=-infinity..y), y=-infinity..infinity );
simplify(%);
int(%, u=0..1);
simplify(%);
(2/sqrt(S)) * subs( f(u) = sqrt((3*Pi) / (3+(2*u-1)^2)), % );
simplify(%);
result = 4/(60*Pi-18*3^(1/2))^(1/2)*Pi = 1.001889363

 int(int( (y-x) * f(u) * (x-y+(2*u-1)*(x+y)) * P(x) * P(y) * P(u*y+(1-u)*x), 
  x=-infinity..y), y=-infinity..infinity );
simplify(%);
int(%, u=0..1);
simplify(%);
1/sqrt(S)*subs( f(u) = sqrt((3*Pi) / (3+(2*u-1)^2)), % );
simplify(%);
result = -2/(60*Pi-18*3^(1/2))^(1/2)*Pi = -0.5009446816
-->
doing the two inner (dx and dy) integrals using formulae in section 4 of 
<a href="#AppB">appendix B</a>,
then doing the outer integral (du) 
by the methods of section 10 of appendix B.
<!--2.25 of Gradshteyn &amp; Rhyzik.-->
The eventual result is
</p>
<center>
B 
= 
5&pi;/12 - 3<sup>1/2</sup>/8.
</center>
<!--in agreement with the previous result got by numerical integration.-->
<p>
The vote<sub>i</sub>utility<sub>j</sub> correlations (using weighted votes)
in the RNEM are
</p>
<ul>
<li>
C<sub>ii</sub>
=
<!--(6/3)=2-->
2
(S<sub>bw</sub>)<sup>-1/2</sup>
&int;<sub>0&lt;u&lt;1</sub>&int;&int;<sub>-&infin;&lt;x&lt;y&lt;&infin;</sub>
(y-x) W(2u-1) [1y-1x+(2u-1)(uy+[1-u]x)]
P(x) P(ux+[1-u]y) P(y) 
dx dy du
= (&pi;/3) (S<sub>bw</sub>)<sup>-1/2</sup>
&asymp;
0.708442762814089954
if i=j
</li><li>
C<sub>ij</sub> 
=
<!-- 6/6=1 -->
(S<sub>bw</sub>)<sup>-1/2</sup>
&int;<sub>0&lt;u&lt;1</sub>&int;&int;<sub>-&infin;&lt;x&lt;y&lt;&infin;</sub>
(y-x) W(2u-1) [1x-1y+(2u-1)(x+y)]
P(x) P(ux+[1-u]y) P(y) 
dx dy du
= -(&pi;/6) (S<sub>bw</sub>)<sup>-1/2</sup>                     
&asymp;
-0.354221381407044977
if i&ne;j.
</li></ul>

<p>
These values all were first computed by high-precision
numerical integration but then ways were found to do the integrals in closed form,
and finally the formulas and numerical results were verified to coincide to all decimal places.
Both C<sub>ii</sub> and 
C<sub>ij</sub> were derived in closed form by using 
part 4 of 
<a href="#AppB">Appendix B</a> to do the two inner integrals,
then part 10 to handle the outer integration.
</p>
<!--
<center>
2(3&pi;)<sup>-1/2</sup>W(v)
= 
2(3+[2u-1]<sup>2</sup>)<sup>-1/2</sup>
=
1
+ u/2
- u<sup>2</sup>/8
- 7u<sup>3</sup>/16
- 37u<sup>4</sup>/128
+ 23u<sup>5</sup>/256
+ 331u<sup>6</sup>/1024
+ 457u<sup>7</sup>/2048
-...
</center>
And note that 
<nobr>C<sub>ii</sub>+2C<sub>ij</sub>=0</nobr>
holds to all decimal places given.
-->
<p>
The vote<sub>i</sub>vote<sub>j</sub> correlation (both votes weighted)
is
</p>
<ul>
<li>
1 &nbsp; &nbsp; if &nbsp; &nbsp;  i=j
</li><li>
<!--  (0+0-1) / 3   the two 0s may not each be 0 but anyway they do cancel out -->
Expect([0+0-1]W<sup>2</sup>)/(3S<sub>bw</sub>)
=
-1/3
&nbsp; &nbsp; if &nbsp; &nbsp;  j&ne;i.
</li>
</ul>
<p>
<b>VARIANCES:</b>
All three vote-total variances are equal due to candidate-permutation symmetry in our model.
</p>

<p>
<b>NUMERICAL CONFIRMATION:</b>
We computed 20000 triples of standard normal "candidate utility" deviates (7 times).
The mean-square (honest weighted) vote in this voting system was found to be
2.18499&plusmn;0.00055,
confirming the theoretical value
2.1849811761.
</p><p>
The mean of the ratio &Delta;/W, where
&Delta; is the utility difference between the max- and min-utilities in the triple
while
W is W(v) [where v, -1&le;v&le;1, is the unweighted vote for the middle candidate]
was found to be
0.9976&plusmn;0.0025,
confirming the theoretical claim that weighting by W(v) yields an unbiased estimate
of utility (in which case we should have gotten &Delta;/W=1 in expectation).
</p><p>
We also confirmed the theoretical values of
C<sub>ii</sub>,
C<sub>ij</sub>,
and the value "-1/3" numerically to &plusmn;0.0005.
<!--
with(stats):
P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);       
W := (z) -> sqrt(3*Pi) / sqrt(3+z*z);
WS := (z) -> (3*Pi) / (3+z*z);
for j from 1 to 5 do
MS := 0; CS := evalf(3*Pi); UD := 0; ED := 0; UER := 0; VUii := 0; VUij := 0;
for i from 1 to 20000 do
  xx :=  sort( [stats[random, normald](3)] );
  z := (2*xx[2]-xx[1]-xx[3])/(xx[3]-xx[1]);
  z2 := z*z;
  wgt := CS/(3+z2);                
  MS := MS + (1 + 1 + z2)*wgt;
  UD := xx[3]-xx[1];
  ED := evalf(W(z));
  UER := UER + UD/ED;
  VUii := VUii + (1*xx[3] - 1*xx[1] + z*xx[2]) *ED;
  VUij := VUij + (1*xx[1] - 1*xx[3] + z*xx[1] + z*xx[3] + 0 + 0)*ED;
od;
MSS := MS/(3.0*20000);
print("MSvote=", MSS,
   "Mean(UtilDiff/EstDiff)=", UER/20000.0,
   "VUii=", VUii/(3.0*20000*sqrt(MSS)),
   "VUij=", VUij/(6.0*20000*sqrt(MSS))
);
od;

"MSvote=", 2.184384297, "Mean(UtilDiff/EstDiff)=", 1.003533504, "VUii=", 0.7104113740, "VUij=",    -0.3561533992
"MSvote=", 2.185671622, "Mean(UtilDiff/EstDiff)=", 0.9991516775, "VUii=", 0.7084353410, "VUij=",    -0.3531596048
"MSvote=", 2.184947390, "Mean(UtilDiff/EstDiff)=", 1.000265953, "VUii=", 0.7086822843, "VUij=",    -0.3542727032
"MSvote=", 2.185225314, "Mean(UtilDiff/EstDiff)=", 1.003525118, "VUii=", 0.7106162146, "VUij=",    -0.3557344148
"MSvote=", 2.184311764, "Mean(UtilDiff/EstDiff)=", 0.9945678885, "VUii=", 0.7056160600, "VUij=",    -0.3514375163

describe[mean]( [2.184311719, 2.185225374, 2.184947354, 2.185671555, 2.184384342, 2.185720511, 2.184292177,
 2.185196854, 2.185128259] );
describe[standarddeviation](
[2.184311719, 2.185225374, 2.184947354, 2.185671555, 2.184384342, 2.185720511, 2.184292177,
 2.185196854, 2.185128259] ) * sqrt(9.0/8.0);

describe[mean]( [0.9966402492, 0.9935970991, 0.9989492379, 1.000185287, 0.9955479599, 1.000460606,  0.9977791025 
]  );
describe[standarddeviation](                                                                
[0.9966402492, 0.9935970991, 0.9989492379, 1.000185287, 0.9955479599, 1.000460606,  0.9977791025]
) * sqrt(7.0/6.0);

assume(u>0);
assume(u<1);
A1 := int(int(int( P(x)*P(u*y+(1-u)*x)*P(y) * 1,
 x=-infinity..infinity), y=-infinity..infinity), u=0..1);
      #Pi^(-1/2) * ln(3)/2 = 0.3099128049
C1 := int(int(int( P(x)*P(u*y+(1-u)*x)*P(y) * (1+1+(2*u-1)^2) * WS(2*u-1),
 x=-infinity..infinity), y=-infinity..infinity), u=0..1);
      #1/2*(-1+3*ln(3))/Pi^(3/2) = 0.2061513679
B1 := int(int(int( P(x)*P(u*y+(1-u)*x)*P(y) * (1+1+(2*u-1)^2) * WS(2*u-1) * (1+1+(2*u-1)^2),
 x=-infinity..infinity), y=-infinity..infinity), u=0..1);
    #-1/4*(3*ln(3)-14)/Pi^(3/2) =  0.4805824628
A := Int(Int(Int( (y-x)*P(x)*P(u*y+(1-u)*x)*P(y) * 1,
 x=-infinity..y), y=-infinity..infinity), u=0..1);
      #ought to be 1/6. Yes = 0.1666666667
B := int(int(int( (y-x)*P(x)*P(u*y+(1-u)*x)*P(y) * WS(2*u-1) * (1+1+(2*u-1)^2),
 x=-infinity..y), y=-infinity..infinity), u=0..1);
    #maple cannot do dydx but can do dx. 
evalf[20]( Int( 3/16*2^(1/2)*exp(-y^2*(-u+u^2+3)/(2-2*u+u^2))*(-11*y*u*exp(2/(2-2*u+u^2)*y^2)*Pi^(1/2)-4*y
*u^3*exp(2/(2-2*u+u^2)*y^2)*Pi^(1/2)+12*y*u^2*exp(2/(2-2*u+u^2)*y^2)*Pi^(1/2)+6*y*exp(2/(2-2*u+u^2
)*y^2)*Pi^(1/2)-6*y*erf(y*(u-2)/(4-4*u+2*u^2)^(1/2))*exp(2/(2-2*u+u^2)*y^2)*Pi^(1/2)-12*y*erf(y*(u
-2)/(4-4*u+2*u^2)^(1/2))*u^2*exp(2/(2-2*u+u^2)*y^2)*Pi^(1/2)+11*y*erf(y*(u-2)/(4-4*u+2*u^2)^(1/2))
*u*exp(2/(2-2*u+u^2)*y^2)*Pi^(1/2)+4*y*erf(y*(u-2)/(4-4*u+2*u^2)^(1/2))*u^3*exp(2/(2-2*u+u^2)*y^2)
*Pi^(1/2)+3*exp(-1/2*y^2*u*(-4+u)/(2-2*u+u^2))*(4-4*u+2*u^2)^(1/2)+4*exp(-1/2*y^2*u*(-4+u)/(2-2*u+
u^2))*u^2*(4-4*u+2*u^2)^(1/2)-4*exp(-1/2*y^2*u*(-4+u)/(2-2*u+u^2))*u*(4-4*u+2*u^2)^(1/2))/(4-4*u+2
*u^2)^(1/2)/(2+5*u^2-4*u-3*u^3+u^4)/Pi^(1/2),[y = -20.9 .. 20.9, u = 10^(-15) .. 1-10^(-15)]
));
    #it tries hard not to do it, but    1.092490588
B := int(int(int( 2*y*P(x)*P(u*y+(1-u)*x)*P(y) * WS(2*u-1) * (1+1+(2*u-1)^2),
 x=-infinity..y), y=-infinity..infinity), u=0..1);
evalf[30](2*Int(-3/8*y*2^(1/2)*exp(-y^2*(1+u^2-u)/(2-2*u+u^2))*(3+4*u^2-4*u)*(-1+erf(y*(u-2)/(4-4*u+2*u^2)
^(1/2)))/(1+u^2-u)/(4-4*u+2*u^2)^(1/2), [y = -infinity .. infinity , u = 0 .. 1]));
  #2B =  2*1.09249058804963752100183728368 = 2.18498117609927504200367456736
MS = B/A/3 =  2.184981176
MS := 2.18498117609927504200367456736;
VUiiX := Int(Int(Int( (y-x)*P(x)*P(u*y+(1-u)*x)*P(y) * W(2*u-1) * ( 1*y - 1*x + (2*u-1)*(u*y+(1-u)*x) ),
 x=-infinity..y), y=-infinity..infinity), u=0..1);
evalf[20]( VUiiX * 2/sqrt(MS) );
#      0.70844276281408995440

VUijX := Int(Int(Int( (y-x)*P(x)*P(u*y+(1-u)*x)*P(y) * W(2*u-1) * ( 1*x - 1*y + (2*u-1)*(x+y) ),
 x=-infinity..y), y=-infinity..infinity), u=0..1);
evalf[20]( VUijX / sqrt(MS) );
#       -0.35422138140704497719
-->

<a name="Thm13"></a>
<p>
<b>THEOREM 13:</b>
<b>Degeneration of rated voting systems in presence of strategic voters</b>
<br>
Unfortunately the voting system in the preceding theorem is only "best" 
if the voters are <i>honest</i>.
Suppose all the voters instead act strategically as follows:
they give A the maximum and B the minimum possible score, or the reverse
(where A and B are 
selected randomly by God before the election as the 
two "frontrunners") and then give the remaining candidate C 
the exactly intermediate
score (since that maximizes the weight, i.e. "impact,"
of this vote on the crucial A vs B battle).
In that case, our "best rated" system degenerates to become equivalent to strategic
Borda voting (see 
<a href="#RemAfterThm8">remark after theorem 8</a>)
&ndash; and that in turn, in the 3-candidate case we are speaking about here,
is equivalent to strategic <i>plurality</i> voting in the sense that both 
elect the same winner.
</p>
<p>
In contrast, plain range voting degenerates with strategic voters to 
become equivalent to strategic <i>approval</i> voting as discussed in 
<a href="https://rangevoting.org/WarrenSmithPages/homepage/Sec54">section 5.4</a>, which is considerably better.
</p>

<a name="Sec7"></a>
<h3>7. The regrets of various voting systems </h3>

<p>
Refer back to the regret-computing <a href="#ProcReg">procedure</a> 
explained at the start of <a href="#Sec5">section 5</a>.
We have now computed all the <i>correlations</i> in closed form,
and hence are ready to move on to the task of 
computing Bayesian <i>Regrets</i>.  We begin by restating/summarizing our
earlier results in the format of the C and D matrices used by that procedure.
</p>
<p>
<b>Best rated voting system (3 candidates, honest voters):</b>
To 8 decimals we find (of course, we actually know exact formulas for all entries for 
all C matrices in this section;
but since many formulas are long we often content ourselves with decimals. 
See the <a href="#RNDict">dictionary</a> table 1 for some of the shorter formulas,
and in all cases where the formula isn't 
in the dictionary, using the known part of C and the known CC<sup>T</sup>
should suffice to determine the missing formulas.)
<pre>
    [ 0.70844276 -0.35422138 -0.35422138  0.49715518  0.00000000  0.00000000 ]
C &asymp; [-0.35422138  0.70844276 -0.35422138  0.08666314  0.48954344  0.00000000 ]
    [-0.35422138 -0.35422138  0.70844276  0.08666314  0.07266879  0.48411985 ]
</pre>
where the lefthand 3&times;3 block of this matrix gives the C<sub>ij</sub>=Correl(vote<sub>i</sub>,utility<sub>j</sub>)
from <a href="#Sec6">section 6</a>
and the righthand  3&times;3 block (which is lower triangular) was chosen using 
Cholesky factorization
as described in step 3 of the <a href="#ProcReg">procedure</a>
given at the start of section 5 in order to cause
(C<sup>T</sup>C)<sub>ij</sub>
to give the correct vote-vote correlations, i.e. 
<pre>
      [  1   -1/3  -1/3]
CC<sup>T</sup> = [-1/3    1   -1/3]
      [-1/3  -1/3    1 ].
</pre>
We also have
<pre>
    [ 1   0   0 ]
D = [ 0   1   0 ]
    [ 0   0   1 ]
</pre>
Indeed, from here on the diagonal D matrix (giving the variances)
may always be taken to be (perhaps up an overall scaling factor, which does not matter)
the 3&times;3 identity matrix, <i>unless</I> otherwise stated.
</p>

<p>
<b>Range voting (3 candidates, honest voters):</b>
From <a href="#Sec52">section 5.2</a> we similarly find
<pre>
    [ 0.70682747 -0.35341373 -0.35341373  0.50059205  0.00000000  0.00000000]
C &asymp; [-0.35341373  0.70682747 -0.35341373 -0.11740835  0.48662889  0.00000000]
    [-0.35341373 -0.35341373  0.70682747 -0.11740835 -0.14910419  0.46322308]
</pre>
<pre>
      [1   Q   Q]
CC<sup>T</sup> = [Q   1   Q] ,    Q = -1/(3S<sub>hnrv</sub>) &asymp; -0.43347748603822207333
      [Q   Q   1]
</pre>
</p>

<p>
<b>Best rank-order-based voting system (3 candidates, honest voters) = Borda:</b>
From <a href="#Sec51">section 5.1</a>
we similarly find &ndash; and this is a rank-deficient case so we need to
append only two, not three, extra columns to the lefthand 3&times;3 block of C
(but we still can regard the result as 3&times;6 if
we append an extra zero column):
<pre>
    [ 0.69098830 -0.34549415 -0.34549415  0.53273141  0.00000000 ]
C &asymp; [-0.34549415  0.69098830 -0.34549415 -0.26636571  0.46135894 ]
    [-0.34549415 -0.34549415  0.69098830 -0.26636571 -0.46135894 ]
</pre>
<pre>
      [  1   -1/2  -1/2]
CC<sup>T</sup> = [-1/2    1   -1/2]
      [-1/2  -1/2    1 ]
</pre>
</p>
<!--
Exact formulas: C =
       [   1/2           1/2          1/2                 1/2                           ]
       [  6             6            6          (4 Pi - 9)                              ]
       [ -------     - -------    - -------     -------------              0            ]
       [     1/2           1/2          1/2            1/2                              ]
       [ 2 Pi          4 Pi         4 Pi           2 Pi                                 ]
       [                                                                                ]
       [    1/2         1/2           1/2                  1/2      1/2           1/2   ]
       [   6           6             6           (4 Pi - 9)        3    (4 Pi - 9)      ]
       [- -------     -------     - -------    - -------------     ------------------   ]
       [      1/2         1/2           1/2             1/2                 1/2         ]
       [  4 Pi        2 Pi          4 Pi            4 Pi                4 Pi            ]
       [                                                                                ]
       [    1/2          1/2         1/2                   1/2       1/2           1/2  ]
       [   6            6           6            (4 Pi - 9)         3    (4 Pi - 9)     ]
       [- -------    - -------     -------     - -------------    - ------------------  ]
       [      1/2          1/2         1/2              1/2                  1/2        ]
       [  4 Pi         4 Pi        2 Pi             4 Pi                 4 Pi           ]
-->
<p>
<b>Plurality voting with 3 candidates and honest voters:</b>
From <a href="#Sec51">section 5.1</a> we similarly find (another rank-deficient case)
<pre>
    [  0.59841342 -0.29920671 -0.29920671  0.68033232  0.00000000  ]
C &asymp; [ -0.29920671  0.59841342 -0.29920671 -0.34016616  0.58918507  ]
    [ -0.29920671 -0.29920671  0.59841342 -0.34016616 -0.58918507  ]
<!-- now finding regrets with TRYS=1000000
 10million, ww=33.9903%, reg=0.226028 -->
</pre>
(Plurality has the same CC<sup>T</sup> as for Borda immediately above).
</p>
<!--exact C:
     [    1/2           1/2          1/2                  1/2                               ]
     [ 3 2           3 2          3 2         (16 Pi - 27)                                  ]
     [ -------     - -------    - -------     ---------------               0               ]
     [     1/2           1/2          1/2             1/2                                   ]
     [ 4 Pi          8 Pi         8 Pi            4 Pi                                      ]
     [                                                                                      ]
     [     1/2         1/2           1/2                   1/2      1/2             1/2     ]
     [  3 2         3 2           3 2          (16 Pi - 27)        3    (16 Pi - 27)        ]
     [- -------     -------     - -------    - ---------------     --------------------     ]
     [      1/2         1/2           1/2              1/2                   1/2            ]
     [  8 Pi        4 Pi          8 Pi             8 Pi                  8 Pi               ]
     [                                                                                      ]
     [     1/2          1/2         1/2                    1/2       1/2             1/2    ]
     [  3 2          3 2         3 2           (16 Pi - 27)         3    (16 Pi - 27)       ]
     [- -------    - -------     -------     - ---------------    - --------------------    ]
     [      1/2          1/2         1/2               1/2                    1/2           ]
     [  8 Pi         8 Pi        4 Pi              8 Pi                   8 Pi              ]
-->
<p>
<b>AntiPlurality voting with 3 candidates and honest voters:</b>
As we remarked in <a href="#Sec51">section 5.1</a> the <i>same</i> 
C and D matrices arise for antiplurality and for plain plurality
voting in N-candidate honest-voter elections with the same N.
</p>

<p>
<b>Approval with 3 candidates and Honest voters:</b>
From <a href="#Sec53">section 5.3</a> we similarly find
<pre>
    [  0.65147002 -0.32573501 -0.32573501  0.60281027  0.00000000  0.00000000 ]
C &asymp; [ -0.32573501  0.65147002 -0.32573501 -0.02492235  0.60229486  0.00000000 ]
    [ -0.32573501 -0.32573501  0.65147002 -0.02492235 -0.02597494  0.60173450 ]
<!--  10million, ww=25.8943%, reg=0.130246 -->
</pre>
</p>
<!--exact:
[    1/2          1/2          1/2                   1/2                                                                     ]
[ 2 3            3            3              (Pi - 2)                                                                        ]
[ -------     - -------    - -------         -----------                      0                               0              ]
[     1/2           1/2          1/2              1/2                                                                        ]
[ 3 Pi          3 Pi         3 Pi               Pi                                                                           ]
[                                                                                                                            ]
[    1/2          1/2          1/2                                            1/2                                            ]
[   3          2 3            3                 Pi - 3                      %1                                               ]
[- -------     -------     - -------    - -------------------        -------------------                      0              ]
[      1/2         1/2           1/2                1/2   1/2                  1/2   1/2                                     ]
[  3 Pi        3 Pi          3 Pi         3 (Pi - 2)    Pi           3 (Pi - 2)    Pi                                        ]
[                                                                                                                            ]
[    1/2          1/2          1/2                                                                     2                1/2  ]
[   3            3          2 3                 Pi - 3                (Pi - 3) (4 Pi - 9)        (16 Pi  + 81 - 72 Pi) 3     ]
[- -------    - -------     -------     - -------------------    - -------------------------    -----------------------------]
[      1/2          1/2         1/2                 1/2   1/2                1/2   1/2   1/2         /     2             \1/2]
[  3 Pi         3 Pi        3 Pi          3 (Pi - 2)    Pi         3 (Pi - 2)    Pi    %1            |16 Pi  + 81 - 72 Pi|   ]
[                                                                                               3 %1 |-------------------|   ]
[                                                                                                    \        %1         /   ]

                                                                    2
                                                          %1 := 8 Pi  - 30 Pi + 27
-->
<pre>
      [  1   -1/3  -1/3]
CC<sup>T</sup> = [-1/3    1   -1/3]
      [-1/3  -1/3    1 ]
</pre>
<p>
<b>Strategic plurality voting (3 candidates) regarded as strategic Borda:</b>
From <a href="#Sec55">section 5.5</a>
we similarly find (this is a triply rank-deficient case)
<pre>
    [ 0.56418958 -0.56418958  0.00000000  0.60281027]
C &asymp; [-0.56418958  0.56418958  0.00000000 -0.60281027]
    [ 0.00000000  0.00000000  0.00000000  0.00000000]
<!--Scalings=sqrt(variances):   1.000000  1.000000  0.000000   NOTE THE ZERO
exact:
                       [                                    1/2           ]
                       [   1           1            (Pi - 2)              ]
                       [ -----     - -----    0     -----------     0    0]
                       [   1/2         1/2               1/2              ]
                       [ Pi          Pi                Pi                 ]
                       [                                                  ]
                       [                                     1/2          ]
                       [    1         1              (Pi - 2)             ]
                       [- -----     -----     0    - -----------    0    0]
                       [    1/2       1/2                 1/2             ]
                       [  Pi        Pi                  Pi                ]
                       [                                                  ]
                       [   0          0       0          0          0    1]
-->
</pre>
and D=diag(1, 1, 0) and
<pre>
      [ 1   -1   0]
CC<sup>T</sup> = [-1    1   0]
      [ 0    0   1].
</pre>
</p>

<p>
<b>Magic best among the 2 "frontrunners" only (N candidates; 2 chosen at random by God 
to be labeled "frontrunners"):</b>
<pre>
    [1 0 0 ... 0]
C = [0 1 0 ... 0]
    [0 0 0 ... 0]
</pre>
and D=diag(1, 1, 0).
[Note, in both this and the preceding case,
the <a href="#MonteCarloPsuCode">pseudocode</a>
for computing regrets and wrong-winner probabilities can be modified
slightly to make sure it refuses to elect a non-frontrunner.]
</p>


<p>
<b>Approval (or Range) with 3 candidates and Strategic voters:</b>
From <a href="https://rangevoting.org/WarrenSmithPages/homepage/Sec54">section 5.4</a> we similarly find (rank-deficient case)
<pre>
    [ 0.56418958 -0.56418958  0.00000000  0.60281027  0.00000000 ]
C &asymp; [-0.56418958  0.56418958  0.00000000 -0.60281027  0.00000000 ]
    [-0.32573501 -0.32573501  0.65147002  0.00000000  0.60281027 ]
</pre>
<pre>
      [ 1  -1  0]
CC<sup>T</sup> = [-1   1  0] 
      [ 0   0  1]
</pre>
</p>
<!--exact C:
             [                                              1/2                  ]
             [    1             1                   (Pi - 2)                     ]
             [  -----       - -----        0        -----------            0     ]
             [    1/2           1/2                      1/2                     ]
             [  Pi            Pi                       Pi                        ]
             [                                                                   ]
             [                                               1/2                 ]
             [     1           1                     (Pi - 2)                    ]
             [ - -----       -----         0       - -----------           0     ]
             [     1/2         1/2                        1/2                    ]
             [   Pi          Pi                         Pi                       ]
             [                                                                   ]
             [    1/2          1/2         1/2                                1/2]
             [   3            3         2 3                           (Pi - 2)   ]
             [- -------    - -------    -------          0            -----------]
             [      1/2          1/2        1/2                            1/2   ]
             [  3 Pi         3 Pi       3 Pi                             Pi      ]
-->

<p>
<b>"Random winner" with 3 candidates (which by an <a href="#ObsSAP">observation</a> 
in section 4.1 is equivalent to antiPlurality with strategic voters):</b>
<pre>
    [0 0 0 1 0 0]
C = [0 0 0 0 1 0]
    [0 0 0 0 0 1]
</pre>
</p>

<p>
<b>"Magic Best" and "Magic Worst" with 3 candidates (Magic Best also is called
"honest utility voting"):</b>
<pre>
    [1 0 0]                     [-1   0   0]
C = [0 1 0]       and      C =  [ 0  -1   0]
    [0 0 1]                     [ 0   0  -1]
</pre>
</p>
<a name="RNDict"></a>
<p>
Here is a <b>dictionary</b> enabling the reader to find exact formulas
for many of the numbers stated  above as decimals.
<!--hon approval, complicated missing; should expand and split into subtables grouped horizontally-->
</p>

<table bgcolor="pink" cellpadding="5" border="1">
<caption>
<b>Table 1.</b> A small dictionary of real numbers.
</caption>
<tr><td>0.024922</td><td align="right">(&pi;/3-1)([&pi;-2]&pi;)<sup>-1/2</sup></td></tr>
<tr><td>0.266366</td><td align="right">(4-9/&pi;)<sup>1/2</sup>/4</td></tr>
<tr><td>0.299207</td><td align="right">(3/8)(2/&pi;)<sup>1/2</sup></td></tr>
<tr><td>0.304142</td><td align="right">(&pi;/3-1)(2&pi;-3)<sup>1/2</sup>(4&pi;-9)<sup>3/2</sup>&pi;<sup>-1/2</sup>(&pi;-2)<sup>-1/2</sup></td></tr>
<tr><td>0.325735</td><td align="right">(3&pi;)<sup>-1/2</sup></td></tr>
<tr><td>0.340166</td><td align="right">(16-27/&pi;)<sup>1/2</sup>/8</td></tr>
<tr><td>0.345494</td><td align="right">(8&pi;/3)<sup>-1/2</sup></td></tr>
<tr><td>0.353414</td><td align="right">3<sup>1/2</sup>2ln(3)&pi;<sup>-1/4</sup>[32&pi;<sup>1/2</sup>+12-3ln(3)]<sup>-1/2</sup></td></tr>
<tr><td>0.354221</td><td align="right">&pi;[30&pi;-3<sup>1/2</sup>9]<sup>-1/2</sup></td></tr>
<tr><td>0.461359</td><td align="right">(12-27/&pi;)<sup>1/2</sup>/4</td></tr>
<tr><td>0.497155</td><td align="right">(10&pi;-3<sup>1/2</sup>3-2&pi;<sup>2</sup>)(10&pi;-3<sup>1/2</sup>)<sup>-1/2</sup></td></tr>
<tr><td>0.500592</td><td align="right">[32&pi;+12&pi;<sup>1/2</sup>-3&pi;<sup>1/2</sup>ln(3)-72ln(3)<sup>2</sup>]<sup>1/2</sup>[32&pi;<sup>1/2</sup>+12-3ln(3)]<sup>-1/2</sup>&pi;<sup>-1/4</sup></td></tr>
<tr><td>0.532731</td><td align="right">(4-9/&pi;)<sup>1/2</sup>/2</td></tr>
<tr><td>0.564190</td><td align="right">&pi;<sup>-1/2</sup></td></tr>
<tr><td>0.589185</td><td align="right">(48-81/&pi;)<sup>1/2</sup>/8</td></tr>
<tr><td>0.598413</td><td align="right">(3/4)(2/&pi;)<sup>1/2</sup></td></tr>
<tr><td>0.602294</td><td align="right">3<sup>-1</sup>(2&pi;-3)<sup>1/2</sup>(4&pi;-9)<sup>1/2</sup>&pi;<sup>-1/2</sup>(&pi;-2)<sup>-1/2</sup></td></tr>
<tr><td>0.602810</td><td align="right">(1-2/&pi;)<sup>1/2</sup></td></tr>
<tr><td>0.651470</td><td align="right">2(3&pi;)<sup>-1/2</sup></td></tr>
<tr><td>0.680332</td><td align="right">(16-27/&pi;)<sup>1/2</sup>/4</td></tr>
<tr><td>0.690988</td><td align="right">(2&pi;/3)<sup>-1/2</sup></td></tr>
<tr><td>0.706827</td><td align="right">3<sup>1/2</sup>4ln(3)&pi;<sup>-1/4</sup>[32&pi;<sup>1/2</sup>+12-3ln(3)]<sup>-1/2</sup></td></tr>
<tr><td>0.708443</td><td align="right">2&pi;[30&pi;-3<sup>1/2</sup>9]<sup>-1/2</sup></td></tr>
</table>

<p>
Using these D- and C-matrices, 
we can now compute the "wrong"-winner percentages and Bayesian regrets
(scaled by V<sup>-1/2</sup>) for
each voting method. 
The simplest procedure for doing that is <b>P-point Monte Carlo integration</b>:
</p>
<a name="MonteCarloPsuCode"></a>
<pre>
WrongWinCount&larr;0;  Regret&larr;0;
for(t=1 to P){
   u &larr; vector of 6 independent standard normal random deviates;
   v &larr; Cu    (3x6 matrix times 6-vector product, yielding a 3-vector)
   v &larr; D<sup>1/2</sup>v    (scales the <i>i</i>th entry of the 3-vector by &radic;D<sub>ii</sub>)
   i &larr; 1;   if(v<sub>2</sub>>v<sub>1</sub>){ i&larr;2; }   if(v<sub>3</sub>>v<sub>i</sub>){ i&larr;3; }
   j &larr; 1;   if(u<sub>2</sub>>u<sub>1</sub>){ j&larr;2; }   if(u<sub>3</sub>>u<sub>j</sub>){ j&larr;3; }
   (Now i maximizes v<sub>i</sub> while j maximizes u<sub>j</sub>)
   if(i&ne;j){
     WrongWinCount &larr; WrongWinCount + 1;
     Regret &larr; Regret + u<sub>j</sub> - u<sub>i</sub>;
   }
}
print("Wrong Win Percentage &asymp; ", 100.0*WrongWinCount/P);
print("V<sup>-1/2</sup>Bayesian Regret &asymp; ", Regret/P);
</pre>
which prints values arbitrarily near to the correct ones
with probability&rarr;1 in the P&rarr;&infin; limit.
We can however also compute the Wrong Win Percentage and Bayesian Regret
<i>analytically</i> in terms of Schl&auml;fli functions S<sub>6</sub>
and pure-linear moments, respectively.  Both are described in 
<a href="#AppC">Appendix C</a> where it is shown that closed
formulas for the latter always exist; the former also have closed forms in every 
rank-deficient case; in both cases dilogarithms may be needed.  (If trilogarithms are
permitted, then every entry has a closed form.)
</p>

<p>
The following table summarizes the results.
It gives the Wrong Win Percentage and Bayesian Regret
for all the voting methods shown, in <i>3-candidate</i>
RNEM elections in the
V&rarr;&infin; limit.  
</p><p>
<b>Notes on the table:</b>
We list voting systems in best-to-worst, i.e. increasing-regret, order.
All (&le;7)-digit numeric values were computed using P&ge;1.6&times;10<sup>12</sup>-point
Monte Carlo integration using the pseusocode above with standard-error estimates taken as
the sample standard deviation of 5 subsample-means (each subsample with P/5 points) divided
by &radic;5.
This <b>accuracy</b> is estimated to be <i>&plusmn;k</i> units in the last decimal place, where
<i>k</i> is given in parentheses after the number.
We sped up the program by about a factor of 10 by
using the following trick. The main timesink in the code is the generation of the 6-vector of
normal random deviates, which we do using the Box-Muller polar method.
(See discussion of normal deviate generation in
<a href="#AppD">appendix D</a>.  Substantially faster 
methods for generating normals are available, namely the Marsaglia-Tsang
"ziggurat" method and the Wallace-Brent all-real methods, but I avoided the former due to
worries that I might introduce "bugs" and the latter due to worries about its statistical quality.)
We therefore generate <i>one</i> such 6-vector but then use it
16 times via considering all ways to make an even number of sign changes in the first 5
coordinates.
This 16&times; trick not only speeds up the computation; it also appears to increase its accuracy
by decreasing variance while leaving expectation value unaltered
(i.e. these points are "better than random").
</p><p>
<b>About the Monte Carlo code:</b>
As a smaller-scale check on the Monte Carlo code, we ran it with 100 times fewer
points using Marsaglia's MWC1038 generator of period&gt;2<sup>33245</sup>.
(That should yield exactly 1 fewer digits of accuracy.)
We also did this again,
the second time with Marsaglia's KISS generator of period&gt;2<sup>124</sup>;
and finally a third time using the generator (due
to Brent and Marsaglia, call it "BM256")
</p>
<center>
X<sub>n</sub> = (X<sub>n-256</sub> + X<sub>n-178</sub> - X<sub>n-119</sub> - X<sub>n-58</sub>) mod 1
</center>
<p>
which directly returns uniform real numbers in [0,1) without requiring any conversion from integers.
All three sanity checks worked in the sense that their statistical errors
were within expected bounds &ndash; but unfortunately, their results disagreed!
Specifically, KISS and MWC1038 agreed, but exhibited small but reproducible
systematic disagreements with BM256.
I suspect most or all of the reason was the fact that KISS and MWC1038 generate 32-bit random words
while BM256 generates random 52-bit reals (the number of bits in an IEEE standard real mantissa).
The simple solution to this unacceptable problem was to <i>combine</i>
the outputs of the MWC1038 and BM256 generators by mod-1 addition
to get a result at least as random as either, and <i>that</i> was the
underlying generator used for the final, large, run.
</p><p>
The tabulated values with 9 or more digits were computed using closed formulas.
In principle all values could have been computed with closed forms, but
the formulas can get large, see 
appendix C's  of <a href="#FormLen">discussion</a>
of formula length.
<!--no longer true, see sec 8.2:
Entries whose closed forms require [at least naively] "monster" formulas
involving <i>tri</i>logarithms and with poorly-understood "branching" behavior,
are decorated with &Dagger;.-->
</p>

<a name="BigResultsTable"></a>
<table bgcolor="aqua">
<caption>
<b>Table 2.</b>
Bayesian Regrets of various voting methods in 3-candidate (V&rarr;&infin;)-voter RNEM elections.
</caption>
<tr bgcolor="pink"><th>Voting method</th><th>"Wrong winner" percentage</th><th>V<sup>-1/2</sup>Regret</th></tr>
<tr><td>Magic Best</td><td>0</td><td>0</td></tr>
<tr><td>BRBH=Best ratings-based (Honest voters, see <a href="#Sec6">sec. 6</a>)</td><td>18.70338(6)%</td><td>0.0674537(2)</td></tr>
<tr><td>Honest Range</td><td>22.35938(6)%</td><td>0.0968636(3)</td></tr>
<tr bgcolor="yellow"><td>Honest Approval (mean as threshold)</td><td>25.86333(3)%</td><td>0.1300873(4)</td></tr>
<tr bgcolor="yellow"><td>Best rank-order-based (Honest Voters)=Borda</td><td>25.86335(4)%</td><td>0.1300876(2)</td></tr>
<tr><td>Strategic Approval (=Range, see <a href="#Thm13">theorem 13</a>)</td><td>30.98197(3)%</td><td>0.1863856(2)</td></tr>
<tr><td>Honest Plurality=AntiPlurality</td><td>33.99984(3)%</td><td>0.2260388(4)</td></tr>
<tr><td>Magic best among the 2 frontrunners only</td><td>1/3&asymp;33.3333333%</td><td><nobr>G<sub>1</sub><sup>(3)</sup>-G<sub>1</sub><sup>(2)</sup></nobr>=<nobr>&pi;<sup>-1/2</sup>/2</nobr>&asymp;0.282094792</td></tr><!--confirmed to 4S-->
<tr><td>Strategic Plurality (=Borda=IRV=Condorcet=BRBH,<br> see theorems <a href="#Thm8">8</a> &amp; <a href="#Thm13">13</a>)</td><td>45.43326(5)%</td><td>(3/2)&pi;<sup>-1/2</sup>-2<sup>1/2</sup>/&pi;&asymp;0.3961262173</td></tr>
<tr><td>Random winner=Strategic AntiPlurality</td><td>2/3&asymp;66.6666667%</td><td>(3/2)&pi;<sup>-1/2</sup>&asymp;0.8462843754</td></tr><!--confirmed to 4S-->
<tr><td>Worst winner</td><td>100%</td><td>3&pi;<sup>-1/2</sup>&asymp;1.6925687506</td></tr>
</table>

<!-- 
Mean and sample stddev of 5 runs each 3.2*10^11 points:

describe[mean](Plur), describe[standarddeviation[1]](Plur);
  33.99982732, 
   0.000003357551191

describe[mean](Bord), describe[standarddeviation[1]](Bord);
   25.86333692,
    0.00005208294035

describe[mean](HonApp), describe[standarddeviation[1]](HonApp);
   25.86327972,
    0.00002104897800

describe[mean](Rnge), describe[standarddeviation[1]](Rnge);
   22.35934266,
    0.00002170076784

describe[mean](BsRat), describe[standarddeviation[1]](BsRat);
   18.70330931, 0.

describe[mean](StApp), describe[standarddeviation[1]](StApp);
   30.98197572,
    0.00002498163075


describe[mean](Plur), describe[standarddeviation[1]](Plur);
      0.2260385440, 
      0.0000005970175877

describe[mean](Bord), describe[standarddeviation[1]](Bord);
    0.1300877600, 
    0.0000002464751509

describe[mean](HonApp), describe[standarddeviation[1]](HonApp);
    0.1300870580, 
    0.0000003669741135

describe[mean](Rnge), describe[standarddeviation[1]](Rnge);
  0.09686415600, 
  0.0000002245662486

describe[mean](BsRat), describe[standarddeviation[1]](BsRat);
  0.06745339600, 
  0.0000001150217371

describe[mean](StApp), describe[standarddeviation[1]](StApp);
   0.1863854040, 
   0.0000001424078650

describe[mean](StBor);     0.3961258600.



comparison with 200-voter old monte carlo data (from 1999-2000) for 3-canddt
http://www.math.temple.edu/~wds/homepage/voFdata
Random-Normal(0,1) Utilities (infinite issue limit). 200 voters.
Each regret datapoint averages 666666 expts.

method       regret(oldMc)   regret(here)             ratio
WORST-WIN      23.92543      1.6925687506            14.13557  vs  sqrt(200)=14.14214
RAND-WIN       11.96272      0.8462843754=.846305    14.13558
STRAT-BORD      5.61662      
STRAT-PLUR(thy) 5.61662      0.3961262173            14.17886
BEST'O'2          NA         0.282094792=.282107
HON-PLUR        3.13808      0.226043                13.88267
HON-ANTIPLUR    3.26536      0.226043                14.44575
STRAT-APP       2.65709      0.186385                14.25592
HON-APP         1.85211      0.130094                14.23671
HON-BORDA       1.84368      0.130099                14.17125
HON-RANGE       1.37282      0.096863                14.17323
BEST-RATED        NA         0.067448
MAGIC-BEST        0             0

2CAND-HON-PLUR  1.61631      0.1140314256(thy)       14.17425
Of these, all look good (<0.81% relative error) except for 
hon-plur(2% error) and hon-antiplur(2%).
Strat-plur(thy) seems correct.  
-->
<p><b>Remark (Robert Munafo):</b>1/(&phi;<sup>5</sup>ln2)&asymp;0.13008773
where &phi;=(1+&radic;5)/2 is the "golden ratio."
</p>
<a name="OldMC"></a>
<p><b>NUMERICAL CONFIRMATION:</b>
I compared the tabulated numbers (as well as
our theoretical regret 0.1140314256V<sup>1/2</sup>
from <nobr><a href="#Thm6">theorem 6</a></nobr> for <i>two</i>-candidate
plurality voting) with old 666666-election Monte Carlo data (from my 1999-2000 study)
for 200-voter random-normal elections.   We do not expect exact equality because
of statistical noise and more importantly because
&infin; and 200 voters are different.
The regrets were found to be identical to
within &lt;0.81% relative error in all cases except for the following:
<ol type="a">
<li>
Honest 3-candidate plurality voting: 1.8% relative discrepancy.
</li><li>
Honest 3-candidate antiPlurality voting: 2.2% off.
<br>
Note: these plurality and antiPlurality discrepancies are 
<i>unavoidably</i> large because the theoretical regret
0.22595V<sup>1/2</sup> 
in the infinite-voter-limit 
V&rarr;&infin;
(which by <a href="#Thm10">theorem 10</a> is the <i>same</i>
for both plurality and antiPlurality voting)
lies almost precisely <i>midway between</i> the two old
experimental results for 200 voters.
Thus, this discrepancy, although at first it seems worrying,
actually represents almost as good confirmation as could possibly be hoped for.
If V<sup>-1/2</sup>regret approaches its limit value L like 
<nobr>L&middot;[1+O(1/V)],</nobr>
then assuming the coefficients hidden in the "O" are about -4 and +4 for
plurality and antiPlurality voting, respectively, would explain the data.
Apparently plurality and antiPlurality have larger than usual |coefficients|;
the other voting systems apparently have |coefficients| of order 1.
</li><li>
The 1999-2000 study had not examined 
the best ratings-based system and "magic best among two."
However, the latter still is numerically confirmed in the sense that the C-matrix based 
approach for
computing regrets and wrong-winner probabilities, gives the same number to
5 decimal places as our exact theoretical result obtained via a different approach.
</ol>

<a name="ConjEq"></a>
<p>
<b>REMARKABLE COINCIDENCE:</b>
The regrets (and the wrong-winner probabilities too!) for honest approval and Borda voting
<i>agree</i> to within about a part in 100,000.
This astonished me and led me to ask whether, in fact, they are equal.
</p><p>
Approval <i>clearly</i> seems better than Borda in the sense that 
approval voters get to indicate one of  two possible scores for their middle-choice candidate,
whereas Borda voters  cannot transmit any information about him.
(In both systems, honest voters behave exactly the same about their top and bottom choice candidates,
so the only difference is the middle choice.)
<i>But</i>  approval forces voters
to <i>exaggerate</i> their views of the middle candidate to be "equal" to the best or
worst &ndash; a distortion which clearly makes approval suboptimal for honest voters.
The amazing thing is that
evidently these positive and negative effects exactly <i>cancel</i>!
</p>
<p>
As we shall  see in the next theorem, they <i>are</i> equal.
</p><p>
This was initially mysterious.
A sufficiently determined reader could, using our closed formulas, compute
both BRs to 500 significant figures, then verify their equality.
(Also, even without the closed formulas, one could still get considerably greater accuracy by
using better methods for numerical integration than Monte Carlo, see Stroud 1971.)
However, even 500-place agreement still would not prove exact equality.
One could try to simplify both formulas to a common canonical form...
but unfortunately at present no algorithm is known to simplify formulas
involving polylogarithms (even dilogs) to canonical forms &ndash; and
I can say from personal experience that MAPLE is exceedingly
incompetent at it &ndash;  and since these formulas
are very long (see
appendix C's  of <a href="#FormLen">discussion</a>
of formula length), this proof would also be enormous even if it could be done.
</p><p>
So those brute-force proof-ideas seem unpromising.
But a more elegant attack works.
</p><p>
<a name="Thm14"></a>
<p>
<b>THEOREM 14</b>
<b>(Borda and Approval "geometrically the same"):</b>
Borda and Approval voting have 
the exact same regrets and wrong-winner probabilities (for honest voters
in the 3-candidate random normal elections model).
</p><p>
<b>Proof:</b>
The proof idea in 5 words is: 
"Don Saari's planar geometrical picture."  (See figure.
This idea is in his book <i>Basic geometry of voting.</i>)
</p>
<a href="assets/images/SaariDodec.png"><img src="assets/images/SaariDodec.png" align="right" width="37%"></a>
<p>
Although it seemed like 3-candidate Borda and Approval votes v are 3-dimensional,
<i>really</i> they only are 2-dimensional because it is OK to
view everything projected into the <i>plane</i>
v<sub>1</sub>+v<sub>2</sub>+v<sub>3</sub>=0.
</p><p>
In this plane, the 6=3! allowed Borda votes 
</p>
<center>
(-1, 0, +1), &nbsp;&nbsp;
(-1, +1, 0), &nbsp;&nbsp;
(+1, 0, -1), &nbsp;&nbsp;
(+1, -1, 0), &nbsp;&nbsp;
(0, -1, +1), &nbsp;&nbsp;
(0, +1, -1),
</center>
<p>
are the vertices of a
regular hexagon.
(Different weighted positional systems would lead to irregular hexagons.)
</p><p>
The 6=2<sup>3</sup>-2 non-silly approval votes (rescaled and translated to lie
on the v<sub>1</sub>+v<sub>2</sub>+v<sub>3</sub>=0 plane)
</p>
<center>
(-2, +1, +1), &nbsp;&nbsp;
(+1, -2, +1), &nbsp;&nbsp;
(+1, +1, -2), &nbsp;&nbsp;
(+2, -1, -1), &nbsp;&nbsp;
(-1, +2, -1), &nbsp;&nbsp;
(-1, -1, +2)
</center>
<p>
<i>also</i> form the vertices of a
regular hexagon.
</p><p>
Up to a scaling by a factor of &radic;3
(which cannot matter) and a rotation by 30 degrees, they
are the same hexagon.
</p><p>
If we project the lefthand 3&times;3 blocks of the Borda and Approval
honest-voter 
C matrices 
from <a href="#Sec7">section 7</a>
(where C<sub>ij</sub> is the 
vote<sub>i</sub>utility<sub>j</sub> correlation)
into a 2-dimensional XY plane, then (up to scaling) these 
2&times;3 matrices result:
<pre>
[6      -3       -3     <font color="red">[6(4&pi;-9)]<sup>1/2</sup>            0</font>]
[0      3&radic;3    -3&radic;3     <font color="red">0            [6(4&pi;-9)]<sup>1/2</sup></font>] 
</pre>
where the reader may check that the <i>same</i>
matrix arises for either Borda or Approval
voting.  (Only pay attention to the leftmost 3 columns of the matrix for the moment.)
Now due to the hexagonal symmetry, the vote-distribution in this XY plane
must be a <i>circularly-symmetric</i> normal distribution, <i>not</i> elliptical.
This vote distribution arises (up to a scaling factor)
by generating a vector u of standard normal deviates,
then computing the matrix-vector product
Cu.   If u is 3-dimensional, then the reader may check that
a 2-dimensional perfectly 
circularly-symmetric normal distribution indeed results from this C.
In order to make the vote distribution come out right, we also need
to add more noise, which effect is got (just as 
in the <a href="#ProcReg">correlation-based procedure</a>
before, in the step where we added "extra columns")
by adding extra components to the u vector
and extra columns to the C-matrix.  These extra columns, in order
not to destroy the perfect circular symmetry (and assuming they form a <i>triangular</i> matrix,
as we know from <a href="https://rangevoting.org/WarrenSmithPages/homepage/PosDefLemma">earlier</a> work they must), must 
wlog form a multiple
of the 2&times;2 identity matrix.  
(In fact, by, e.g, projecting the full Borda 3&times;5 matrix we can show it 
is exactly the multiple shown in the rightmost two columns, but we will not need this fact for
the purposes of the present proof.)
</p><p>
Honest Borda voters decide which one of the 6 legal votes to cast, by seeing
which of 6 wedge-shaped regions (each with apex angle 60&deg; 
forming an infinite "pie") the 2D-projected 
(u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>) 
lies in.  
Honest approval voters instead examine the 12-wedge pie got by bisecting every Borda
pie-wedge, and there is a fixed 2-to-1 map from pie wedges to votes.
The Borda voters of course may also be viewed as consulting the
12-wedge pie and using a (different) fixed 2-to-1 map.
</p><p>
The only difference between approval and Borda is the 30&deg; angle
by which the hexagon of legal votes is rotated relative to this
(fixed) pie.  However, since the wedge-angles of the 12-wedge pie are each
30&deg;, this really is no change at all.
If we agree to rescale the Borda and Approval votes 
to make their circularly-symmetric-normal vote-distributions in the XY plane
identical, 
the pictures actually are the same.
</p><p>
It therefore follows (since their scalings must be the same)
that both the lefthand and the righthand blocks of the 2&times;5
C-matrices are the <i>same</i> for both Borda and Approval.
</p><p>
Therefore, the integrals defining RNEM Bayesian Regret and wrong-winner probability,
also are the <i>same</i>.  
[Specifically, the integrals are over the region of 
5-space 
(u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>, u<sub>4</sub>, u<sub>5</sub>) 
where  (say) candidate 1 wins because X&gt;|Y|tan(30&deg;)
where (X, Y)<sup>T</sup>=Cu, but u<sub>2</sub>&gt;u<sub>1</sub> 
and
u<sub>2</sub>&gt;u<sub>3</sub> 
so that candidate 2 was the greatest-utility winner.
The integrand is the normal density times 
u<sub>2</sub>-u<sub>1</sub> 
for Regret (or just times 1 for wrong-winner probability).
Finally we need to multiply by a factor of 3!=6 
to count all symmetric images of this scenario.]
</p><p>
The proof is complete. <b>QED.</b>
</p>
<p><b>NUMERICAL CONFIRMATION:</b>
When we explicitly write the 5-dimensional integral representations of the 
wrong winner probability&asymp;25.863%
and
Bayesian Regret&asymp;0.13009
deduced in the above proof, we get (after the additional trivial
change of variables 
u<sub>1</sub>=x<sub>2</sub>-x<sub>1</sub>,
u<sub>2</sub>=x<sub>2</sub>,
u<sub>3</sub>=x<sub>2</sub>-x<sub>3</sub>,
u<sub>4</sub>=x<sub>4</sub>,
u<sub>5</sub>=x<sub>5</sub>,
and using the
fact that cot30&deg;=&radic;3)
</p>
<center>
0.25863 &asymp; 6&int;&int;&int;&int;&int; 
F'(x<sub>2</sub>-x<sub>1</sub>)
F'(x<sub>2</sub>)
F'(x<sub>2</sub>-x<sub>3</sub>)
F'(x<sub>4</sub>)
F'(x<sub>5</sub>)
dx<sub>5</sub>
dx<sub>1</sub>
dx<sub>3</sub>
dx<sub>4</sub>
dx<sub>2</sub>
</center>
<p>
where
F'(y)=(2&pi;)<sup>-1/2</sup>exp(-y<sup>2</sup>/2) is the standard normal density
and the integral is over the region
</p>
<center>
A&le;x<sub>5</sub>&le;B, &nbsp;
0&le;x<sub>1</sub>&le;&infin;, &nbsp;
0&le;x<sub>3</sub>&le;&infin;, &nbsp;
-&infin;&le;x<sub>4</sub>&le;+&infin;, &nbsp;
-&infin;&le;x<sub>2</sub>&le;+&infin;
</center>
<p>
and
</p>
<center>
A=(6x<sub>1</sub>-6x<sub>3</sub>-[24&pi;-54]<sup>1/2</sup>x<sub>4</sub>)(8&pi;-18)<sup>-1/2</sup>,
&nbsp;&nbsp;
B=([24&pi;-54]<sup>1/2</sup>x<sub>4</sub>-6x<sub>1</sub>)(8&pi;-18)<sup>-1/2</sup>.
</center>
<p>
The right hand side instead gives &asymp;0.13009 if its
integrand is multiplied by x<sub>1</sub>.
These two numerical values were obtained by numerical integration 
(via ACM TOMS algorithm 698)
of the outer 4 integrals (with &plusmn;&infin; truncated to &plusmn;6)
after a symbolic integration (using erf) of the innermost integral.  Their
agreement with the values found 
<a href="https://rangevoting.org/WarrenSmithPages/homepage/BigResultsTable">earlier</a>
using Monte Carlo integration of the original form of the integral, constitutes
numerical confirmation both of the symbolic manipulations inside the 
<a href="https://rangevoting.org/WarrenSmithPages/homepage/Thm14">proof</a>, and
of my Monte Carlo program.
</p>
<p><small>
It is possible to reduce the whole 5D-integral to close form using the Schl&auml;fli function 
theory in <a href="#AppC">appendix C</a>.   As an experiment, I asked MAPLE to do
this for the wrong-winner
probability, but the 
resulting closed form was many pages long and when MAPLE was asked to simplify it
it went into an (apparently) infinitely-long think. 
<!-- The remote chance remains, though, that some very simple expression works, e.g.
Simon Plouffe pointed out that 19/(11+&radic;13)/10=0.1300875... -->
</small></p>
<p>
<b>REMARK:</b>
The amazing equalities in
<a href="https://rangevoting.org/WarrenSmithPages/homepage/Thm14">theorem 14</a>
<i>only</i> hold for &le;3 candidates.
(Borda would have lower regret than approval in <i>&ge;4</i>-candidate RNEM elections
with honest voters, albeit approval does better with strategic voters.)
</p>

<!--
BORDA lefthand 3x3 block:
[2 -1 -1]
[-1 2 -1] * sqrt(6/Pi)/4
[-1 -1 2]

XYworld:
[6      -3       -3]
[0      3r3    -3r3] * sqrt(6/Pi)/8

CTC =
[2 -1 -1]
[-1 2 -1] /2
[-1 -1 2]

APPROVAL lefthand 3x3 block:
[2 -1 -1]
[-1 2 -1] * sqrt(3/Pi)/3
[-1 -1 2]

XYworld:
[6      -3       -3]
[0     3r3     -3r3] * sqrt(3/Pi)/6

CTC =
[3 -1 -1]
[-1 3 -1] /3
[-1 -1 3]
-->

<blockquote>
<b>References for Section 7:</b>
<br>
Richard P. Brent:
Some Comments on C.S. Wallace's Random Number Generators,
The Computer Journal 51,5 (2008) 579-584.
<br>
Pierre L'Ecuyer &amp; Richard Simard:
TestU01: A software library in ANSI C for the empirical testing of random number generators,
ACM Transactions on Mathematical Software 33,4 (August 2007) Article 22.
<br>
<!--George Marsaglia &amp; Arif Zaman:
Some portable very-long period random number generators,
Computers in Physics 8,1 (1994) 117-121.
The pseudocode for their "mzran13" generator  contains a typo: 
n-69069 should read "n=69069."-->
George Marsaglia: Random Number Generators,
J. Modern Applied Statistical Methods 2,1 (May 2003) 2-13.
<br>
Donald G. Saari: Geometry of Voting, Springer 1995.
<br>
G.Marsaglia &amp; Wai Wan Tsang:
The ziggurat method for generating random variables, J. Statist. Softw. 5,8 (2000) 1-7.
[There are two slight bugs in their code for random normals.
Low-order bits from the same random integer used to
provide the sample,
are re-used to select
the rectangle &ndash;
causing a slight correlation 
which causes the generator to fail high-precision tests.
Getting those bits from an independent random word fixes that.
Also, a further even smaller flaw is that using 32-bit random integers is not really sufficient
for generating 52<sup>+</sup>-bit random-real normals, so their output is artificially "grainy."]
<br>
Arthur H. Stroud:
Approximate Calculation of Multiple Integrals,
Prentice Hall, 1971.
<br>
D.B.Thomas, W.Luk, P.H.W.Leong, J.D.Villasenor:
Gaussian Random Number Generators,
ACM Computing Surveys 39,4 (Oct. 2007) Article 11.
[Concludes Ziggurat and Wallace are the best; 2-to-7 times faster than Polar method.]
</blockquote>

<a name="Sec8"></a>
<h3>8. What about honest+strategic voter <i>mixtures</i>? </h3>

<p>
What if some fraction F of the voters are honest while 1-F are strategic?
More generally, we can consider a K-component voter mixture where fraction F<sub>k</sub>&ge;0
for k=1,2,&hellip;,K have behavior k, with &sum;<sub>1&le;k&le;K</sub>F<sub>k</sub>=1.
</p>
<a name="Thm15"></a>
<p>
<b>THEOREM 15 (Multicomponent voter mixtures):</b>
The same <a href="#MonteCarloPsuCode">Monte-Carlo procedure</a> works as before to
compute Bayesian Regret from the D and C matrices for the voting systemss
except that instead of the lines that compute
</p>
<center>
v &larr; D<sup>1/2</sup>Cu
</center>
<p>
we instead compute
<center>
v &larr; &sum;<sub>1&le;k&le;K</sub> 
F<sub>(k)</sub><sup>1/2</sup> D<sub>(k)</sub><sup>1/2</sup> C<sub>(k)</sub> u<sub>(k)</sub>;
<br>
u &larr; &sum;<sub>1&le;k&le;K</sub> 
F<sub>(k)</sub><sup>1/2</sup> u<sub>(k)</sub>;
</center>
<p>
where (for k=1,2,&hellip;,K)
<ul>
<li>
Each u<sub>(k)</sub> is an <i>independent</i> 6-vector of standard normal deviates;
</li><li>
Each D<sub>(k)</sub> is the diagonal matrix of the vote-variances for the voters of type k,
and <i>note</I> that now all the D's need to be <i>compatibly scaled</i>;
merely computing them up to
some undetermined scaling constant no longer suffices;
</li><li>
Each C<sub>(k)</sub> encodes the vote-vote and vote-utility correlations as usual,
just for the voters of type k only;
</li></ul>
<p>
We warn the reader that this only necessarily works for <i>nonsingular</i>
voting systems where all the
entries of the C and D matrices are well defined. 
(Strategic Plurality and antiPlurality voting
are singular as was explained in
<a href="https://rangevoting.org/WarrenSmithPages/homepage/Sec55">section 5.5</a>;
and we shall explain what happens for them in
<a href="#Thm17">theorem 17</a>.)
</p>
<p>
Again, instead of Monte Carlo we can simply compute the corresponding integrals as before.
Again we get Schl&auml;fli and moment functions (see <a href="#AppC">appendix C</a>)
just as before.
Although the method in <a href="#Thm15">theorem 15</a> 
has the virtue of simplicity (the proof should be obvious &ndash; the given formula makes the correlations,
variances, and expectation value come out right; and because of the properties of multidimensional
normal distributions, that's enough &ndash; and the 
<a href="#MonteCarloPsuCode">Monte-Carlo procedure</a>
is very simple) it is poor for <i>analysis</i> purposes because
it unfortunately multiplies the dimensionality
of the integrals by K.  That difficulty is illusory; 
really the dimensionality is not increased at all.
</p>
<a name="Thm16"></a>
<p>
<b>THEOREM 16 (Dimension non-increase for voter mixtures):</b>
The K-times-higher dimensional integrals arising for voter <nobr>K-component</nobr> mixtures
as in  <a href="#Thm15">theorem 14</a>
can be replaced by one integral of the
exact same dimensionality and type as before, just with appropriately re-devised
C and D matrices.
</p>
<p>
<b>Proof sketch:</b>
The vote<sub>i</sub>-utility<sub>j</sub> correlations (i.e. the correlations
between 
y<sub>i</sub> and u<sub>j</sub> in the <a href="#MonteCarloPsuCode">Monte Carlo pseudocode</a>) 
are easily worked out exactly from the component matrices.
These will be used to fill in the lefthand N&times;N block of the 
C matrix.
Then the righthand block will be computed via Cholesky as before
to make the 
vote<sub>i</sub>-vote<sub>j</sub> correlations come out right
(those too are easily worked out exactly), and as before this
requires at most N extra columns to be adjoined to the C matrix.
Finally, the vote variances (in y) too are easily worked out exactly and used 
for the entries of the D matrix.
<b>QED.</b>
</p>

<p>
Due to this non-increase, we still have closed forms using low-dimensional
Schl&auml;fli and moment functions (see <a href="#AppC">appendix C</a>) for any voter
mixture.
</p>

<a name="Thm17"></a>
<p>
<b>THEOREM 17 (Discontinuities):</b>
For plurality voting in the RNEM, introducing a fraction &epsilon;
of strategic voters into the mix, for any &epsilon;&gt;0 no matter how small,
causes the regret to jump <i>discontinuously</i> 
to the same value as plurality with <i>100%</i>
strategic voters.
The same thing happens with antiplurality voting.
</p>
<p>
<b>Proof:</b>
With &epsilon; fraction strategic voters who (for plurality voting) always vote
for one of the two "frontrunners"
(whichever they perceive to be the "lesser evil")
and zero for every other candidate, the net result will be a boost in vote total
by an amount&ge;V&epsilon;/2, for the most popular frontrunner.
This, in the V&rarr;&infin; limit, far exceeds the differences of order (1-&epsilon;)V<sup>1/2</sup>
among all the other candidates
arising from the honest votes.   
It therefore, with probability&rarr;1 in the V&rarr;&infin; limit, forces the top frontrunner to
win, i.e. the same result as with 100% strategists (at least, assuming the strategic and honest voters
have the same utilities independently, and the RNEM <i>does</i> assume that; and we are implicitly
using well known tail
properties of the normal distribution and central limit theorem).
Similarly for antiPlurality voting, the non-frontrunner with the fewest honest antivotes
always wins for any &epsilon;&gt;0 with probability&rarr;1 in the V&rarr;&infin; limit.
<b>QED.</b>
</p>
<p>
<b>REMARKS:</b>
</p>
<ol>
<li>
Note that this 
discontinuity in regret 
as a function of &epsilon;
only happens in the  V&rarr;&infin; limit.
For any finite V the regret is a continuous function of &epsilon;.
(Physicists call this a "phase transition.")
</li><li>
<a href="https://rangevoting.org/WarrenSmithPages/homepage/Thm17">Theorem 17</a>
goes a long way toward explaining why plurality-voting countries like the USA
suffer such massive 2-party domination.
</li></ol>

<p>
Using theorems 14-16, I computed the regret curves
for our voting methods.  
Compatible scalings for the D matrices arise from the following:
<p>
<ul>
<li>
Honest {-1, 0, +1} Borda: variance=2/3.
</li><li>
Strategic {-1, 0, +1} Borda: variance=1 for frontrunners, 0 for nonfrontrunner.
</li><li>
Honest [-1, 1] Range:
variance=S<sub>hnrv</sub>&asymp;0.7689749618 from <a href="#Sec52">section 5.2</a>.
</li><li>
Strategic &plusmn;1 Approval=Range voting: variance=1.
</li><li>
Honest &plusmn;1 Approval: variance=1.
</li><li>
Honest BRBH: if scaled by W(0)<sup>-1</sup>=&pi;<sup>-1/2</sup> 
so that strategic BRBH becomes strategic {-1, 0, +1} Borda 
(see <a href="#Sec6">section 6</a>),
then honest BRBH has variance &pi;<sup>-1</sup>S<sub>bw</sub>&asymp;0.6955011095.
</li></ul>

<a name="RegPlot"></a> 
<center>
<a href="assets/images/RegVsHonestyGraph2.png"><img src="assets/images/RegVsHonestyGraph2.png" width="80%"></a>
</center>
<!-- equations of curves: 
#Strategic to honest Borda:
y = .4603217355-.2830432724*x-.4826848220e-1*(2*x-1)^2-.6304224566e-2*(2*x-1)^3-.\
5080940833e-1*(2*x-1)^4+.8469284790e-1*(2*x-1)^5+.1665504138*(2*x-1)^6-.1924367018*(2*x-\
1)^7-.2402866640*(2*x-1)^8+.1969127571*(2*x-1)^9+.1481113046*(2*x-1)^10-.7443672664e-1*(
2*x-1)^11-.3089484809e-1*(2*x-1)^12

#Strategic Approval to Honest Range:
y = .2066269878-.8040000220e-1*x-.2666870079e-1*(2*x-1)^2-.6241468148e-2*(2*x-1)^3+.\
3911483122e-1*(2*x-1)^4+.1822612313e-1*(2*x-1)^5-.1697150008*(2*x-1)^6-.5675432249e-1*(2
*x-1)^7+.3306608524*(2*x-1)^8+.7077527152e-1*(2*x-1)^9-.3026122085*(2*x-1)^10-.\
3075749654e-1*(2*x-1)^11+.1046701669*(2*x-1)^12

#Strategic Approval to Honest Approval:
y = .2002357962-.5394960530e-1*x-.9153423976e-2*(2*x-1)^2+.6707160255e-3*(2*x-1)^3-.\
6736192932e-1*(2*x-1)^4+.9243988971e-2*(2*x-1)^5+.2860542704*(2*x-1)^6-.5828860409e-1*(2
*x-1)^7-.5337480617*(2*x-1)^8+.8850610031e-1*(2*x-1)^9+.4523928598*(2*x-1)^10-.\
4144282398e-1*(2*x-1)^11-.1433273395*(2*x-1)^12

#Strategic Borda to honest Best Rated: 
y = .4766064717-.3655781206*x-.5414079842e-1*(2*x-1)^2+.3093619220e-1*(2*x-1)^3-.\
4946273266e-1*(2*x-1)^4-.6505534343e-1*(2*x-1)^5+.2076166563*(2*x-1)^6+.1375087409*(2*x-\
1)^7-.4207159440*(2*x-1)^8-.1287162040*(2*x-1)^9+.3848408439*(2*x-1)^10+.4387665026e-1*(
2*x-1)^11-.1303055494*(2*x-1)^12
-->
<p>
<b>OBSERVATIONS:</b>
<ol>
<li>
At least under the assumption this plot is not <i>incredibly</I>
inaccurate, we see that it proves the <b>MAIN RESULT</b> of this paper:
<i>For 3-candidate RNEM elections,
range voting is superior to even the best rank-ballot-based voting system (Borda,
see <a href="#Thm1">theorems</a> 1-3 and <a href="https://rangevoting.org/WarrenSmithPages/homepage/Thm11">11</a>)
at every voter honesty-vs-strategy  fraction.</i>
</li><li>
We also see from the plot these other results:
<ol type="i">
<li>
 Approval voting is superior to Borda at every voter
honesty fraction <i>except</i> 100% honesty, where the two have equal regrets
by <a href="#Thm14">theorem 14</a>;
</li><li>
Range is superior to 
approval voting at every voter
honesty fraction <i>except</i> 100% strategy (where they are the same);
</li><li>
BRBH is 
superior to 
Borda voting at every voter
honesty fraction <i>except</i> 100% strategy (where they are the same);
</li></ol>
</li><li>
However, all of these observations have to be regarded by True Mathematicians 
as <i>conjectures</i>,
not <i>theorems</I>,
because of the slight theoretical possibility that our numerical computations were 
inaccurate enough that
when curve A looks like it lies below curve B everywhere, really it somewhere lies above it.
By using <b>interval arithmetic</b> and our closed formulas for all curves, one could in principle
prove the Main Result with full rigor.  
<br>
I.e. to prove A(x)&lt;B(x) for all x with 0&lt;x&lt;1
one simply evaluates A(x) and B(x) for the <i>interval</i> x=(0,1).  
If the resulting two intervals are disjoint, proof done.
If not, then one can subdivide the domain into two subintervals, e.g. (0, &frac12;) and 
[&frac12;, 1) and continue on.  If the procedure stops in some finite number
of steps (and it usually takes very little time), we have a proof.
<br>
Of course, it is ludicrous to deny the Main Result because in fact, our plot
is accurate to pixel resolution, i.e. <i>vastly</i> more accuracy than needed.
But the fact remains that it, <i>strictly</i> speaking, is not proven until
somebody dots the final i by doing this mechanical verification.
<br>
Although the results 2(i), (ii) and (iii) presumably could also be proven
with interval arithmetic, they are trickier because 
the curves actually touch at their endpoints.
You'd need therefore also to prove the <i>derivative</I> of curve A lies above or below that of B
near the touching point.  That can be done using symbolic differentiation
of our closed formulas
(which also can be done fully automatically, e.g. see Rall 1981, Griewank 2000), 
combined with interval arithmetic, and conceivably even 2nd or 3rd 
derivatives might need to be taken. These all are fully mechanizable computations 
but seem outside
the reach of an unaided human because the closed formulas are so large.  
<blockquote>
<a name="PhiloNote"></a>
<b>Philosophical note:</b>
Also, even if somebody truly
did the job, one would have to wonder, in view of the complexity of their software,
whether that proof would really generate more confidence than our non-proof.
I.e. consider a hypothetical graduate student who announced "I wrote a 5000-line
computer program to do all the formulas, 
symbolic differentiation, and interval arithmetic, and
it has now <i>genuinely</I> completed the proof!  My program sits on top of
a 1,000,000-line commercial symbolic manipulation system with secret code, a 2,000,000-line
operating system, a 300,000-line compiler, and a secret computer design involving 1,000,000,000
transistors, all of which depend upon the validity of quantum physics and correctness
of manufacturing, and all of which, in fact, are known to contain bugs...
So trust me."  At some point, debates over the "logical validity" of such
proofs begin to resemble arguments about how many angels can dance on the head of a pin.
</blockquote>
I also made a plot of the derivatives of these curves,
which is not shown because it is about 50 times less accurate.
Nevertheless, its accuracy <i>is</i> sufficient for confidence in (i), although
it still leaves room to doubt (ii) and (iii).
The plot also indicates all the smooth curves have 
|derivatives|&le;0.6 everywhere, which would imply that
at most 12 plot points suffice for a rigorous proof of our Main Result that
range is everywhere-superior to Borda.
(A line segment joining the regrets for "worst winner" and "best winner" would, in contrast, 
have slope&asymp;1.69.)
</li><li>
We could also conjecture based on the plot that all these curves are 
monotonically decreasing and concave-&cap;.
(This again, if true, ought to be provable mechanically using symbolic differentiation 
and interval arithmetic; but my low-accuracy plot of the derivatives of the curves was 
insufficient for
high confidence in these conjectures.)
</li></ol>
<a name="LazyMan"></a>
<p>
<b>Lazy man's interval arithmetic:</b>
The mechanical task, outlined above, of using closed formulas 
and interval arithmetic to prove the Main Result, is painful 
and philosophically debatable and so I did not do it.
The question then arose: was there some less-painful way to get the same effect (or nearly so)?
Here are some answers:
</p>
<ol>
<li>
Monte Carlo evaluation of regrets as described above using ordinary
finite-precision IEEE arithmetic
(as opposed to closed formulas using "interval arithmetic")
actually can yield <i>wholy rigorous</i> numbers 
<i>provided</i> the underlying random standard normal numbers
it inputs actually act sufficiently like truly random normals.
There are two reasons:
<ol type="a">
<li>
The random variables X whose expectation values
we evaluate using Monte Carlo integration all
have trivially
<i>bounded variance</i>, and indeed, more strongly, all
have trivial-to-bound expectation of exp(kX) for any fixed k.
This allows us to use &quot;<a href="#ProbBackgnd">Chernoff bounds</a>&quot;
to produce tight confidence intervals bracketing
the outputs of Monte Carlo,
with confidence <i>exponentially</i>
near 1 that
the interval contains the true value.
</li><li>
Each sampling of the random variable X, even if computed in finite-precision
arithmetic, is accurate because it consists purely of a multiplication of a
vector of random normals
by a constant matrix (and we know closed formulas for all matrix entries
and hence have used entries exact to 1 part
in 2<sup>53</sup>); even if every arithmetic
operation therein had rounding error in the <i>same</i> direction and all these errors were 
by the maximum possible amount, this could only shift the computed mean by 1 part 
in 10<sup>15</sup>. 
</li></ol>
<li>
In view of the above, we can say that all our tabulated 
Monte-Carlo results are accurate to 1 part in 
100, with confidence&gt;99.999999999999999999%.
</li><li>
There are only 3 ways our 
"lazy man's proof"
of our Main Result (based on plotting two curves)
could be wrong: 
<ol type="a">
<li>
Errors due to roundoff in finite-precision arithmetic,
</li><li>
Statistical errors due to use of Monte Carlo rather than analytic evaluation of integrals,
</li><li>
The curve might have a large |derivative|
in between two of our plot points, allowing it to exhibit a huge yet un-noticed "spike."
</li></ol>
We have shown that (a) and (b) can be dispensed with if we accept tiny
(exponentially tiny) failure probability and trust our source of randomness.
The only possible problem, then, is (c).
<p><p>
It might be possible to justify (c) with the aid of the following conjecture.
Each of our two plotted curves (Borda and Range)
are defined by two C-matrices, each of which has
bounded |entries|,
and determinant(CC<sup>T</sup>) bounded away from 0.
We may now consider replacing these two matrices
by the <i>worst possible</i> such matrix pair,
i.e. leading to a curve with the <i>maximum possible</i> |derivative|.
Here we can instead of taking derivatives with respect to the honesty-fraction F,
0&le;F&le;1, employ other variables such as &theta; where 2F=1+cos&theta; and 
0&le;&theta;&le;&pi;.
<!--I like the following variable R:
Consider a mixture of "magic best winner" with "magic worst winner" 
voting and let R be the regret of that mixture.
(It is easy to see the R&harr;F and &theta;&harr;F maps are each 1-to-1 so that these
are legitimate changes of variables.)
Then the derivative is constant and equal to -1, and furthermore this |derivative|
is clearly maximum possible <i>on average</I> although perhaps some other
regret curve might have a greater |derivative| at some one particular point.
I conjecture, however, that that cannot happen???
-->
I conjecture that with some appropriate  choice of variable the
worst possible matrix-pair arises from "magic best winner" and "magic worst winner."
If so, one could easily see that
using 1000 plot
points (which I did) would be more than sufficient to get a rigorous proof.
</li>
</ol>
<p>
In view of this, even though we admittedly have not undertaken the maximally-magnificent 
interval-arithmetic
calculation, we claim the cruder calculation we did do nevertheless would suffice
for full rigor <i>provided</i> we trust the random number generator, we
accept a "probabilistic proof" with a tiny and rigorously boundable failure probability,
and we accept or prove the above conjecture.
</p>
<blockquote>
<small>
Probabilistic proofs are well-accepted nowadays, e.g. the Atkin-Larson probabilistic 
primality test, which either proves an input number P is composite, or proves that <i>either</i>
P is prime <i>or</i> the used random bits were exceedingly unlucky (i.e. again we have
an exponentially tiny rigorously boundable failure probability).
</small>
</blockquote>
<p>
<b>In summary:</b> 
Despite these inadequacies,
for the purposes of political scientists rather than 
ultrapure mathematicians, the issue is already settled:
claims #1 and #2 i, ii, iii 
<i>are</I> true accurate to a part in a thousand.
So be happy.
</p><p>
Finally, we observe that the BRBH system, although it <i>is</i> better than range voting,
only is better if the percentage of honest voters exceeds about 91%.
Otherwise it is worse, and usually a lot worse.  91% is large enough that
I think there should be no doubt that, for <i>practical</i> purposes,
range voting is superior even to BRBH.   Range and especially approval voting are 
both good for honest voters <i>and</i>
comparatively insensitive to voter strategizing.
</p>

<!--
<p>
<b>THEOREM ???4:</b> <small>3-CANDDT APPROVAL IS SUPERIOR TO <i>EVERY</i>
RANK-ORDER-BALLOT VOTING SYSTEM
IF ENOUGH STRATEGIC VOTERS</small>:<br>
For 3-candidate elections with an
arbitrary F-parameterized mixture of strategic voters and
honest voters (same strategy model as in the preceding theorem) 
in the RNEM:
Approval Voting (where the voters approve candidates above mean candidate-utility)
is superior to the best possible rank-order-ballot based system
in that it has lower Bayesian Regret.   
This is true for every F (where F is the percentage of strategic voters)
from "about 1%" to 100%.   However, Borda is superior to Approval
with F=0, i.e. with 100% honest voters.
</p>
--Borda=184368 and 561662 for honest & strat;  Approval=185211 --
<p>
<b>Proof sketch:</b>
First of all, this can be verified by doing a computer simulation 
comparing Approval versus Borda in
3-candidate RNEM elections.???
</p><p>
FIRST CAVEAT: this is not really a "proof," it is a "computer simulation."
However, by running the computer long enough with genuine random numbers 
one gets arbitrarily high confidence it is true for that value of F.
Also I hope to evaluate all these numbers in closed form &ndash; techniques we shall discuss later
indicate this should be possible.
</p><p>
SECOND CAVEAT: I have not computed the crossover F precisely.  I called it "about 1%" but
that was a sloppy estimate.  One could and should nail it down with more computer work
and/or closed-form analytic evaluations.
We could probably throw out the computer and do everything analytically, but that'd be 
lots more work.  It probably is worth it to try because the numerical data actually makes me
suspect the limit crossover F is not 1%, but actually 0.
QED
</p>
<p>
???
</p>

<table>
<tr><th>#voters</th><th>Honest Regret Ratio</th><th>Strategic Regret Ratio</th></tr>
<tr><td>5</td><td bgcolor="aqua">1.10545</td><td bgcolor="pink">0.36974</td></tr>
<tr><td>10</td><td bgcolor="aqua">1.04487</td><td bgcolor="pink">0.32987</td></tr>
<tr><td>20</td><td bgcolor="aqua">1.02186</td><td bgcolor="pink">0.32894</td></tr>
<tr><td>50</td><td bgcolor="aqua">1.01247</td><td bgcolor="pink">0.32864</td></tr>
<tr><td>100</td><td bgcolor="aqua">1.00584</td><td bgcolor="pink">0.32944</td></tr>
<tr><td>200</td><td bgcolor="aqua">1.00457</td><td bgcolor="pink">0.32976</td></tr>
</table>
<p>
<b>Table:</b>
Approval/Borda regret ratios for 100% <font color="blue">honest</font>
and 100% <font color="red">strategic</font>
voters in 3-candidate
RNEM, from Monte Carlo experiments by Smith 2000.  
Approval is a superior voting system to Borda when
the regret ratio is below 1.
</p>
--
Fp := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);   

integrate( integrate( integrate(  
Fp(x)*Fp(y)*Fp(z) * z, y=x..z), z=x..infinity), x=-infinity..infinity);
= 1/(4*sqrt(Pi)) = 0.1410473959

integrate( integrate( integrate(  
Fp(x)*Fp(y)*Fp(z) * y, y=x/2+z/2..z), z=x..infinity), x=-infinity..infinity);
= (sqrt(3)/6-1/4)/sqrt(Pi) = 0.0218201081

6*integrate( integrate( integrate(  
Fp(x)*Fp(y)*Fp(z) * (x+y), y=x..z), z=x..infinity), x=-infinity..infinity);
= -3/(2*sqrt(Pi)) = -0.8462843754

6*integrate( integrate( integrate(  
Fp(x)*Fp(y)*Fp(z) * (x+z)/2, y=x/2+z/2..z), z=x..infinity), x=-infinity..infinity);
= -0.06546032424
= -2/(sqrt(Pi)*(15+sqrt(5)))  ???
= -0.06546615900 ?

integrate( integrate( integrate(  
Fp(x)*Fp(y)*Fp(z) * (x+z)/2, y=x/2+z/2..z), z=-infinity..infinity), x=-infinity..infinity);
= -0.02182010808
= ???  what is this?


integrate( integrate( integrate(  
Fp(x)*Fp(y)*Fp(z) * y, y=x/2+z/2..infinity), z=-infinity..infinity), x=-infinity..infinity);
= 1/sqrt(3*Pi) = 0.3257350080

--

<pre>
THEOREM 5: 3-CANDDT RANGE VOTING IS SUPERIOR TO EVERY RANK-ORDER-BALLOT VOTING SYSTEM:
For 3-candidate elections with a arbitrary F-parameterized mixture of strategic voters and
honest voters (same strategy model as before) in the RNEM:
Range Voting (where the voters rate the best candidate 1, the worst 0, and the other
linearly interpolated between according to its utility; this is for honest voters;
for strategic range voters give them all 0s and 1s and give 1s to the
candidates above mean candidate-utility) is superior to the best possible rank-order-ballot 
based system in that it has lower Bayesian Regret.   
This is true for every F (where F is the percentage of strategic voters)
from 0% to 100% inclusive.  

PROOF SKETCH:
Computer simulation comparing Range versus Borda in
3-candidate random normal utilities elections.
SAME CAVEAT as the preceding proof's first caveat.
QED
</pre>

<table>
<tr><th>#voters</th><th>Honest Regret Ratio</th><th>Strategic Regret Ratio</th></tr>
<tr><td>5</td><td bgcolor="aqua">0.70129</td><td bgcolor="pink">0.36974</td></tr>
<tr><td>10</td><td bgcolor="aqua">0.71741</td><td bgcolor="pink">0.32987</td></tr>
<tr><td>20</td><td bgcolor="aqua">0.73045</td><td bgcolor="pink">0.32894</td></tr>
<tr><td>50</td><td bgcolor="aqua">0.74075</td><td bgcolor="pink">0.32864</td></tr>
<tr><td>100</td><td bgcolor="aqua">0.74325</td><td bgcolor="pink">0.32944</td></tr>
<tr><td>200</td><td bgcolor="aqua">0.74461</td><td bgcolor="pink">0.32976</td></tr>
</table>
<p>
<b>Table:</b>
Range/Borda regret ratios
for 100% <font color="blue">honest</font>
and 100% <font color="red">strategic</font>
voters in 3-candidate
RNEM, from Monte Carlo experiments by Smith 2000.  
In the limit of an infinite number of voters V
it follows from the central limit theorem that 
the regrets both scale proportionally to V<sup>1/2</sup> and hence the regret ratio
approaches a positive limit.  
This data makes it plausible that the honest-voters limit is 3/4 but
that remains to be proven.  (The Gaussian-based approach described last table also works
to compute the limit regrets to arbitrary accuracy.)
Range is a better voting system than Borda when the
regret ratio is below 1.
</p><p>
MORE??? compute limits numbers.
</p>

<pre>
DISCUSSION:
The same stuff also proves Range is superior in this model
to every rank-order ballot system with
rank equalities <i>permitted</i> for honest voters
(because rank equalities occur 0% of the time in our models for honest voters).
However, it remains entirely possible at present that some rank-order-with-equalities 
voting system is superior to approval/range voting for strategic voters... you'd then
have to define what "strategic voter" meant, but we could use the same kind
of voter as our approval voters in theorem 4... so then...

What is the best rank-order-ballot based voting system (rank-equalities
permitted) in the random-normal utilities model?
There are only 4 possible strategic votes:  A=B&gt;C, A&gt;B=C, C=B&gt;A, C&gt;B=A.
For each of these votes, the best system gives A, B, and C their
expected-utility (conditioned on that being the strategic vote) scores
and the highest summed-score wins.  That is 12 weights that need to be
determined, but due to even-symmetry and candidate-renaming symmetry
it is really only 3 weights because all 4 vote types "really" are
the "same" type.  And since neither an overall multiplicative nor
additive scaling of the weights change anything, and since the voting system is not 
allowed to know who "B" is, i.e. who the frontrunners are,
everything really is determined by only 1 weight, so really 

THEOREM 6: 3-CANDDT APPROVAL VOTING IS BEST RANK-ORDER SYSTEM FOR STRAT VOTERS
For 3-candidate elections in a random even-symmetric
utilities model: Approval voting is the best of all
possible rank-order-ballot <i>with rank-equalities permitted</i>
fair voting systems ("best" meaning lowest Bayesian regret, and "fair" meaning
renaming the candidates does not alter the winner), assuming
100% strategic voters who each use the same strategy as the strategic approvers
in theorem 4.

THEOREM 7: 3-CANDDT RANGE VOTING IS SUPERIOR TO EVERY RANK-ORDER-BALLOT (EQs PERMITTED) VOTING SYSTEM:
For 3-candidate elections with a arbitrary F-parameterized mixture of strategic voters and
honest voters (same strategy model as before) in the RNEM:
Range Voting (where the voters rate the best candidate 1, the worst 0, and the other
linearly interpolated between according to its utility; this is for honest voters;
for strategic range voters give them all 0s and 1s and give 1s to the candidates 
above mean candidate-utility) is superior to the best possible fair rank-order-ballot 
based system <i>with rank-equalities permitted</i> in that it has lower Bayesian Regret.   
This is assuming the strategic voters always rank the frontrunners top and bottom
and the other candidate is rated equal to one of them according to whether it
above or below mean utility for the three candidates.
And this is true for every F (where F is the percentage of strategic voters)
with 0&le;F&lt;100%.

PROOF SKETCH:
Computer simulation comparing Range versus Approval and Borda 
(actually only honest-voter Range V Borda is needed because strategic range voters and 
strategic approval voters are the same thing so that part cancels out).
SAME CAVEAT as the theorem 4's proof's first caveat, but there is only one F, namely F=0,
we actually need to simulate, so this is very certain and the computer could clearly be
dispensed with.
QED

</pre>

<hr>
-->

<a name="Sec82"></a>
<h3>8.2. What is the true dimensionality?</h3>
<p>
When considering computing "regrets" and "wrong-winner probabilities" from
our 3&times;6 C-matrices, there are 6 hyperplanes that matter
in the 6-dimensional space of vectors u.  Their equations are:
<center>
v<sub>k</sub>=v<sub>j</sub>
&nbsp;&nbsp; and &nbsp;&nbsp;
u<sub>k</sub>=u<sub>j</sub>
</center>
for (j,k)=(1,2), (2,3), and (1,3).
</p>
More generally, if we had N candidates with perhaps N&ne;3, then
these would be (N-1)N/2 hyperplanes and the C-matrices would be 
N&times;(2N).
<p>
<p>
These hyperplanes define a polytopal cone in the 2N-dimensional space
of vectors u (since the vote-vector v can be regarded as
a linear function of u inside the Monte-Carlo integration
<a href="#MonteCarloPsuCode">procedure</a> from section 7).  
In fact, however, this cone is divisible into
(N-1)N interior-disjoint
<i>simplicial</i> cones, each defined by only 2(N-1) hyperplanes.
Namely, in our case N=3, a typical simplex is
<center>
v<sub>1</sub>&ge;v<sub>2</sub>,
&nbsp;
v<sub>1</sub>&ge;v<sub>3</sub>,
&nbsp;
u<sub>2</sub>&ge;u<sub>3</sub>,
&nbsp;
u<sub>2</sub>&ge;u<sub>1</sub>,
</center>
defining the region where candidate 1 wins the election but candidate 2 is
the best (i.e. maximum-utility)
candidate, and the other five simplicial cones
have (1,3), (2,3), (2,1), (3,1), (3,2) respectively in place of (1,2).
Since this simplex is defined by <i>four</i> face-planes, it in fact
corresponds (if we restrict attention to the <i>surface</i> of the sphere of
unit-norm vectors u)
to a nonEuclidean <i>tetrahedron</i>.
This really has only <i>three</i>-dimensional nonEuclidean volume,
computable in terms of dilogarithms using the Murakami-Yano
formula from <a href="#AppC">appendix C</a>, <i>not</i> 5-dimensional
(which would have required trilogarithms).
See the <a href="#DimRed">dimension reduction principle</a> in 
section 3 of <a href="#AppC">appendix C</a>.
</p><p>
As an immediate consequence,
therefore, we see that all the "wrong-winner probabilities" arising
from 3&times;6 C-matrices can be
expressed using dilogs without need of trilogs.
<p></p>
Furthermore, the integration to find the <i>regrets</I> is over the
same disjoint union of simplicial cones, but instead of the integrand
being a constant it is now a pure-linear function within each simplex
(namely proportional to
u<sub>2</sub>-u<sub>1</sub> in the "typical tetrahedron" above).
This integral may be done (using the methods in
<a href="#AppC">appendix C</a>)
using only <i>arctrig</i> without needing dilogs!
</p><p>
More generally, for N candidates, using C-matrices that are
N&times;2N, we have
</p>
<a name="Thm18"></a>
<p>
<b>THEOREM 18 (dimensionality below what one might think):</b>
In N-candidate RNEM elections where our correlation-based 
<a href="#ProcReg">procedure</a> is applicable
to find regrets, those regrets are expressible as a sum of (N-1)N
noneuclidean simplex (2N-4)-curved-dimensional volumes
(i.e. Schl&auml;fli functions S<sub>2N-3</sub>), each corresponding to a region where
"j wins but k was the max-utility candidate";
and the wrong-winner probabilities are expressible as a
sum of (N-1)N
noneuclidean simplex (2N-3)-curved-dimensional volumes,
i.e. Schl&auml;fli functions S<sub>2N-2</sub> in
the notation of <a href="#AppC">appendix C</a>.
</p>
<p>
<b>The dihedral angles</b>
between the just-discussed hyperplanes (ignoring 90&deg; dihedrals, and where the reader 
is warned that angles &theta; would have to be replaced by the supplementary
angles &pi;-&theta; if the other 
side of one hyperplane is regarded as the "inside")
are:
<ul>
<li>
&pi;/4
&nbsp; 
(e.g. between the 
u<sub>1</sub>=u<sub>2</sub> and
u<sub>1</sub>=u<sub>3</sub> hyperplanes)
</li><li>
<pre>
       [C<sub>a</sub>-C<sub>b</sub>]&middot;[C<sub>j</sub>-C<sub>k</sub>]
arccos(--------------)
       |C<sub>a</sub>-C<sub>b</sub>|&middot;|C<sub>j</sub>-C<sub>k</sub>|
</pre>
(between the 
v<sub>a</sub>=v<sub>b</sub> and
v<sub>j</sub>=v<sub>k</sub> hyperplanes, where C<sub>r</sub>
denotes the <i>r</i>th row of C)
</li><li>
<pre>
       [C<sub>a</sub>-C<sub>b</sub>]<sub>j</sub> - [C<sub>a</sub>-C<sub>b</sub>]<sub>k</sub>
arccos(------------------)
           |C<sub>a</sub>-C<sub>b</sub>|  &radic;2
</pre>
(between the 
v<sub>a</sub>=v<sub>b</sub> and
u<sub>j</sub>=u<sub>k</sub> hyperplanes).
</li></ul>

<blockquote>
<b>References for Section 8:</b>
<br>
G.Alefeld &amp; J.Herzberger: Introduction to Interval Computations,
Academic Press, 1983.
<br>
A.O.L. Atkin &amp; R.G. Larson: On a primality test of Solovay and
Strassen, SIAM J. Comput. 11,4 (1982) 789-791.
<br>
Andreas Griewank:
Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. SIAM
(Frontiers in Applied Mathematics #19)  2000.
<br>
R. Hammer, M. Hocks, U. Kulisch, D. Ratz:
Numerical Toolbox for Verified Computing I: With Algorithms and Pascal-XSC Programs, Springer-Verlag, Berlin, 1994.
<br>
T.Hagerup &amp; C.R&uuml;b:
A guided tour of Chernoff bounds, Information Processing Letters 33,6 (1990) 305-308.
<br>
Eldon Hansen &amp; G. William Walster: Global Optimization using Interval Analysis (2nd ed.)
Marcel Dekker, New York, 2004.
<br>
Ramon E. Moore: Interval Analysis, Prentice Hall, Englewood Cliffs, N.J., 1966.
<br>
Ramon E. Moore: Methods and Applications of Interval Analysis, SIAM, Philadelphia PA 1979.
<br>
Miodrag S. &amp; Ljiljana D. Petkovic: Complex Interval Arithmetic and Its Applications. Berlin: Wiley, 1998.
<br>
Louis B. Rall:
Automatic Differentiation: Techniques and Applications,
Springer (Lecture Notes in Computer Science #120) 1981.
</blockquote>

<a name="Sec9"></a>
<h3>9. Discussion and open problems</h3>


<h3>9.1 About the number of angels that can dance on the head of a pin </h3>

<blockquote>
<i>
The mathematician awoke and saw there was a fire.
He ran over to his desk, began working through theorems,
lemmas, and hypotheses, and after a few minutes, put down
his pencil and exclaimed triumphantly "I have reduced the matter
to previously solved problems, thus <i>proving</i>
that I can extinguish the fire!"
He then went back to sleep.
</i>
</blockquote>

<p>
This paper's accomplishment somewhat resembles the above joke.
For 3-candidate voting systems in the RNEM, we have by plotting two curves
demonstrated that range voting is superior (measured by Bayesian Regret)
to the best rank-order voting system, for either honest or strategic voters,
or any mixture (and approval voting also is thus-superior, 
except at 100% honesty where it 
equals but does not better Borda).
<i>But</i>, strictly speaking, this was <i>not</i> a proof, because
it does not exclude the possibility that through some miracle-conspiracy
of arithmetic roundoff errors, or some miraculous incredibly sharp and high
spike in one of the plotted curves, that the lower-regret
curve might somehow manage to avoid being lower everywhere.
</p>
<p>
However, like the mathematician in the joke, we have proven that fire can
be extinguished.   Specifically:
</p>
<ol>
<li>
We have demonstrated that both curves have closed formulas,
</li><li>
We have explained how well known standard techniques of "interval arithmetic"
can be used, in conjunction with those formulas, to get a fully
rigorous, albeit computer aided, proof.
</li><li>
But I then "went back to sleep" without actually <i>doing</i> that final step
(which is not trivial because the formulas are long).
I did, however, <i>partially</i> do the job (see the
"<a href="#LazyMan">lazy man's</a>" discussion in section 8)
by arguing that even without interval arithmetic and closed formulas, the
curve-plotting
calculation we did <i>still</i> constitutes a rigorous "probabilistic proof" with extremely tiny
error probability, provided our random numbers are random and provided
a certain conjecture about derivative bounds holds.
</li></ol>
<p>
It would probably be possible for a 
graduate student to now do the final step in
about 1-10 weeks of computer programming and debugging.
However, one has to ask whether it would really be worth that effort,
see 
"<a href="#PhiloNote">philosophical note</a>" in section 8.
</p>

<h3>9.2. About Bayesian regret</h3>

<p>
I have been asked <i>why</i> I claim that Bayesian Regret is the only correct way to
objectively measure voting system quality.
I'm tempted just to respond that statisticians over 200 years have pretty much come to a 
consensus that Bayesianism is the unique philosophically correct approach to statistics
and objectively comparing the quality of different statistical estimators generally, 
and so ask them, not me.  (See Jaynes 2003, Sivia-Skilling 2006, Robert 2001,
Berger 1993.)
I also could respond that Bordley and Merrill both independently invented the 
Bayesian-Regret framework for comparative evaluation of <i>voting systems</i> (and before me), 
so again, ask them, not me. 
This argument was fought, and won, long ago, with a strong majority
consensus being reached in every scientific area <i>except</i> 
economics, where 
(for obscure <!--and self-contradictory--> historical reasons)  
holdouts against the whole notion of "utilities"
still are frequently encountered even 
in the 21st century.
</p>
<p>
For a somewhat deeper response, aimed 
particularly at those people, see
<a href="../../OmoUtil.html">http://rangevoting.org/OmoUtil.html</a>
<!--MAKE THIS WEB PAGE INTO A PAPER &amp; CITE IT???-->
</p>

<h3>9.3. About the RNEM and its realism or lack thereof </h3>

<p>
Our Bayesian Regret framwork and overarching technique for determining "best voting systems"
in no way depend on the RNEM.  
Anybody who prefers a different and more-realistic model of voters is free to use it
instead.  (Our 1999-2000 computer results indeed <i>did</I> employ
many other models and the superiority of range voting over all the rank-order-ballot
based competitors tried, was very robust across models; and the follow-up paper "part III"
will be able to make some rigorous statements about regrets in certain other 
interesting models.)
</p>
<p>
I did not use the RNEM because of a delusion it was a highly-realistic model of
elections.  The two most important ways it is unrealistic are:
<ol>
<li>
In many political scenarios, the opinions of voters about candidate C
are <i>correlated</i> with their opinions about A and B;
</li><li>
or the voters exhibit a large statistical <i>bias</i> favoring A over B
&ndash;
</li>
</ol>
either way directly contradicting,
and revealing the unrealism of, the RNEM. 
"1-dimensional politics" (or 2D) models are more realistic in the former respect.
The "Dirichlet model" 
where (in 3-candidate elections with rank-order ballots) the 3!=6 kinds
of vote totals are assumed to be uniformly distributed on the 5-dimensional simplex
</p>
<center>
x<sub>1</sub>&ge;0,
&nbsp;&nbsp;
...,
&nbsp;&nbsp;
x<sub>6</sub>&ge;0,
&nbsp;&nbsp;
&sum;<sub>1&le;j&le;6</sub>x<sub>j</sub>=1,
</center>
<p>
is more realistic in the latter respect.
The reasons this paper focused on the RNEM are that it is
</p>
<ol>
<li>
mildly realistic, and 
</li><li>
simple enough so that I could obtain closed formulas.
</li></ol>
<p>
The so-called "impartial culture" (IC) is the degenerate case of the RNEM
arising from specializing to rank-order-ballot voting systems.
(IC is:
all candidate-orderings equally likely by each voter independently.)
It has been heavily studied by many political-science authors.
Despite IC's unreality, 
my personal experience is that the probabilities 
predicted by the IC model
for various kinds
of voting pathologies, <i>usually</i> agree tolerably respectably with
attempts to measure frequencies
of those pathologies in real life (where note that such real-life measurements usually 
are difficult, debatable, and noisy); see table 3.
</p>
<a name="ICvDMtab"></a>
<table border="1" bgcolor="lightgreen">
<caption>
<b>Table 3:</b> 
Impartial Culture and Dirichlet Model calculations versus real life.
</caption>
<tr><th>Phenomenon</th><th>IC Probability</th><th>DM Prob'y</th><th>Approximate frequency in real life</th></tr>
<tr><td>3-canddt IRV is nonmonotonic</td><td>(14.7=12.2+2.47)% (two disjoint kinds of nonmonotonicity)</td><td>(3.22=2.17+1.05)%</td><td>About 20% based on the 
<a href="../../LAgovs.html">9 Louisiana governor elections</a> 1995-2007</td></tr>
<tr><td>In 4-canddt Condorcet elections, adding new bloc of co-voting voters makes election result worse for them</td><td>Roughly (0.5 to 5)% depending on Condorcet flavor</td><td align="middle">?</td><td align="middle">?</td></tr>
<tr><td>3-canddt IRV eliminates a Condorcet Winner</td><td>3.71%</td><td align="middle">3.23%</td><td>Apparently 9 CWs eliminated in the 150 federal IRV elections in <a href="https://rangevoting.org/WarrenSmithPages/homepage/Aus07.html">Australia 2007</a>.   
(But in "1-dimensional politics" models this phenomenon is more like 25-33% common.)
</td></tr>
<tr><td>3-canddt plurality voting winner same as "plurality loser"</td><td>16.4%</td><td align="middle">9.25%</td><td>Seems in right ballpark</td></tr>
<tr><td>3-canddt IRV voting winner same as "IRV loser"</td><td>&asymp;2.5%</td><td align="middle">1.7%</td><td align="middle">?</td></tr>
<tr><td>3-canddt IRV elections where adding new co-voting bloc causes election winner to worsen in their view</td><td>16.2%</td><td align="middle">7.4%</td><td>Apparently about 40% based on the <a href="../../LAgovs.html">9 Louisiana governor elections</a></td></tr>
<tr><td>3-canddt IRV voting "favorite betrayal" situation where 
a bloc of co-voting C voters can improve election winner in their view by <i>not</i> voting 
their favorite C top (does not count nonmonotone situations where this makes C win)</td><td><nobr>arctan(2<sup>-1/2</sup>)/&pi;</nobr>&asymp;19.59%</td><td align="middle">20.2%</td><td>
Apparently about 40% based on the <a href="../../LAgovs.html">9 Louisiana governor elections</a></td></tr>
<tr bgcolor="pink"><td>3-canddt election features Condorcet cycle</td><td>[3arcsec(3)-&pi;]/(2&pi;)&asymp;8.78% <br>
(Guilbaud 1952 in footnote; see also Gehrlein 2006)</td><td align="middle">1/16=6.25%</td><td>About 1% 
(Tideman 2006's theoretical extrapolation from real-life data);
some models of "1-dimensional politics" predict 0%</td>
</tr><tr>
<tr bgcolor="pink"><td>"Majority-top winner" exists in 3-canddt election</td><td>0</td><td align="middle">9/16=56.25%</td>
<td>Happened for 50% of Australian federal IRV seats in 2007 election and 44% of the <a href="../../LAgovs.html">9 Louisiana governor elections</a>.</td></tr>
</table>

<!--
Australia electoral commission claims 75 of the 150 house seats decided "on first preferences";
other 75 decided "on preferences".
http://results.aec.gov.au/13745/Website/Downloads/HouseSeatsDecidedOnFirstPrefsDownload-13745.txt
http://results.aec.gov.au/13745/Website/Downloads/HouseSeatsDecidedOnPrefsDownload-13745.txt
29 sept 2008.

LAgovs 40%
winner same as IRV loser</td><td>(2.47&plusmn;0.14)%</td><td align="middle">?</td></tr>

.  Examples???
http://rangevoting.org/RandElect.html
 IRV nonmono prob  Monotone.html  14.7=12.2+2.47%
LAgovs 20%

 cond cycle 3canddts        CondorcetCycles.html   Tideman says 1%
(3*arccos(1/3)-pi) / (2*pi) = 8.78%  Guilbaud, puzz7
stated without proof in a footnote of
G.Th.Guilbaud [Economie Apliquee 5 (1952) 501-584].
Tideman, Nicolaus: Collective Decisions and Voting: The Potential for Public Choice, Ashgate 2006

Call an election situation a "participation failure scenario"
if there exists a vote Q, such that adding some number T>0 of
honest Q-voters, will cause the election result to worsen in their view.
P=prob of such a situation in Condorcet 4-candt... depnds which C.method...
For two particular Condorcet methods, I estimated P by monte-carlo
and it is safe to say 0.5% < P < 5% and my best guess is 2.5%.
(My program does not compute P exactly, it only finds high-confidence
bounds on it. If I were less lazy I could tighten the bounds...)

 Peru puzz17    3.71%  CW elimd 1st IRV round 3-canddts
28% in LAgovs
9 out of 150 in Aus07
peru, chile, france
However in "1-dimensional" politics it is more like 25-33% common.

  plur elects plur-loser canddt 3canddt puzz24  16.4%

IRV reversal failure (winner=loser)  (2.47 +- 0.14)%

 every wtpos agrees but CW exists and is different puzz46 3candt  1.808
Vincent Merlin, Maria Tataru, Fabrice Valognes: On the likelihood of Condorcet's profiles, Social Choice & Welfare 19,1 (2002) 193-206

   IRV 3candt elctns where adding extra voters of 1type will cause winner to worsen  16.2% pz55
LAgovs noshow 40%
Depankar Ray: 
On the practical possibility of a "no show paradox" under the single transferable vote, 
Math'l Social Sciences 11,2 (1986) 183-189. 
Ray found that in situations where the IRV and plain-plurality winner differ, then 
(under very mild probabilistic assumptions) the probability of this happening was exactly 50%

FBLE situtation in IRV
http://www.rangevoting.org/IRVStratPf.html
arctan( 1/sqrt(2) ) / pi = 19.59%
LAgovs 40%

majority winner exists   prob=0   44% in LAgovs, numerous Aus07
-->

<p>
The IC estimates in the top part of the table seem to be working reasonably well, in
particular as well or better than the Dirichlet model,
but 
the bottom two lines disagree noticeably with reality.
Regenwetter et al explain, in chapter 1 of their book,
theoretical reasons why IC would be
expected to <i>maximally</i> overestimate
the probability of "Condorcet cycles" in 3-candidate elections.
And indeed the IC theoretical prediction 8.78% 
is a large overestimate of the real-life rate of approximately 1% (albeit
Condorcet cycles seem fairly common in <i>legislative</i> votes since they are
intentionally created as part of "poison pill" legislative tactics).
Even worse, "majority-top winners" occur <i>zero</i> percent of the time in IC
3-candidate elections in the V&rarr;&infin; limit but actually are quite common
in real life.  The "Dirichlet model"
predicts 56.25%.
</p>

<h3>9.4. Questions for future work</h3>

<p>
The reader may ask "why have you only focused on <i>3-candidate</i> elections?
What about 4, 5, and 6?"
The answer is that the techniques in this paper will easily permit 
the reader to calculate the honest-voter regrets to, say, 4-digit accuracy and
thus produce a convincing non-proof that range voting is superior
to the best rank-order system, with honest voters,
for those numbers N of candidates also.
This is done in the follow-up paper <a href="Best4.html">Part II</a>.
</p><p>
I focused on the 3-candidate case here because it
is  <i>specially</i> nice
because closed formulas exist and hence
this non-proof can be converted into a genuine proof.  
(Also, of course, 3 is the simplest and most important nontrivial number.)
We know from <a href="#Sec82">section 8.2</a>
that closed formulas involving dilogs will also be attainable
for 4-candidate regrets.
</p>
<p>
An obvious question is to determine more closed formulas.
The reader should, with enough work, be able to use our techniques to write down closed
formulas for all the regrets and wrong-winner probabilities in the
<a href="#BigResultsTable">big results table</a>, as well as extending that table to cover 
4-candidate elections.  The key word is "enough" work, and a question is whether those
formulas can be simplified sufficiently that they become attractive.   
These questions are more of <i>aesthetic</i> than genuine interest &ndash; just 
knowing the answer accurate to 3 digits seems good enough for any political science purpose,
so trying for a beautiful exact formula has no objective importance.
Because I <i>am</i> a mathematical
aesthete, though, I apologize that I have not found as many such
formulas as I should.
Anybody expert with symbolic manipulation systems ought to be able to
find more than I.
</p><p>
Some problems of more general and genuine interest are
to develop automated techniques for simplifying
formulas involving dilogarithms, and to understand whether and when Schl&auml;fli
functions in N dimensions can be expressed in terms of nice 1-dimensional functions
(see <a href="#AppC">appendix C</a>).
</p>
<p>
Another question: "what about voting systems where the 'votes' are something 
<i>other</i> than pure rank-orderings
of the candidates, or other than numerical ratings?"
As a concrete example of such a voting system (suggested by Ivan Ryan),
consider Condorcet voting
but the votes are not plain rank-orderings &ndash; voters also
are allowed to employ one ">>" in the order, for example
<center>
Obama &gt; Gore &gt; Nader &gt;&gt; McCain &gt; Kerry &gt; Bush.
</center>
Then Ryan's proposal was that any A&gt;B relationship on a ballot which
included a "&gt;&gt;" somewhere in the path, should count as 2 votes.
(Or your favorite constant in place of "2"; this could be tuned to
optimize performance.)
</p><p>
Then the pairwise table is computed as per the usual Condorcet
prescription and we attempt to find a Condorcet winner as usual.
</p><p>
This allows a voter to express (to some degree anyway)
"strength of preference." Also, because it moves <i>outside</I> of
the usual "pure rank order" framework by allowing a more general
kind of vote, it <i>evades</i> our mathematical results 
indicating that range voting is superior regret-wise
to every rank-order system.
</p><p>
Our mathematical techniques still would allow analysing
voting systems with this kind of "one-&gt;&gt;" ballot and finding the best
such system and its regret.
Perhaps range voting still would
be superior to the best such system, but future investigators will have to
do that analysis.
</p><p>
Another question is: "what about other statistical/political
models besides RNEM (such as D-dimensional
politics models, etc)?"  Can future authors prove analogous results to ours
in those models?  With the help of some fortuitous miracles we <i>are</i>
able to accomplish that in some cases. 
That will be explained in the follow-up paper "<a href="BestVot2.html">part III</a>."
</p>
<blockquote>
<b>References for section 9:</b>
<br>
James O. Berger: 
Statistical Decision Theory and Bayesian Analysis 
2nd ed. Springer (Series in Statistics) 1993.
<br>
William V. Gehrlein:
Condorcet's paradox,
Springer 2006.
<br>
G.Th.Guilbaud: Les th&eacute;ories de l'int&eacute;r&ecirc;t g&eacute;n&eacute;ral 
et le probl&egrave;me logique de l'agr&eacute;gation,
Economie Apliqu&eacute;e 5,4 (1952) 501-584.
<br>
E.T. Jaynes: Probability theory: The logic of science,
Cambridge Univ. Press 2003.
<br>
M.Regenwetter, B.Grofman, A.A.J.Marley, I.M.Tsetlin:
Behavioral social choice: probabilistic models, statistical inference,
and applications,
Cambridge University Press, New York 2006.
<br>
Christian P. Robert:
The Bayesian choice: From decision-theoretic foundations to computational implementation,
Springer (texts in statistics) 2001.
<!--
J.M.Bernardo &amp; M.F.A.Smith: Bayesian theory. New York: Wiley 1994.
G.E.P.Box &amp; G.C.Tiao: Bayesian inference in statistical analysis. New York: Wiley 1992.
-->
<br>
Devinderjit Sivia &amp; John Skilling: Data Analysis: A Bayesian Tutorial,
Oxford University Press (2nd edition 2006).
<br>
Nicolaus Tideman:  
Collective Decisions and Voting: The Potential for Public Choice, Ashgate 2006.
</blockquote>


<!--
<a name="Sec10"></a>
<h3>10. What about elections with more than 3 candidates? And other models?
</h3>
--
By Warren D. Smith, 20-21 June 2008.
--

<pre>
Other election models can be considered too, besides the issue-based politics
and random normal models.  I have no doubt the same results will
be true in at least some of them, and for the same reasons.

In general in models like those above, we can prove that the best rank-order-ballot-based
system (with rank-equalities forbidden) <i>must</i> be a weighted positional voting system.
Specifically the weights are W<sub>1</sub>, W<sub>2</sub>, ..., W<sub>N</sub>
for an N-candidate race where W<sub>k</sub> is the
expected utility of the <i>k</i>th-best candidate for a random voter.
CAREFUL, THIS  OFTEN BOGUS???
</pre>

--
with(stats):
for N from 3 to 10 do
   y := sort( [ stats[random, normald](N) ] ):
   for k from 2 to 40000 do
      x := sort( [ stats[random, normald](N) ] );
      y := y + x;
   od;
   y := y / 40000:
   print(N, evalf(y, 4));
od;

Results from random normal model:
10000-sample run:
                         3, [-0.8435015244, -0.005643251296, 0.8468056946]
                    4, [-1.029696652, -0.2983848534, 0.3041718281, 1.040994521]
           5, [-1.164694728, -0.5044303025, -0.005263151495, 0.4862245713, 1.161547529]
     6, [-1.277552730, -0.6451086575, -0.1965332406, 0.1992849090, 0.6378668106, 1.257374577]
7, [-1.359792102, -0.7550846720, -0.3498077757, -0.001100318596, 0.3517360673, 0.7581743349,    1.348063182]
8, [-1.423842042, -0.8518880361, -0.4743257838, -0.1553271625, 0.1496571433, 0.4709590369,
    0.8474863979, 1.415086175]
9, [-1.482666492, -0.9312512718, -0.5701739307, -0.2711039819, -0.003391509098, 0.2726041426,
    0.5722858484, 0.9295712383, 1.473779932]
10, [-1.539372418, -1.001930305, -0.6547443535, -0.3758132485, -0.1225124276, 0.1223486260,
    0.3727856661, 0.6524572114, 0.9970468452, 1.541727816]

20000-sample run:
                                   3, [-0.853, 0.0, 0.840]
                                  4, [-1.04, -0.297, 0.301, 1.03]
                             5, [-1.17, -0.500, 0.0, 0.488, 1.16]
                          6, [-1.27, -0.639, -0.201, 0.205, 0.646, 1.26]

40000-sample run:
  3, [-0.84, -0.00081, 0.84]
  4, [-1.03, -0.30, 0.30, 1.04]
  5, [-1.16, -0.50, 0.0, 0.49, 1.16]
  6, [-1.27, -0.64, -0.20, 0.20, 0.64, 1.27]
  7, [-1.35, -0.76, -0.35, 0.0, 0.35, 0.76, 1.35]
  8, [-1.425, -0.853, -0.474, -0.153, 0.152, 0.472, 0.853, 1.424]
  9, [-1.487, -0.93, -0.57, -0.27, 0.0, 0.27, 0.57, 0.93, 1.481]
  10, [-1.54, -1.00, -0.66, -0.38, -0.12, 0.12, 0.38, 0.66, 1.00, 1.54]

hi-precision numerical integration:
  "n=", 3
   0.8462843752, 0, -0.8462843752
exact value = &pi;<sup>-1/2</sup>3/2

  "n=", 4
1.029375373   0.2970113822   -0.2970113822   -1.029375373
hi-precision: 1.029375373003964132056987 and 0.2970113822746453255175167

  "n=", 5
1.162964474   0.4950189704  0.    -0.4950189704   -1.162964474
hi-precision: 1.162964473640519612772268 and 0.4950189704577422091958612

  "n=", 6
1.267206361   0.6417550389   0.2015468338   -0.2015468338   -0.6417550389   -1.267206361

  "n=", 7
1.352178376   0.7573742707   0.3527069592  0.   -0.3527069592   -0.7573742707   -1.352178376

  "n=", 8
1.423600306   0.8522248627   0.4728224950   0.1525143995   -0.1525143995   -0.4728224950   -0.8522248627   -1.423600306

  "n=", 9
1.485013162   0.9322974569   0.5719707829   0.2745259191  0.   -0.2745259191   -0.5719707829   -0.9322974569   -1.485013162

 "n=", 10
1.538752731 1.001357044   0.6560591054   0.3757646970   0.1226677523   -0.1226677523   -0.3757646970   -0.6560591054   -1.001357044   -1.538752731
--
<table>
<caption>
<b>Table:</b>
The best (regret minimizing) rank-order voting systems for 
N-candidate elections (N=2,3,4,...,10), with 100% honest voters
in the random normal utilities model, are the
weighted-positional systems with these weights
(from numerical integration and confirmed to &plusmn;0.01 accuracy via 40000 Monte Carlo runs) &ndash;
Wk is the expectation value of the <i>k</i>th greatest of N sorted standard normal deviates:
</caption>
<tr><th>N</th><th>Weights W<sub>N</sub>,...,  W<sub>2</sub>, W<sub>1</sub></th></tr>
<tr><td>2</td><td align="center" bgcolor="aqua">-0.56419, 0.56419 (Plurality)</td></tr>
<tr><td>3</td><td align="center" bgcolor="aqua">-0.84628, 0, 0.84628 (Borda)</td></tr>
<tr><td>4</td><td align="center" bgcolor="aqua">-1.02938, -0.29701, 0.29701, 1.02938</td></tr>
<tr><td>5</td><td align="center" bgcolor="aqua">-1.16296, -0.49502, 0, 0.49502, 1.16296</td></tr>
<tr><td>6</td><td align="center" bgcolor="aqua">-1.26721, -0.64176, -0.20155, 0.20155, 0.64176, 1.26721</td></tr>
<tr><td>7</td><td align="center" bgcolor="aqua">-1.35218, -0.75737, -0.35271, 0, 0.35271, 0.75737, 1.35218</td></tr>
<tr><td>8</td><td align="center" bgcolor="aqua">sym, 0.15251, 0.47282, 0.85222, 1.42360</td></tr>
<tr><td>9</td><td align="center" bgcolor="aqua">sym, 0, 0.275453, 0.57197, 0.93230, 1.48501</td></tr>
<tr><td>10</td><td align="center" bgcolor="aqua">sym, 0.12267, 0.37576, 0.65606, 1.00136, 1.53875</td></tr>
</table>

<pre>
A formula expressing the tabulated Wk as a definite integral is
     G<sub>k</sub><sup>(N)</sup> = -&int; y F(y)<sup>k-1</sup> [1-F(y)]<sup>N-k</sup> F'(y) dy / B(k, N+1-k) 
where 1&le;k&le;N,
F'(y)=(2&pi;)<sup>-1/2</sup>exp(-y<sup>2</sup>/2) is the standard normal density,
F(x)=[1+erf(2<sup>-1/2</sup>x)]/2 is the CDF of (i.e. integral dy from -&infin; to x of) the standard normal density,
B(x,y)=&Gamma;(x)&Gamma;(y)/&Gamma;(x+y)  is Euler's beta function,
and the integration in the W-formula is from -&infin; to +&infin;.
This formula enables obtaining far more decimals of accuracy than Monte Carlo, e.g:
     G<sub>1</sub><sup>(2)</sup>=&pi;<sup>-1/2</sup>&asymp;0.5641896
     G<sub>1</sub><sup>(3)</sup>=(3/2)&pi;<sup>-1/2</sup>&asymp;0.8462844
     G<sub>1</sub><sup>(4)</sup>&asymp;1.029375373003964132057        G<sub>2</sub><sup>(4)</sup>&asymp;0.2970113822746453255175
     G<sub>1</sub><sup>(5)</sup>&asymp;1.162964473640519612772        G<sub>2</sub><sup>(5)</sup>&asymp;0.49501897045774220919586
</pre>
The G<sup>(4)</sup>s
and
G<sup>(5)</sup>s
should be expressible in closed form with the aid of polylogarithms, but I have not done so.
--
incidentally sum of sqs is 2/pi when N=2, is 9/2/pi when N=3, but apparently nothing nice when N=4.

F := (x) -> 1/2+1/2*erf(1/2*2^(1/2)*x);
Fp := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);
W := (k, n) -> -integrate( y * F(y)^(k-1) * (1-F(y))^(n-k) * Fp(y) , 
    y=-infinity..infinity)/Beta(k, n+1-k);
for n from 2 to 10 do
ss := 0;
print("<tr><td>", n, "</td><td>");
for k from 1 to n do
xx := evalf[20]( W(n+1-k,n) );
print( evalf(xx, 17) , ",");
ss := evalf(ss + xx^2, 20); 
od; 
print( "</td><td>", evalf(ss/n, 17), "</td></tr>" );
od;
quit;

F := (x) -> 1/2+1/2*erf(1/2*2^(1/2)*x);
Fp := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);
W := (k, n) -> -integrate( y * F(y)^(k-1) * (1-F(y))^(n-k) * Fp(y) , 
    y=-infinity..infinity)/Beta(k, n+1-k);
for n from 2 to 10 do
ss := 0;
for k from 1 to n do
xx := evalf[20]( W(n+1-k,n) );
print( "G[", k, "][", n, "]=", evalf(xx, 17) , ";");
ss := evalf(ss + xx^2, 20); 
od; 
print( "Gssum[", n, "]=", evalf(ss/n, 17), ";" );
od;
quit;

W(1,2) = 1/sqrt(Pi) = 0.5641895835
W(1,3) = 3/(2*sqrt(Pi)) = 0.846284  
W(1,4)=1.029375   W(2,4)=0.297011
W(1,5)=1.162964   W(2,5)=0.495019

solve diff(F(x)^N, x$2)=0 for x to find location of saddlepoint.  Equivalently solve
-N*exp(-x^2/2)+(Pi/2)^(1/2)*x+(Pi/2)^(1/2)*x*erf(x/2^(1/2))+exp(-x^2/2) = 0
for x.

this works:
sd := (N) ->  fsolve( -N*exp(-x^2/2)+(Pi/2)^(1/2)*x+(Pi/2)^(1/2)*x*erf(x/2^(1/2))+exp(-x^2/2) , 
 x,  sqrt(2*log(N))-7*log(log(N+3))/sqrt(log(N))..sqrt(2*log(N)) ); 
zz := (N,y) -> F(y)^(N-1)*Fp(y);
g1 := (N) -> N*int( y*F(y)^(N-1)*Fp(y), y = sd(N)-10./log(N) .. sd(N)+50./log(N) );
g2 := (N,j1) -> N*int( (y-j1)^2 * F(y)^(N-1)*Fp(y), y = sd(N)-10./log(N) .. sd(N)+50./log(N) );
for k from 1 to 16 do
   N := 2*10^k;
   ss := evalf(sd(N));
   G1 := evalf(g1(evalf(N)));
   G2 := evalf(g2(evalf(N), G1));
   print( N, ss, G1, evalf(sqrt(2*log(N))), G2, evalf(Pi^2/12/log(N)) );
od;

 int(int(int(int(P(w)*P(x)*P(y)*P(z)*z, w=-infinity..x),x=-infinity..y),y=-infinity..z),z=-infinity..infinity);
gets down to 3

 int(int(int(int(P(w)*P(x)*P(y)*P(z)*z, w=-infinity..x),z=y..infinity),x=-infinity..y),y=-infinity..infinity);
gets down to 2
--
<pre>
If we can then argue from computer simulations of 4-candidate elections that (in whatever of
the models above) range voting has less regret than <i>every</i> weighted positional system
we will have again proved the superiority (measured via Bayesian Regret)
of range over every rank-order ballot voting system,
but now in 4-candidate elections.  (As usual, it suffices to look only at the best one, not
every one.)  This methodology indeed would allow this theorem to
be effectively proved for <i>any</i> fixed number N of
candidates, if enough computer time were devoted to the matter for that N.

Note that our sorts of models <i>do not see</i> election manipulation
by "candidate cloning."  Instead they all postulate a fixed number of candidates
are selected independently from some fixed distribution.  That's
a weakness in our models; and we pay for that weakness when we find that the
optimum rank-order voting system is of weighted positional type:  all weighted
positional systems including Borda are known to be vulnerable to cloning.
(Range voting is immune to candidate cloning though, so this particular remark
only makes our preference for it more valid.)

A different weakness in our models is their somewhat naive notion of what 
"strategic voting" is.  A certain amount of naivete is, however, forced upon us,
which we can see as follows.  A critic might say "you must view a V-voter
election as a V-player game and strategic voting is the best strategy in that game
for that player."  Unfortunately, "game theory" as it presently stands contends 
there is <i>no such thing</i> as an "optimal strategy" in a V-player game when V&ge;3.
</pre>


<hr>

<a name="conclu"></a>
<h3>10.Conclusion
</h3>
--
By Warren D. Smith, 20-21 June 2008.
--

<pre>
These results seem to me to be absolutely devastating for all of voting theory.
They completely destroy the whole idea tracing to Kenneth Arrow that "rank order"
ballots (with or without permitting rank equalities) are a good thing.

They also heavily (some might even say "completely") revamp all of voting theory.

It's amazing that I and everybody else managed to miss all this for so long.

Well (to look a bit deeper) the reason the other voting theorists missed it was primarily their
allergy to utility-based thinking, which is and must be the true axiomatic
underpinning of the area.  The reason <i>I</i> missed it was just my stupidity.

All of these results that range voting was superior to common rival voting system proposals
were previously known from my 1999-2000 Bayesian Regret computerized voting system study.
However, those previous results only worked for <i>some</i> rival systems and
were all empirical. The present results work for <i>all</I> rank-order voting systems
as rivals, even those that nobody has ever discovered or named yet, and 
<i>prove as a <u>Theorem</u></I> the superiority of range voting over them in 3-candidate
elections in both of the simplest reasonable probabilistic election models, plus at
the same time identifying Borda as the best of the rank-order systems when rank-equalities
are forbidden (in the random-even-symmetric models; in the D-dimensional politics models 
it is another weighted-positional system which is <i>not</I> Borda) &ndash; and approval 
as the best if rank-equalities are permitted in strategic contexts
(in the random-even-symmetric models; in the D-dimensional politics models
it is a two-weight "two-faced approval" system).
None of that was realized before and it is of fundamental importance.

On the other hand, the computer remains supreme (because human theorem-provers 
encounter difficulties) for elections with 4 or more candidates
and in fancier utility models than these simple ones.
I have no doubt that, now that the seed has been planted,
future humans should be able to advance the pride of humanity somewhat further.
But this will do for now.  
One can also show (using similar methods) that range voting
is not the best voting system with ballots of its ilk, even for 3-candidate 
honest-normalizing-voter elections, in the right models of our ilk; and one
can indeed <i>identify</i> the best such methods.  

Specifically, call a range vote (with the permitted rating range being the real interval [0,1])
"normalized" if the worst candidate is awarded score 0 by that voter, and the best score 1.
The true utility difference  &Delta;U  between these two candidates for that voter
is however, in general, not 1.  
Call 1/&Delta;U the "normalization factor" and its reciprocal is the
"denormalization factor."  Now 

THEOREM (THE BEST VOTING SYSTEM WITH RANGE-TYPE BALLOTS):
The best single-winner voting system (in the sense of minimizing Bayesian Regret) 
with continuum [0,1] range-type rating ballots is precisely normalized range voting
<i>except</I> that each ballot B is <i>weighted</I>
with the expected denormalization factor for that ballot conditioned
on the fact that that B <I>was</I> the honest (or strategic) normalized range vote
(or in an F-weighted probability mixture of honest &amp; strategic voters, the expected 
denormalization factor in <i>that</i> model;  
conditional expectations taken over whatever probabilistic model we are in).
</pre>

<img align="right" src="assets/images/Best3candVotW.png">
<table>
<tr><th><u>x</u></th><th><u>W(x)</u></th></tr>
<tr><td>0.00-0.05</td><td align="center" bgcolor="aqua">1.56 </td></tr>
<tr><td>0.05-0.10</td><td align="center" bgcolor="aqua">1.59 </td></tr>
<tr><td>0.10-0.15</td><td align="center" bgcolor="aqua">1.63 </td></tr>
<tr><td>0.15-0.20</td><td align="center" bgcolor="aqua">1.66 </td></tr>
<tr><td>0.20-0.25</td><td align="center" bgcolor="aqua">1.69 </td></tr>
<tr><td>0.25-0.30</td><td align="center" bgcolor="aqua">1.72 </td></tr>
<tr><td>0.30-0.35</td><td align="center" bgcolor="aqua">1.73 </td></tr>
<tr><td>0.35-0.40</td><td align="center" bgcolor="aqua">1.76 </td></tr>
<tr><td>0.40-0.45</td><td align="center" bgcolor="aqua">1.77 </td></tr>
<tr><td>0.45-0.50</td><td align="center" bgcolor="aqua">1.77 </td></tr>
</table>
<p>
<b>Table:</b>
The best (regret minimizing) range-type (i.e. votes are scores in the real interval [0,1],
one score for each candidate) 
voting system for 3-candidate elections with 100% honest voters (who rate their favorite 1,
worst 0, and other linearly interpolated in between according to his utility) in the
random normal utilities model.
The voting system is the same as range voting except that if the middle candidate is
rated x, 0&le;x&le;1, then that vote is given weight W(x), where we tabulate W(x)
[tabulated is a Monte Carlo approximation to the probability-weighted average of W(x) over 
each 0.05-wide bin, each bin based on over 100000 Monte Carlos]; 
and since W(1-x)=W(x) we only tabulate for 0&le;x&le;0.5.
The candidate with the greatest weighted sum of scores wins.
If we had binned everything into only a <i>single</i>
bin 0&le;x&le;1, then its W-value would have been
&pi;<sup>-1/2</sup>3&asymp;1.69257,
which arises as the ratio P/Q of the following two triple integrals:
<center>
P = &int;&int;&int; F'(x) F'(y) F'(z) (y-x) dz dy dx = &pi;<sup>-1/2</sup>/2 &asymp; 0.28209
</center>
<center>
Q = &int;&int;&int; F'(x) F'(y) F'(z) dz dy dx = 1/6 &asymp; 0.16667
</center>
each integrated over the region -&infin;&lt;x&lt;z&lt;y&lt;+&infin;,
where
F'(u)=(2&pi;)<sup>-1/2</sup>exp(-u<sup>2</sup>/2) is the standard normal density.
--
One also can evaluate the following in closed form:

W(&frac12;)/W(1)=3<sup>-1/2</sup>2&asymp;1.15470.
This arises as the ratio (CB)/(AD) of the following four double integrals:
<center>
A = &int;&int; F'(x)<sup>2</sup> F'(y) (x-y)<sup>2</sup> dx dy = &pi;<sup>-1/2</sup>3/4 &asymp; 0.65147
</center>
<center>
B = &int;&int; F'(x) F'(x/2+y/2) F'(y) (x-y)<sup>2</sup> dx dy = (3&pi;)<sup>-1/2</sup>2 &asymp; 0.42314
</center>
<center>
C = &int;&int; F'(x)<sup>2</sup> F'(y) |x-y| dx dy = 3<sup>1/2</sup>/(2&pi;) &asymp; 0.27566
</center>
<center>
D = &int;&int; F'(x) F'(x/2+y/2) F'(y) |x-y| dx dy = 3<sup>-1/2</sup>2/&pi; &asymp; 0.36755
</center>
each integrated over the whole xy plane, where
F'(u)=(2&pi;)<sup>-1/2</sup>exp(-u<sup>2</sup>/2) is the standard normal density.

A simple approximation to W(x) is 
W(x)&asymp;1.76849-0.98398(x-&frac12;)<sup>2</sup>
(accurate to within additive error &plusmn;0.01???).
--
</p><p>

This yields for example 
<center>
W(0)=W(1)=(3&pi;)<sup>1/2</sup>/2&asymp;1.53499,
W(1/4)=W(3/4)=2(39&pi;)<sup>1/2</sup>/13&asymp;1.70292,
W(&frac12;)=&pi;<sup>1/2</sup>&asymp;1.77245,
W(&frac12;)/W(1)=3<sup>-1/2</sup>2&asymp;1.15470.
</center>
The best ratings-ballot-based voting system for N-candidate elections (with honest voters
in the random normal utilities model) is also range voting with vote-weights, 
but then the vote-weighting function W is a function of N-2 variables, i.e. of the
N-2 intermediate scores.
--
Q := (u) -> 3/sqrt(16*Pi) * (1+u^2-u)^(-3/2);
subs( csgn( 1/(1+u^2) + u^2/(1+u^2) - u/(1+u^2) ) = 1, %);

We can evaluate the following in closed form:
(1) the weighted average of W(x) over 0&le;x&le;1 is 3/sqrt(pi)=1.69256875
     (Ratio of last 2 integrals)
(2) W(1)/W(&frac12;)=2/sqrt(3)=1.15470.
     (Ratio from first 4 integrals)
  Fp := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);
 // integrate(integrate( Fp(x)*Fp(y), x=-infinity..infinity), y=-infinity..infinity) =  1
  integrate(integrate( Fp(x)*Fp(x)*Fp(y)*(x-y)^2, x=-infinity..infinity), y=-infinity..infinity);
     3/(4*sqrt(pi))=0.65147
  integrate(integrate( Fp(x)*Fp(x/2+y/2)*Fp(y)*(x-y)^2,  x=-infinity..infinity), y=-infinity..infinity);
     (2/3)*sqrt(3/pi)=0.42314
  integrate(integrate( Fp(x)*Fp(x)*Fp(y)*abs(x-y), x=-infinity..infinity), y=-infinity..infinity);
     sqrt(3)/(2*pi)=0.27566
  integrate(integrate( Fp(x)*Fp(x/2+y/2)*Fp(y)*abs(x-y),  x=-infinity..infinity), y=-infinity..infinity);
     2/(pi*sqrt(3))=0.36755

  integrate(integrate( Fp(x)*Fp(y)*abs(x-y), x=-infinity..infinity), y=-infinity..infinity);  
     2/sqrt(pi)=1.128378  // irrelevant

integrate(integrate(integrate( Fp(x)*Fp(y)*Fp(z),
 z=x..y), y=x..infinity), x=-infinity..infinity);
  1/6
integrate(integrate(integrate( Fp(x)*Fp(y)*Fp(z)*(y-x),
 z=x..y), y=x..infinity), x=-infinity..infinity);
  1/(2*sqrt(pi))=0.2820947918

WI := (u) ->
  integrate(integrate( Fp(x)*Fp(u*x+(1-u)*y)*Fp(y)*(x-y)^2, 
    x=-infinity..infinity), y=-infinity..infinity) /
  integrate(integrate( Fp(x)*Fp(u*x+(1-u)*y)*Fp(y)*abs(x-y), 
    x=-infinity..infinity), y=-infinity..infinity);

Den := (u) ->
  integrate(integrate( Fp(x)*Fp(u*x+(1-u)*y)*Fp(y)*abs(x-y), 
    x=-infinity..infinity), y=-infinity..infinity);
Den2 := (u) ->
  integrate(integrate( Fp(x)*Fp(u*x+(1-u)*y)*Fp(y)*(x-y), 
    x=y..infinity), y=-infinity..infinity) +
  integrate(integrate( Fp(x)*Fp(u*x+(1-u)*y)*Fp(y)*(y-x),
    x=-infinity..y), y=-infinity..infinity);
--
</p>

--
with(stats):
for k from 1 to 10 do q[k] := 0; d[k] := 0; od;
for k from 1 to 10 do 
   print( d[k], q[k] );
od;
print("starting");
do
 for k from 1 to 15 do
   y := sort( [ stats[random, normald](3) ] ):
   c := y[3]-y[1]:
   z := (y[2]-y[1])/c:
   b := floor( min(z, 1.0-z) * 20 ) + 1:
   q[b] := q[b]+1:
   d[b] := d[b]+c:
 od;
od;
for k from 1 to 10 do 
   print( d[k]/q[k], q[k] );
od;

1000:
1.613278486
1.331107464
1.570985540
1.556798491
1.682667708
1.770929901
1.698136792
1.809383273
1.718748780
1.748117135

1400 sec:
1.555491702
1.591137069
1.625742341
1.656260392
1.687625924
1.717810712
1.733099387
1.755366479
1.770992836
1.773455634

130 sec:
1.570806824, 9901
1.583695973, 10345
1.624485927, 10814
1.663438076, 11161
1.680411744, 11838
1.722466616, 12088
1.738980934, 12259
1.774738816, 12485
1.767097086, 12733
1.768519720, 12826

with(Statistics):
W := Vector([1.555491702,1.591137069,1.625742341,1.656260392,1.687625924,1.717810712,
1.733099387,1.755366479,1.770992836,1.773455634], datatype=float):
X := Vector([0.025, 0.075, 0.125, 0.175, 0.225, 0.275, 0.325, 0.375, 0.425, 0.475],
datatype=float):
Fit( a + b*( t - 1/2 )^2, X, W, t);
 WW := (x) -> 1.76849151597121179 - 0.983979168375481384 * (x - 1/2)^2;
-->

<h3>Acknowledgements</h3>
<p>
I thank Drs. 
Steven J. Brams,
Nicholas Miller,  
Steve Omohundro,
Marcus Pivato,
and Alan T. Sherman for
stylistic and publication advice and/or literature references, 
and Rick Carback for donating
computer time.
</P>

<hr>

<a name="AppA"></a>
<h3> Appendix A: Normal order statistics </h3>

<p>
Denote the expected value of the <i>k</i>th greatest of N
independent standard normal deviates, by
G<sub>k</sub><sup>(N)</sup>.
Of particular interest is 
G<sub>1</sub><sup>(N)</sup>,
the expected value of the <i>maximum</i> of N
independent standard normal deviates:
</p>
<center>
G<sub>1</sub><sup>(N)</sup> 
&nbsp; = &nbsp;
N&int;<sub>-&infin;&lt;y&lt;+&infin;</sub> y F(y)<sup>N-1</sup> F'(y) dy 
&nbsp; = &nbsp;
&int;<sub>-&infin;&lt;y&lt;&infin;</sub> [UnitStep(y)-F(y)<sup>N</sup>] dy 
&nbsp; = &nbsp;
<nobr>
&int;<sub>-&infin;&lt;y&lt;&infin;</sub> (1 - [1-F(y)]<sup>N</sup> - F(y)<sup>N</sup>)/2 dy 
</nobr>
</center>
where <br>
F'(y)=(2&pi;)<sup>-1/2</sup>exp(-y<sup>2</sup>/2) is the standard normal density;<br>
F(x)=[1+erf(2<sup>-1/2</sup>x)]/2 is the CDF of (i.e. integral dy from -&infin; to x of) the standard normal density;<br>
UnitStep(x)=1 if x&gt;0 and 0 otherwise.
</p><p>
Proof:
The first expression should be immediate from the definition and the fact that the negated
minimum is the same as the maximum (in expectation) due to even symmetry.
It is actually valid for <i>any</i> even-symmetric differentiable probability density F'(y) well enough
behaved when y&rarr;&plusmn;&infin;, although we are
only interested in the standard normal density here.
Then the second arises 
because it is 
trivially equivalent to 
<center>
lim<sub>L&rarr;&infin;</sub> 
<font size="+2">(</font>
F(L)<sup>N</sup>L
-
&int;<sub>-&infin;&lt;y&lt;L</sub> F(y)<sup>N</sup> dy 
<font size="+2">)</font>
</center>
which arises from the first by
integration by parts; 
finally the third then arises by using negation symmetry.
<b>QED.</b>
</p>
<p>
In the limit 
N&rarr;&infin;,
we have 
</p>
<center>
G<sub>1</sub><sup>(N)</sup> = (2lnN)<sup>1/2</sup> + O((lnN)<sup>-1/2</sup>lnlnN).
</center>
<p>
In addition to the expectation value, it also is possible to compute
the <i>variance</i> of the maximum of N
independent standard normal deviates.  It is
</p>
<center>
&pi;<sup>2</sup>/(12lnN) + O((lnN)<sup>-3/2</sup>lnlnN).
</center>
<p>
[Proof sketch:
These arise by combining Hall 1979 with
section 9 of our table of integrals in appendix B.]
</p><p>
One could go further and indeed compute the mean, the variance, and <i>any</i> particular moment
asymptotically when N&rarr;&infin;  as an <i>asymptotic series</i> expansion in N (these expressions
were merely the first-order terms in those series) by using the "saddlepoint method" 
(Bender &amp; Orszag 1978) of asymptotic analysis
of our first integral expression.
</p>

<br>
<table bgcolor="pink">
<caption>
<b>Table 4:</b>
G<sub>1</sub><sup>(N)</sup>, the expected max of N independent standard normals, versus N.
</caption>
<tr bgcolor="lightgreen">
<th>N</th><th>G<sub>1</sub><sup>(N)</sup></th><th>N</th><th>G<sub>1</sub><sup>(N)</sup></th></tr>
<tr><td>  1</td><td>0</td>               <td>  11</td><td>1.58643635190800</td></tr>
<tr><td>  2</td><td>&pi;<sup>-1/2</sup>&asymp;0.56418958354775</td><td>  12</td><td>1.62922763987191</td></tr>
<tr><td>  3</td><td>(3/2)&pi;<sup>-1/2</sup>&asymp;0.84628437532163</td><td>  13</td><td>1.66799017704913</td></tr>
<tr><td>  4</td><td>3&pi;<sup>-1/2</sup>[1/2+&pi;<sup>-1</sup>arcsin(1/3)]&asymp;1.02937537300396</td><td>  14</td><td>1.70338155409998</td></tr>
<tr><td>  5</td><td>(5/2)&pi;<sup>-1/2</sup>[1/2+(3/&pi;)arcsin(1/3)]&asymp;1.16296447364052</td><td>  15</td><td>1.73591344494104</td></tr>
<tr><td>  6</td><td>1.26720636061147</td><td>  16</td><td>1.76599139305479</td></tr>
<tr><td>  7</td><td>1.35217837560690</td><td>  17</td><td>1.79394198088269</td></tr>
<tr><td>  8</td><td>1.42360030604528</td><td>  18</td><td>1.82003187896872</td></tr>
<tr><td>  9</td><td>1.48501316220924</td><td>  19</td><td>1.84448151160382</td></tr>
<tr><td> 10</td><td>1.53875273083517</td><td>  20</td><td>1.86747505979832</td></tr>
<tr bgcolor="yellow"><td>200</td><td>2.74604244745115</td><td>2000</td><td>3.435337162</td></tr>
<tr bgcolor="yellow"><td>20000</td><td>4.01878926</td><td>200000</td><td>4.53333091</td></tr>
</table>

<p>
A more general formula is
</p>
<center>
&Gamma;(k)&Gamma;(N+1-k) G<sub>k</sub><sup>(N)</sup> 
= 
-&Gamma;(N+1)
&int;<sub>-&infin;&lt;y&lt;&infin;</sub> y F(y)<sup>k-1</sup> [1-F(y)]<sup>N-k</sup> F'(y) dy 
</center>
<p>
where 1&le;k&le;N.
<!-- and
B(x,y)=&Gamma;(x)&Gamma;(y)/&Gamma;(x+y)  is Euler's beta function.
-->
[This is valid for any probability density F'(y), not just the particular standard normal one we are interested in
here, and arises because the
<i>k</i>th smallest of N i.i.d. random deviates has F(y) that is Beta(k, N+1-k)-distributed.]
Of course by symmetry
</p>
<center>
G<sub>k</sub><sup>(N)</sup> + G<sub>N+1-k</sub><sup>(N)</sup> = 0.
</center>
<p>
One reason for the pre-eminent importance of the 
G<sub>1</sub><sup>(N)</sup>
is that all the other
G<sub>k</sub><sup>(N)</sup>
can be computed in terms of them alone, via the recurrence
</p>
<center>
G<sub>k+1</sub><sup>(N)</sup> 
=
[N G<sub>k</sub><sup>(N-1)</sup>  - (N-k) G<sub>k</sub><sup>(N)</sup>]/k.
</center>
<p>
[Proof sketch: consider the <i>k</i>th greatest among N-1 random points, then add an <i>N</i>th
point. With probability k/N it becomes the <nobr><i>(k+1)</i>th</nobr>
greatest, otherwise it stays 
the <i>k</i>th greatest.]
</p><p>
Consequently, for example,
</p>
<center>
G<sub>2</sub><sup>(4)</sup> = 3&pi;<sup>-1/2</sup>[1/2-(3/&pi;)arcsin(1/3)] &asymp; 0.29701138,
&nbsp;&nbsp;&nbsp;
G<sub>2</sub><sup>(5)</sup> = (5/2)&pi;<sup>-1/2</sup>[1-(6/&pi;)arcsin(1/3)] &asymp; 0.49501897
</center>
<p>
However, the reader is warned that this recurrence is numerically unstable when used in the forward
direction.  
</p><P>
Define
</p>
<center>
&#9723;<sub>N</sub>=&sum;<sub>1&le;k&le;N</sub>[G<sub>k</sub><sup>(N)</sup>]<sup>2</sup>/N.
</center>
<p>
This can also be used (instead of G<sub>1</sub><sup>(N)</sup>)
as the "master" quantity from which all the 
G<sub>k</sub><sup>(N)</sup> can be derived via the above linear recurrence.
As a consequence of Jensen's inequality
</p>
<center>
&#9723;<sub>N</sub> &nbsp; &lt; &nbsp; 1
</center>
<p>
where
&#9723;<sub>N</sub>&rarr;1 
in the N&rarr;&infin;  limit since the sum becomes a Riemann integral.
</p>
<p>
The theory exposited in 
appendix C on Schl&auml;fli functions and moments shows that
closed formulas (but now involving dilogarithms as well as more elementary functions) 
also exist for all the G<sup>(6)</sup>, 
and G<sup>(7)</sup>, 
and if we allow also trilogarithms then
closed forms exist for all the
G<sup>(8)</sup> and
G<sup>(9)</sup> too.
[I used the symbolic manipulation system MAPLE9 to determine 
G<sub>1</sub><sup>(6)</sup>,
&#9723;<sub>6</sub>,
and &#9723;<sub>7</sub>,
but will not state these results since each was approximately 4 pages long.  Quite
possibly much shorter simplified forms exist, but both MAPLE9 and every other contemporary 
symbolic manipulation systems are almost incapable of
simplifying expressions containing dilogs.]
</p>

<table border="1" cellpadding="2" bgcolor="aqua">
<caption>
<b>Table 5</b> giving G<sub>k</sub><sup>(N)</sup>.  
(According to our results in <a href="#Sec6">section 6</a>
these are the weights for the best rank-order-ballot voting system in N-candidate RNEM elections.)
</caption>
<tr bgcolor="pink"><th>N</th><th>G<sub>k</sub><sup>(N)</sup> for k=N, N-1, ..., 2, 1</th><th>&#9723;<sub>N</sub>=&sum;<sub>1&le;k&le;N</sub>[G<sub>k</sub><sup>(N)</sup>]<sup>2</sup>/N</th></tr>
 <tr><td>1</td><td>0 </td><td>0</td></tr>
 <tr><td>2</td><td>
 -0.56418958354775629,
 0.56418958354775629 (Plurality)
 </td><td>0.31830988618379067=1/&pi;</td></tr>
 <tr><td>3</td><td>
 -0.84628437532163443,
  0,
 0.84628437532163443 (Borda)
 </td><td>0.47746482927568600=3/(2&pi;)</td></tr>
 <tr><td>4</td><td>
 -1.0293753730039641,
 -0.29701138227464533,
 0.29701138227464533,
 1.0293753730039641
 </td><td>0.57391470987387290=9[&pi;<sup>2</sup>-4&pi;arcsin(1/3)+20arcsin(1/3)<sup>2</sup>]/(4&pi;<sup>3</sup>)</td></tr>
 <tr><td>5</td><td>
 -1.1629644736405196,
 -0.49501897045774221,
  0,
 0.49501897045774221,
 1.1629644736405196
 </td><td>0.63901205922520556=5[5&pi;<sup>2</sup>-36&pi;arcsin(1/3)+180arcsin(1/3)<sup>2</sup>]/(8&pi;<sup>3</sup>)</td></tr>
 <tr><td>6</td><td>
<!--
 -1.2672063606114713,
 -0.64175503878576119,
 -0.20154683380170425,
-->
sym,
 0.20154683380170425,
 0.64175503878576119,
 1.2672063606114713
 </td><td>0.68609420546552530</td></tr>
 <tr><td>7</td><td>
<!--
 1.3521783756069044,
 -0.75737427063887269,
 -0.35270695915298243,
-->
sym,
  0,
 0.35270695915298243,
 0.75737427063887269,
 1.3521783756069044
 </td><td>0.72182981266275276</td></tr>
 <tr><td>8</td><td>
<!--
 -1.4236003060452778,
 -0.85222486253829092,
 -0.47282249494061799,
 -0.15251439950692319,
-->
sym,
 0.15251439950692319,
 0.47282249494061799,
 0.85222486253829092,
 1.4236003060452778
 </td><td>0.74993670036986136</td></tr>
 <tr><td>9</td><td>
<!--
 -1.4850131622092370,
 -0.93229745673360373,
 -0.57197078285469610,
 -0.27452591911246175,
-->
sym,
  0,
 0.27452591911246175,
 0.57197078285469610,
 0.93229745673360373,
 1.4850131622092370
 </td><td>0.77265726588235093</td></tr>
 <tr><td>10</td><td>
<!--
 -1.5387527308351729,
 -1.0013570445758144,
 -0.65605910536476120,
 -0.37576469699787754,
 -0.12266775228433806,
-->
sym,
 0.12266775228433806,
 0.37576469699787754,
 0.65605910536476120,
 1.0013570445758144,
 1.5387527308351729
 </td><td>0.79142718641334414</td></tr>

<!--
<tr><td>2</td><td align="center" bgcolor="aqua">-0.56419, 0.56419 (Plurality)</td><td align="center">0.318309886</td></tr>
<tr><td>3</td><td align="center" bgcolor="aqua">-0.84628, 0, 0.84628 (Borda)</td><td align="center">0.477464829</td></tr>
<tr><td>4</td><td align="center" bgcolor="aqua">-1.02938, -0.29701, 0.29701, 1.02938</td><td align="center">0.573914710</td></tr>
<tr><td>5</td><td align="center" bgcolor="aqua">-1.16296, -0.49502, 0, 0.49502, 1.16296</td><td align="center">0.639012060</td></tr>
<tr><td>6</td><td align="center" bgcolor="aqua">-1.26721, -0.64176, -0.20155, 0.20155, 0.64176, 1.26721</td><td align="center">0.686094206</td></tr>
<tr><td>7</td><td align="center" bgcolor="aqua">-1.35218, -0.75737, -0.35271, 0, 0.35271, 0.75737, 1.35218</td><td align="center">0.721829813</td></tr>
<tr><td>8</td><td align="center" bgcolor="aqua">sym, 0.15251, 0.47282, 0.85222, 1.42360</td><td align="center">0.749936700</td></tr>
<tr><td>9</td><td align="center" bgcolor="aqua">sym, 0, 0.275453, 0.57197, 0.93230, 1.48501</td><td align="center">0.772657266</td></tr>
<tr><td>10</td><td align="center" bgcolor="aqua">sym, 0.12267, 0.37576, 0.65606, 1.00136, 1.53875</td><td align="center">0.791427186</td></tr>
-->
</table>

<p>
One may also estimate the variance corresponding to G<sub>k</sub><sup>(N)</sup>
for other k.  For example [by using the known connection 
to the Beta(k,N+1-k) distribution and its known variance formula],  with k=(N+1)/2, the 
variance is &pi;/(2N+4) + O(N<sup>-2</sup>)
when N&rarr;&infin;.
</p>

<p>
<b>Previous work:</b>
Few to none of these results about normal order statistics are original
(although I rediscovered most).  
Royston 1982 gives a computer algorithm for approximate
computation of the G<sub>k</sub><sup>(N)</sup> [which he calls E(k,N)]
while Balakrishnan 1984 gives one for 
&#9723;<sub>N</sub> [which he calls S<sub>N</sub>/N]
based on Ruben 1956.
<!--??? G1N arises from regsimp with dihedrals arcsec(-3) on sphere in N-2 flat space dimns.-->
Similar tables to ours
were given by  
Teichroew 1956,
Harter &amp; Balakrishnan 1996,
Parrish 1992, and
(to low precision) Rohlf &amp; Sokal 1994.  
The latter call the G<sub>k</sub><sup>(N)</sup> by the name "Rankits."
Harter attributes our recurrence to Walter T. Federer in a 1951 Iowa agricultural report.
Also, Parrish tabulated the variances and covariances of the normal order statistics,
as did Sarhan and Greenberg 1956.
Closed forms for the G<sub>k</sub><sup>(N)</sup> with N&le;5 were found by Godwin 1949 although
he did not realize the cases with N=6,7 also have closed forms 
(employing dilogs) and with N=8,9
(employing trilogs).  This is made maximally clear by combining Ruben 1956
with our appendix C to express the &#9723;<sub>N</sub>, then use the Federer recurrence
and solve a quadratic equation to get all the G<sub>k</sub><sup>(N)</sup>.
Ruben's work is the deepest.
Our asymptotic results about G<sub>1</sub><sup>(N)</sup> and the corresponding variance
for N large are deducible from
section 9 of our table of integrals in appendix B plus Hall 1979.
Indeed, more precise and
general asymptotics than we have stated are deducible in this way, <i>but</i> much 
<i>more</i> precise asymptotics, namely arbitrarily 
many terms of an asymptotic series expansion, would be deducible
from the saddlepoint method (a fact the previous authors seem not to have pointed 
out, so we are).
</p><P>
<b>Why this appendix is needed:</b>
Apparently its material
is nowhere else collected in one place
(at least, none of the sources we referenced do so).
</p>
<!--
It is also possible to express the N=7 and N=8 cases in terms of certain 1-dimensional
integrals...

relative volumes of regular spherical simplices with dihedrals = arcsec(-3):
on (N-1)-diml spheres in flat N-space:
These also tabulated by Ruben 1954 table 1 page223 but hisn=2+myN.
S[N] is expressed by Ruben as a sum involving these volume[j] for j=1,...,2*floor(N/2)-4 ??
Since I know volume[6] I can get S[N] for N<=11 ?? or N<=7 I think actually
N      volume
0      V0 := 1;
1      V1 := 1/2;
2fake  V2 := arcsec(-3)/(2*Pi);
   0.304086723984696364914572220388784544341685675280299856356030850988999295661278876564894086912\
    1127434602366086347522710108812368824983072723667002920135395471014745474874900333215093502\
    236948
3     V3 := (3*arcsec(-3)-Pi)/(4*Pi);
   0.206130085977044547371858330583176816512528512920449784534046276483498943491918314847341130368\
   1691151903549129521284065163218553237474609085500504380203093206522118212312350499822640253\
   3554224
4      Matrix(1..4, 1..4, arcsec(-3)); NF4(%); V4 := simplify(%);
   0.149737652917184421674063525809494603216880611914616336724639428810285820147918230655427219340\
   6295400808025745498522735701682634776235958540849881649942102561742235165386556650059278741\
   2176171
5       A := Matrix(1..5, 1..5, arcsec(-3) );
res := (1/2) * (  #1 row+col missing
NF4( Matrix(4,4, [ 
[A[2,2],A[2,3],A[2,4],A[2,5]],
[A[3,2],A[3,3],A[3,4],A[3,5]],
[A[4,2],A[4,3],A[4,4],A[4,5]],
[A[5,2],A[5,3],A[5,4],A[5,5]] 
])) + NF4( Matrix(4,4, [ 
[A[1,1],A[1,3],A[1,4],A[1,5]],
[A[3,1],A[3,3],A[3,4],A[3,5]],
[A[4,1],A[4,3],A[4,4],A[4,5]],
[A[5,1],A[5,3],A[5,4],A[5,5]] 
])) + NF4( Matrix(4,4, [ 
[A[1,1],A[1,2],A[1,4],A[1,5]],
[A[2,1],A[2,2],A[2,4],A[2,5]],
[A[4,1],A[4,2],A[4,4],A[4,5]],
[A[5,1],A[5,2],A[5,4],A[5,5]] 
])) + NF4( Matrix(4,4, [ 
[A[1,1],A[1,2],A[1,3],A[1,5]],
[A[2,1],A[2,2],A[2,3],A[2,5]],
[A[3,1],A[3,2],A[3,3],A[3,5]],
[A[5,1],A[5,2],A[5,3],A[5,5]] 
])) + NF4( Matrix(4,4, [ 
[A[1,1],A[1,2],A[1,3],A[1,4]],
[A[2,1],A[2,2],A[2,3],A[2,4]],
[A[3,1],A[3,2],A[3,3],A[3,4]],
[A[4,1],A[4,2],A[4,3],A[4,4]]
] )))
                   - (1/4) * (   #sum of normalized dihedrals
A[1,2] + A[1,3] + A[1,4] + A[1,5] + A[2,3] + A[2,4] + A[2,5] + A[3,4] + A[3,5] + A[4,5]
) / SphereSurf(2)
                   + (1/2); 
V5 := simplify(res);
0.114127322331220141898728263551775147187987341585791200921521444553216311216598385226332831071\
    2919915514149147877500063982175664878132214542957196824516767726818724226279140792110463097\
    451672
 arcsec(3) = Pi-arcsec(-3)
 sin(arcsec(3))  = sqrt(8)/3
 cos(arcsec(3))  = 1/3
 sin(2*arcsec(3))  = 4*sqrt(2)/9
 cos(2*arcsec(3))  = -7/9
 sin(4*arcsec(3))  = -56*sqrt(2)/81
 cos(4*arcsec(3))  = 17/81
 sin(Pi-x) = sin(x)
 cos(Pi-x) = -cos(x)
subs(exp(-2*I*(Pi - arcsec(3))) = -7/9+4/9*I*2^(1/2),
exp(4*I*(Pi - arcsec(3))) = -81/(-17+56*I*2^(1/2)),
exp(I*(Pi - arcsec(3))) = -3/(1+2*I*2^(1/2)),
exp(2*I*(Pi - arcsec(3))) = 9/(-7+4*I*2^(1/2)),
exp(-4*I*(-Pi + arcsec(3))) = -81/(-17+56*I*2^(1/2)),
exp(-I*(-Pi + arcsec(3))) = -3/(1+2*I*2^(1/2)),
exp(2*I*(-Pi + arcsec(3))) = -7/9+4/9*I*2^(1/2) ,
exp(-2*I*(-Pi + arcsec(3))) = 9/(-7+4*I*2^(1/2)), % );
-->

<blockquote>
<b>References for appendix A:</b>
<br>
N.Balakrishnan:
Algorithm AS 200: Approximating the sum of squares of normal scores,
Applied Statistics 33,2 (1984) 242-245.
<br>
C.M.Bender &amp; S.A.Orszag:
Advanced Mathematical Methods for Scientists and Engineers,
McGraw-Hill 1978 (but now published by Springer).
<br>
H.J.Godwin:
Some low moments of order statistics, 
Annals Mathematical Statistics 20,2 (1949) 279-285.
<br>
Peter Hall:
On the rate of convergence of normal extremes,
J.Applied Probability 16,2 (1979) 433-439.
<br>
H.Leon Harter &amp; N.Balakrishnan:
CRC Handbook of tables for use of Order Statistics in Estimation,
CRC Press, Boca Raton, Florida, 1996.
<!-- discussion seems to be a revision & update of
HL Harter:
Expected values of normal order statistics, Biometrika 48, 1/2 (1961) 151-176; correction 476.
-->
<br>
Rudolph S. Parrish:
Computing expected values of normal order statistics,
I: Communications in Statistics B &ndash; Simulation and Computation 21,1 (1992) 57-70;
II: Variances and Covariances, 71-101.
<br>
Harold Ruben:
On the moments of order statistics in samples from normal populations,
Biometrika 41 (1954) 200-227.
<br>
Harold Ruben: On the sum of the squares of normal scores,
Biometrika 43,3/4 (Dec. 1956) 456-458.  Corrigienda 52 (1965) 669.
Well summarized in Zentralblatt Math 0074.13603.
<!--
Ruben 1956, eq 11 p457 read 1/(2*sqrt(pi)) not 1/sqrt(2pi)

eq 12, read (n-1)^{-(k)} not (n-1)^k
and for (n-1)^{-(k)} read (n+1)^{-(k)}
-->
<br>
J.P.Royston: Algorithm AS 177: expected normal order statistics, 
J.Royal Statistical Soc. C (Applied Statistics) 31,2 (1982) 161-165; 
corrections/comments by W.K&ouml;niger 32,2 (1983) 223-224.
<br>
F. James Rohlf &amp; Robert R. Sokal: Statistical Tables, Macmillan 1994.
<br>
A.E.Sarhan &amp; B.G.Greenberg:
Estimation of location and scale parameters by 
order statistics from singly and doubly censored samples,
I: Ann. Math. Statist., 27,2 (1956) 427-451;
II: Same Ann, 29,1 (1958) 79-105;
correction of part I: 40,1 (1969) 325.
<br>
Daniel Teichroew (ed.):
Tables of Expected Values of Order Statistics and Products of Order Statistics 
for Samples of Size  Twenty and Less from the Normal Distribution,
Annals Math'l. Statist. 27,2 (1956) 410-426.
<br>
G.L.Tetjen, D.K.Kahaner, R.J.Beckman:
Variances and covariances of normal order statistics for sample sizes 2-50,
Selected Tables in Mathematical Statistics 5 (1977) 1-73;
we only cite the TKB tables to warn the reader not to use them
&ndash; since Parrish denounced them as wrong.
<br>

</blockquote>

<a name="AppB"></a>
<h3> Appendix B: a table of definite integrals </h3>

<p>
<b>The purpose</b>
of this table is to collect together numerous integrals we needed elsewhere in this paper,
in one place, where hopefully they will form a useful resource for future workers in this area.
Not all of these integrals are new and difficult.  But most 
of our multiple integrals are unavailable in any table we know of, nor are contemporary
symbolic manipulation systems capable of doing them.
</p><P>
We shall sometimes 
denote various constants by C<sub>1</sub>, C<sub>2</sub>, etc. for easy reference 
elsewhere.
At the end of the table we shall explain how to evaluate every integral of these ilks 
in closed form.
Let P(x)=(2&pi;)<sup>-1/2</sup>exp(-x<sup>2</sup>/2)
be the standard normal density function. Then:
</p>
<b>1.</b>
<center>
&int;<sub>-&infin;&lt;x&lt;+&infin;</sub> P(x) dx = 1 <br>
&int;<sub>-&infin;&lt;x&lt;+&infin;</sub> x P(x) dx = 0 <br>
&int;<sub>-&infin;&lt;x&lt;+&infin;</sub> x<sup>2</sup> P(x) dx = 1 <br>
&int;<sub>0&lt;x&lt;+&infin;</sub> P(x) dx = 1/2 <br>
&int;<sub>0&lt;x&lt;+&infin;</sub> x P(x) dx = (2&pi;)<sup>-1/2</sup> &asymp; 0.3989422802 <br>
&int;<sub>0&lt;x&lt;+&infin;</sub> x<sup>2</sup> P(x) dx = 1/2 <br>
</center>
<hr>
<b>2.</b>
<center>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> P(x) P(y) dx dy = 1/2 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> y P(x) P(y) dx dy = &pi;<sup>-1/2</sup>/2 &asymp; 0.2820947918 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> x P(x) P(y) dx dy = -&pi;<sup>-1/2</sup>/2 &asymp; -0.2820947918 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) P(x) P(y) dx dy = &pi;<sup>-1/2</sup> &asymp; 0.5641895835 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> |y-x| P(x) P(y) dx dy = 2&pi;<sup>-1/2</sup> &asymp; 1.1283791671 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> x<sup>2</sup> P(x) P(y) dx dy = 1/2 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> y<sup>2</sup> P(x) P(y) dx dy = 1/2 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> x y P(x) P(y) dx dy = 0 <br>
</center>
<hr>
<b>3.</b> For the region of integration explicitly
stated in the integrals, the following formulas require
0&le;&theta;&lt;&pi;/2. 
But actually they are valid for 0&lt;&theta;&lt;2&pi; if the region of integration
is "a wedge, with apex angle &theta; located at the origin, lying on top
of the positive x-axis."
<center>
&int;<sub>0&lt;x&lt;&infin;</sub>&int;<sub>0&lt;y&lt;xtan&theta;</sub> P(x) P(y) dx dy = &theta;/(2&pi;) <br>
&int;<sub>0&lt;x&lt;&infin;</sub>&int;<sub>0&lt;y&lt;xtan&theta;</sub> x P(x) P(y) dx dy = (8&pi;)<sup>-1/2</sup>sin&theta; <br>
&int;<sub>0&lt;x&lt;&infin;</sub>&int;<sub>0&lt;y&lt;xtan&theta;</sub> y P(x) P(y) dx dy = 
(8&pi;)<sup>-1/2</sup>[1-cos&theta;] <br>
</center>
Using these we can compute some other integrals too.  For example
<center>
&int;&int;&int;<sub>z&gt;(x+y)/2</sub>
z P(x) P(y) P(z) dx dy dx 
=
&int;&int;<sub>z&gt;2<sup>-1/2</sup>x</sub>
z P(x) P(z) dx dz
=
2&int;<sub>0&lt;z&lt;&infin;</sub>&int;<sub>0&lt;u&lt;2<sup>1/2</sup>z</sub> z P(z) P(u) dz du 
= <br>
=
2(8&pi;)<sup>-1/2</sup>(2/3)<sup>1/2</sup>
=
(3&pi;)<sup>-1/2</sup>
&asymp;
0.325735008.
</center>
<hr>
<b>4.</b>
<center>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> P(x) P(uy+[1-u]x) P(y) dx dy = &pi;<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-1/2</sup>/2 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> x P(x) P(uy+[1-u]x) P(y) dx dy = 0 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> y P(x) P(uy+[1-u]x) P(y) dx dy = 0 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> |x-y| P(x) P(uy+[1-u]x) P(y) dx dy = 3<sup>1/2</sup>/(2 &pi; (1+u<sup>2</sup>-u)) <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) P(x) P(uy+[1-u]x) P(y) dx dy = 3<sup>1/2</sup>/(4 &pi; (1+u<sup>2</sup>-u)) <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> y P(x) P(uy+[1-u]x) P(y) dx dy = 3<sup>1/2</sup>/(8 &pi; (1+u<sup>2</sup>-u)) <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> x P(x) P(uy+[1-u]x) P(y) dx dy = -3<sup>1/2</sup>/(8 &pi; (1+u<sup>2</sup>-u)) <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) y P(x) P(uy+[1-u]x) P(y) dx dy = (2-u)&pi;<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-3/2</sup>/8 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) x P(x) P(uy+[1-u]x) P(y) dx dy = -(1+u)&pi;<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-3/2</sup>/8 <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) x y P(x) P(uy+[1-u]x) P(y) dx dy = 3<sup>1/2</sup>(1+u<sup>2</sup>-u)<sup>-2</sup>(2u<sup>2</sup>-2u-1)/(12&pi;) <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) x<sup>2</sup> P(x) P(uy+[1-u]x) P(y) dx dy = 3<sup>1/2</sup>(1+u<sup>2</sup>-u)<sup>-2</sup>(2u<sup>2</sup>+u+2)/(12&pi;) <br>
&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> (y-x) y<sup>2</sup> P(x) P(uy+[1-u]x) P(y) dx dy = 3<sup>1/2</sup>(1+u<sup>2</sup>-u)<sup>-2</sup>(2u<sup>2</sup>-5u+5)/(12&pi;) <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> (x-y)<sup>2</sup> P(x) P(uy+[1-u]x) P(y) dx dy = 3(16&pi;)<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-3/2</sup> <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> x y P(x) P(uy+[1-u]x) P(y) dx dy = &pi;<sup>-1/2</sup>(u-1)u(1+u<sup>2</sup>-u)<sup>-3/2</sup>/4 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> x<sup>2</sup> P(x) P(uy+[1-u]x) P(y) dx dy = &pi;<sup>-1/2</sup>(u<sup>2</sup>+1)(1+u<sup>2</sup>-u)<sup>-3/2</sup>/4 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> y<sup>2</sup> P(x) P(uy+[1-u]x) P(y) dx dy = &pi;<sup>-1/2</sup>([1-u]<sup>2</sup>+1)(1+u<sup>2</sup>-u)<sup>-3/2</sup>/4 <br>
<!--
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> [1+1+(2u-1)<sup>2</sup>] u<sup>n</sup> P(x) P(uy+[1-u]x) P(y) dx dy = &pi;<sup>-1/2</sup>(3+4u<sup>2</sup>-4u)(1+u<sup>2</sup>-u)<sup>-1/2</sup>/2 <br>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> (y-x) [1+1+(2u-1)<sup>2</sup>] u<sup>n</sup> P(x) P(uy+[1-u]x) P(y) dx dy = 
[2(3+4u<sup>2</sup>-4u)/(1+u<sup>2</sup>)
+
(4u<sup>3</sup>+3-u)(u+1)(u<sup>2</sup>+1)<sup>-1/2</sup>(1+u<sup>2</sup>-u)<sup>-1</sup>]
3<sup>-1/2</sup>u<sup>n</sup>/(4&pi;) <br>
-->
</center>
<p>
Of course if any integrand above is multiplied by any function f(u) then the integral is too.
</p>
<hr>
<b>5.</b>
<center>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> P(x) P(y) P(z) dx dy dz = 1/6 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> z P(x) P(y) P(z) dx dy dz = &pi;<sup>-1/2</sup>/4 &asymp; 0.1410473959 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> x P(x) P(y) P(z) dx dy dz = -&pi;<sup>-1/2</sup>/4 &asymp; -0.1410473959 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> y P(x) P(y) P(z) dx dy dz = 0 <br>

&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> z<sup>2</sup> P(x) P(y) P(z) dx dy dz = C<sub>1</sub> = 3<sup>1/2</sup>/(12&pi;)+1/6 &asymp;  0.2126107412851493374592772 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> x<sup>2</sup> P(x) P(y) P(z) dx dy dz = C<sub>1</sub> &asymp;  0.2126107413 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> y<sup>2</sup> P(x) P(y) P(z) dx dy dz = C<sub>2</sub> = (&pi;-3<sup>1/2</sup>)/(6&pi;) &asymp; 0.0747785174297013250814456 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> x y P(x) P(y) P(z) dx dy dz = 3<sup>1/2</sup>/(12&pi;) &asymp; 0.04594407462 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> y z P(x) P(y) P(z) dx dy dz = 3<sup>1/2</sup>/(12&pi;) &asymp; 0.04594407462 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> x z P(x) P(y) P(z) dx dy dz = -3<sup>1/2</sup>/(6&pi;) &asymp; -0.09188814927 <br>
</center>
<hr>
<b>6.</b>
<center>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> (2y-x-z)/(z-x) P(x) P(y) P(z) dx dy dz = 0 <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> y (2y-x-z)/(z-x) P(x) P(y) P(z) dx dy dz = C<sub>4</sub> = (ln3-1)&pi;<sup>-1/2</sup>/2 &asymp; 0.02781801303817596663741896 &Dagger; <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> x (2y-x-z)/(z-x) P(x) P(y) P(z) dx dy dz = -C<sub>4</sub>/2 = -(ln3-1)&pi;<sup>-1/2</sup>/4 &asymp; -0.01390900656 &Dagger; <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> z (2y-x-z)/(z-x) P(x) P(y) P(z) dx dy dz = -C<sub>4</sub>/2 = -(ln3-1)&pi;<sup>-1/2</sup>/4 &asymp; -0.01390900656 &Dagger; <br>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> [(2y-x-z)/(z-x)]<sup>2</sup> P(x) P(y) P(z) dx dy dz = C<sub>8</sub> = &pi;<sup>-1/2</sup>(4-ln3)/32 &asymp; 0.051154147642716153988  <br>
<!--
P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);
I1 := int(int(int( ((2*y-x-z)/(z-x))^2 * P(x) * P(y) * P(z),
 y=x..z), x=-infinity..z), z=-infinity..infinity);
I3 := int(int(int( ((2*y-x-z)/(z-x))^2 * P(x) * P(y) * P(z),
 x=-infinity..y), y=-infinity..z), z=-infinity..infinity);
I2 := int(int(int( u^2 * P(x) * P(u*z+(1-u)*x) * P(z),
x=-infinity..z), z=-infinity..infinity), u=0..1);
I2 = &pi;<sup>-1/2</sup>(4-ln3)/32 =  0.051154147642716153988
   =numerint?=                         0.05115414762
I3 = ???
-->
</center>
<hr>
<b>7.</b>
<center>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> P(x) P(y) P(z) dx dy dz = 1/12 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> y P(x) P(y) P(z) dx dy dz = 
C<sub>3</sub> = (3<sup>1/2</sup>2-3)&pi;<sup>-1/2</sup>/12 &asymp; 0.0218201080807009021251083 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> x P(x) P(y) P(z) dx dy dz = 
C<sub>5</sub> = -(3/&pi;)<sup>1/2</sup>/12 &asymp; -0.0814337520 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> z P(x) P(y) P(z) dx dy dz = 
C<sub>6</sub> = (3-3<sup>1/2</sup>)&pi;<sup>-1/2</sup>/12 &asymp; 0.05961364387 &Dagger; <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> y<sup>2</sup> P(x) P(y) P(z) dx dy dz = C<sub>2</sub>/2 = (&pi;-3<sup>1/2</sup>)/(12&pi;) &asymp; 0.03738925871 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> x<sup>2</sup> P(x) P(y) P(z) dx dy dz = 3<sup>1/2</sup>/(12&pi;)+1/12 &asymp; 0.1292774080 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> z<sup>2</sup> P(x) P(y) P(z) dx dy dz = 1/12 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> x z P(x) P(y) P(z) dx dy dz = C<sub>7</sub> = -3<sup>1/2</sup>/(12&pi;) &asymp; -0.04594407462 &Dagger; <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> y z P(x) P(y) P(z) dx dy dz = 3<sup>1/2</sup>/(12&pi;) &asymp; 0.04594407462 <br>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> x y P(x) P(y) P(z) dx dy dz = 0 <br>
</center>
<hr>
<b>8.</b>
<center>
&int;&int;<sub>-&infin;&lt;x,z&lt;+&infin;</sub>&int;<sub>x/2+z/2&lt;y&lt;&infin;</sub> P(x) P(y) P(z) dx dy dz = 1/2 <br>
&int;&int;<sub>-&infin;&lt;x,z&lt;+&infin;</sub>&int;<sub>x/2+z/2&lt;y&lt;&infin;</sub> x P(x) P(y) P(z) dx dy dz = -(3&pi;)<sup>-1/2</sup>/2 &asymp; -0.1628675040<br>
&int;&int;<sub>-&infin;&lt;x,z&lt;+&infin;</sub>&int;<sub>x/2+z/2&lt;y&lt;&infin;</sub> z P(x) P(y) P(z) dx dy dz = -(3&pi;)<sup>-1/2</sup>/2 &asymp; -0.1628675040<br>
&int;&int;<sub>-&infin;&lt;x,z&lt;+&infin;</sub>&int;<sub>x/2+z/2&lt;y&lt;&infin;</sub> y P(x) P(y) P(z) dx dy dz = (3&pi;)<sup>-1/2</sup> &asymp; 0.3257350080 <br>
</center>
<hr>
<b>9.</b>
<center>
&int;<sub>-&infin;&lt;u&lt;+&infin;</sub> exp(-e<sup>-u</sup>-u) du = 1<br>
&int;<sub>-&infin;&lt;u&lt;+&infin;</sub> u exp(-e<sup>-u</sup>-u) du = &gamma; &asymp; 0.577215649 &nbsp;&nbsp; (Euler-Mascheroni constant)<br>
&int;<sub>-&infin;&lt;u&lt;+&infin;</sub> (u-&gamma;)<sup>2</sup> exp(-e<sup>-u</sup>-u) du = &pi;<sup>2</sup>/6 &asymp; 1.644934068<br>
</center>

<hr>
<b>10.</b>
<center>
&int;<sub>0&lt;u&lt;1</sub> (1+u<sup>2</sup>-u)<sup>-1/2</sup> du = ln3 &asymp; 1.098612289<br>
&int;<sub>0&lt;u&lt;1</sub> u/(1+u<sup>2</sup>-u)<sup>1/2</sup> du = (ln3)/2 &asymp; 0.5493061445<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>2</sup>/(1+u<sup>2</sup>-u)<sup>1/2</sup> du = 1/2-(ln3)/8 &asymp; 0.3626734639<br>
&int;<sub>0&lt;u&lt;1</sub> (1+u<sup>2</sup>-u)<sup>-1</sup> du = 2&pi;3<sup>-3/2</sup> &asymp; 1.098612289<br>
&int;<sub>0&lt;u&lt;1</sub> u/(1+u<sup>2</sup>-u) du = &pi;3<sup>-3/2</sup> &asymp; 0.6045997883<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>2</sup>/(1+u<sup>2</sup>-u) du = 1-&pi;3<sup>-3/2</sup> &asymp; 0.3954002117<br>
&int;<sub>0&lt;u&lt;1</sub> 4(u-1/2)<sup>2</sup>/(1+u<sup>2</sup>-u) du = 4-2&pi;3<sup>-1/2</sup> &asymp;  0.372401270<br>
&int;<sub>0&lt;u&lt;1</sub> (1+u<sup>2</sup>-u)<sup>-3/2</sup> du = 4/3 &asymp; 1.333333333<br>
&int;<sub>0&lt;u&lt;1</sub> u/(1+u<sup>2</sup>-u)<sup>3/2</sup> du = 2/3 &asymp; 0.6666666667<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>2</sup>/(1+u<sup>2</sup>-u)<sup>3/2</sup> du = ln3-2/3 &asymp; 0.4319456223<br>
&int;<sub>0&lt;u&lt;1</sub> (1+u<sup>2</sup>-u)<sup>-1</sup>(1+u<sup>2</sup>)<sup>-1</sup> du = 3<sup>-3/2</sup>&pi;+(ln2)/2 &asymp; 0.9511733786<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>1</sup>(1+u<sup>2</sup>-u)<sup>-1</sup>(1+u<sup>2</sup>)<sup>-1</sup> du = 3<sup>-3/2</sup>2&pi;-&pi;/4 &asymp; 0.4238014135<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>2</sup>(1+u<sup>2</sup>-u)<sup>-1</sup>(1+u<sup>2</sup>)<sup>-1</sup> du = 3<sup>-3/2</sup>&pi;-(ln2)/2 &asymp; 0.2580261980<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>3</sup>(1+u<sup>2</sup>-u)<sup>-1</sup>(1+u<sup>2</sup>)<sup>-1</sup> du = &pi;/4-3<sup>-3/2</sup>&pi; &asymp; 0.1807983752<br>
&int;<sub>0&lt;u&lt;1</sub> u<sup>4</sup>(1+u<sup>2</sup>-u)<sup>-1</sup>(1+u<sup>2</sup>)<sup>-1</sup> du = 1+(ln2)/2-3<sup>-3/2</sup>2&pi; &asymp; 0.1373740133<br>
<!--
&int;<sub>0&lt;u&lt;1</sub> (u<sup>2</sup>+1)/(1+u<sup>2</sup>-u)<sup>3/2</sup> du = 2/3+ln3 &asymp; 1.765278956<br>
-->
</center>


<!--
P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);
int(int(int( P(x)*P(y)*P(z), y=(z+x)/2..infinity), x=-infinity..infinity), z=-infinity..infinity);
  = 0.5

Ix := int(int(int( x*P(x)*P(y)*P(z), y=(z+x)/2..infinity), x=-infinity..infinity), z=-infinity..infinity);
    = int(int(int( z*P(x)*P(y)*P(z), y=(z+x)/2..infinity), x=-infinity..infinity), z=-infinity..infinity);
    = -0.1628675040
I2 := int(int(int( x * P(x) * P(u*z+(1-u)*x) * P(z),    
x=-infinity..infinity), z=-infinity..infinity), u=1/2..infinity);   
Iy := int(int(int( y*P(x)*P(y)*P(z), y=(z+x)/2..infinity), x=-infinity..infinity), z=-infinity..infinity);
  = 1/sqrt(3*Pi) = 0.3257350080
-->
<p>
The 1- and 2-dimensional integrals in the first two groups are standard and are
derived in many freshman calculus courses 
(or arise from them by considering
taking partial derivatives of the integrand)
&ndash; 
e.g.  both
</p>
<center>
&int;&int;<sub>-&infin;&lt;x,y&lt;+&infin;</sub> P(x) P(y) dx dy = 1 
</center>
<p>
and the integrals in the third group
are best shown by changing variables from Cartesian
to polar coordinates.
The 4th group of integrals, all 2D and involving the parameter <i>u</i>, can be done 
directly by first indefinitely integrating (using the "error function") the inner integral.
(Absolute values inside integrands are handled by splitting the integral into two parts,
where the quantity inside the absolute value signs is positive and negative.)
A different, powerful, and quite-general approach, which works for every integral in groups 1-4,
is to view the product of the Ps in the integrand as exp(a quadratic form in x,y)
and use
</p>
<center>
&int;&hellip;&int; exp(A + B&middot;x -  x&middot;Cx) d<sup>n</sup>x =
exp(A+B&middot;C<sup>-1</sup>B/4)&pi;<sup>n/2</sup>det(C)<sup>-1/2</sup>
</center>
<p>
where the integral is over all n-dimensional real vectors x,
A is a constant, B is a constant n-vector,
and C is a constant n&times;n positive-definite symmetric matrix.
This formula in turn arises by rewriting the quadratic 
<nobr>x&middot;Cx-Bx-A</nobr>
in <i>spherically symmetric</i> form as 
<nobr>|y|<sup>2</sup>-Q</nobr>
where 
<nobr>y=C<sup>1/2</sup>x-C<sup>-1/2</sup>B/2</nobr>
and 
<nobr>Q=B&middot;C<sup>-1</sup>B/4+A</nobr>,
then integrating d<sup>n</sup>y, where 
<nobr>d<sup>n</sup>x=(detC)<sup>-1/2</sup>d<sup>n</sup>y</nobr>.
One can also integrate over a halfspace delineated by any hyperplane through the origin,
rather than the whole space; just post-multiply the linear transformation from x to y by
an appropriate rotation chosen so that
the hyperplane, in y-space, becomes the standard hyperplane
y<sub>1</sub>&ge;0.
Also, one can still do this integral in closed form even if the integrand
is multiplied by any polynomial in
the coordinates, because a polynomial is still a polynomial after the linear
transformation, and any monomial can be integrated times the y-space spherically
symmetric gaussian by using
</p>
<center>
&int;<sub>0&lt;x&lt;&infin;</sub>
x<sup>P-1</sup> exp(-Ax<sup>2</sup>) dx
=
A<sup>-P/2</sup> &Gamma;(P/2) / 2
&nbsp; &nbsp; (if &nbsp;  A,P&gt;0)
</center>
<p> 
in each dimension.  (This integral in turn arises by making a power-law change of variables
in Euler's integral defining the &Gamma; function.)
</p>
<p>
All the triple integrals in sets 5, 6, and 7 can be done
by passing through the 2D u-containing integrals via
<center>
&int;&int;&int;<sub>-&infin;&lt;x/2+z/2&lt;y&lt;z&lt;+&infin;</sub> f(x, y, z) P(x) P(y) P(z) dx dy dz = 
&int;<sub>&frac12;&lt;u&lt;1</sub>&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> f(x, uy+[1-u]x, y) (y-x) P(x) P(uy+[1-u]x) P(y) dx dy du
</center>
and
<center>
&int;&int;&int;<sub>-&infin;&lt;x&lt;y&lt;z&lt;+&infin;</sub> f(x, y, z) P(x) P(y) P(z) dx dy dz = 
&int;<sub>0&lt;u&lt;1</sub>&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> f(x, uy+[1-u]x, y) (y-x) P(x) P(uy+[1-u]x) P(y) dx dy du
</center>
although for some of them there are much easier alternative methods.
I suppose the integrals in the 8th set could similarly be done using
<center>
&int;&int;<sub>-&infin;&lt;x,z&lt;+&infin;</sub>&int;<sub>x/2+z/2&lt;y&lt;&infin;</sub> f(x, y, z) P(x) P(y) P(z) dx dy dz = 
&int;<sub>&frac12;&lt;u&lt;&infin;</sub>&int;&int;<sub>-&infin;&lt;x&lt;y&lt;+&infin;</sub> f(x, uy+[1-u]x, y) (y-x) P(x) P(uy+[1-u]x) P(y) dx dy du
</center>
but this is not necessary;  the triple integral there with value (3&pi;)<sup>-1/2</sup> can be done
by straightforwardly integrating one integral at a time and the others then arise from symmetries.
All the tabulated results which are numbers were checked by numerical integration
(generally to 10 decimals although occasionally 25 or only 2; the ones
confirmed to only 2 decimals were done via Monte Carlo numerical
integration and are adorned with "&Dagger;.").
</p><p>
The 9th set of integrals are the moments of the "extreme value distribution" whose CDF is
<nobr>exp(-e<sup>-u</sup>)</nobr> on -&infin;&lt;u&lt;&infin;.  
They can be proved by recognizing that
</p>
<center>
&int;<sub>-&infin;&lt;u&lt;+&infin;</sub> u<sup>k</sup> exp(-e<sup>-u</sup>-u) du 
</center>
<p>
is the <i>k</i>th derivative
of &Gamma;(x) at x=1!  
That is because of the well known integral expression for the Gamma function 
</p>
<center>
&Gamma;(x+1) 
=
&int;<sub>-&infin;&lt;u&lt;+&infin;</sub> exp(xu-u-e<sup>-u</sup>) du
=
&int;<sub>0&lt;w&lt;+&infin;</sub> w<sup>x</sup>exp(-w) dw
</center>
<p>
where the two integrals are equivalent by changing variables w=e<sup>u</sup>.
That causes
</p>
<center>
(d<sup>k</sup>/dx<sup>k</sup>)&Gamma;(x+1) 
&nbsp; = &nbsp;
&int;<sub>-&infin;&lt;u&lt;+&infin;</sub> u<sup>k</sup>exp(xu-u-e<sup>-u</sup>) du.
</center>
<p>
The 10th set of integrals all are evaluated instantly by the symbolic algebra system MAPLE
(both definitely and indefinitely); every integral like them can be done
by methods explained in section 2.10 and 2.25 of Gradshteyn &amp; Rhyzik.
</p><p>
It is perhaps of interest that 
all the tabulated
integrals in sets 1-8 
which are numbers happen to be integer linear combinations of
the following six reals:
<center>
(2&pi;)<sup>-1/2</sup>, &nbsp; 
&pi;<sup>-1/2</sup>/8, &nbsp; 
1/12, &nbsp; 
3<sup>1/2</sup>/(12&pi;), &nbsp; 
(3/&pi;)<sup>1/2</sup>/12, &nbsp; 
(ln3)&pi;<sup>-1/2</sup>/32.
</center>
</p>

<!--
The difficult triple integrals denoted by
C<sub>1</sub>,  C<sub>2</sub>,  C<sub>3</sub>,  C<sub>4</sub>,  
were done by passing though appropriate
double integral formulae involving u (and then integrating du).
(Actually all the triple integrals can be done in that manner.)
All results which are numbers were checked by numerical integration to 10 decimals,
and the four difficult ones were checked with 25 decimals.
Re that, note that the N-point trapezoidal
rule works very well for 
integrals from -&infin; to +&infin; 
of analytic functions with exponential falloff at both ends
(truncate the integrals where
the integrand is below 10<sup>-N</sup>); this is well known, as a consequence of
the Euler-Maclaurin sum formula, to yield error dropping 
asymptotically faster than any power of N.

Here are some 4-candidate integrals that seem out of reach for MAPLE even using evalf:
P := (x) -> exp(-1/2*x^2)/sqrt(2*Pi);  
Int(int(int(int( P(w)*P(x)*P(y)*P(z), w = -infinity..x),
x = -infinity..y), y = -infinity..z),z=-infinity..infinity);  = 1/24.
Int(int(int(int( P(w)*P(x)*P(y)*P(z)*[w,x,y,z], w = -infinity..x),
x = -infinity..y), y = -infinity..z),z=-infinity..infinity);  = G_{1,2,3,4}^{(4)}/24
Int(int(int(int( P(w)*P(x)*P(y)*P(z)*(2*(y-w)/(z-w)-1)*x, w = -infinity..x),
x = -infinity..y), y = -infinity..z),z=-infinity..infinity); = -???
Int(int(int(int( P(w)*P(x)*P(y)*P(z)*(2*(y-w)/(z-w)-1)*y, w = -infinity..x),
x = -infinity..y), y = -infinity..z),z=-infinity..infinity); = ???
Int(int(int(int( P(w)*P(x)*P(y)*P(z)*(2*(y-w)/(z-w)-1)*z, w = -infinity..x),
x = -infinity..y), y = -infinity..z),z=-infinity..infinity); = ?????
Int(int(int(int( P(w)*P(x)*P(y)*P(z)*(2*(y-w)/(z-w)-1)*w, w = -infinity..x),
x = -infinity..y), y = -infinity..z),z=-infinity..infinity); = -?????

int(int(int(int( 
P(w)*P(u*w+(1-u)*z)*P(v*w+(1-v)*z)*P(z)*(2*(u*w+(1-w)*z-w)/(z-w)-1)*(u*w+(1-w)*z)*(z-w), 
w = -infinity..z),z=-infinity..infinity),u=0..1),v=0..1); = ???
-->

<blockquote>
<b>References for appendix B:</b>
<br>
I.S.Gradshteyn &amp; I.M.Ryzhik:
Table of integrals series and products,
(Alan Jeffrey and Daniel Zwillinger, eds.)
Seventh edition,
Academic Press  (Feb 2007).
<!-- 1171 pages ISBN number: 0-12-373637-4 -->
<br>
Integrals printed in the scientific literature after about 1980 unfortunately have
generally not been incorporated into tables and usually computerized tools do not know about
them either.  This includes a tremendous number of
polylogarithm-related integrals.   This book and its references contain 
a substantial number of them (but still far
from a complete list):
<br>
Vladimir A. Smirnov: Evaluating Feynman integrals, Springer (tracts modern physics #211) 2004.
</blockquote>

<a name="AppC"></a>
<h3> Appendix C: Spherical simplices, their moments, and Schl&auml;fli functions </h3>

<p>
<b>Why this appendix is here:</b>
The two available books mainly about Schl&auml;fli functions, namely Schl&auml;fli's
own book and B&ouml;hm &amp; Hertel, while excellent, are both in German and both
very out of date.  For example, both were written before the Murakami-Yano and Kellerhals 
formulas, and the nice Welzl proof technique, became available.  Nor do they discuss
(what I call) "moments."   This appendix is the only place that collects together the formulas
for S<sub>N</sub>(X) for all N&le;7, as well as the only place that does
quite a few other things.  Some of the content is original or partly so, although
the biggest results are merely restatements of contributions by previous workers.
<!-- My Murakami fomrula tested and good about branching.  Some of their formula versions not. -->
</p>
<p>
<b>Integrals</b> of N-dimensional 0-mean <i>normal distributions</i>
within regions delineated by
N <i>hyperplanes</i> through the origin, 
often arise in our investigations (of voting systems in random normal election model).
Further, the same integrals often arise <i>but</i> with the
integrand multiplied by various <b>powers</b> of the coordinates.
</p><p>
The powerless problem version is equivalent 
(via a linear transformation of the N coordinates to make the Gaussian become spherically 
symmetric, followed by a trivial radial definite integration
&ndash; the work involved in finding and doing that transformation is
comparatively trivial)
to the problem
of finding the <i>nonEuclidean area of a spherical (N-1)-simplex</i>,
an old problem in geometry first heavily studied by Ludwig Schl&auml;fli (1814-1895):
</p>
<center>
(&frac12;)K<sup>-N/2</sup>&Gamma;(N/2)
&int;<sub>spherical (N-1)-simplex</sub> 1&middot;d<sup>N-1</sup>Area 
= <br> =
&int;<sub>infinite flat-space N-simplex "cone" with apex at 0</sub> exp(-K|x|<sup>2</sup>) 
dx<sub>1</sub>dx<sub>2</sub>&hellip;dx<sub>N</sub>
, 
&nbsp;&nbsp;
K&gt;0.
</center>
<p>
If N&ge;3 this is a continuous function of the dihedral angles of the simplex (Luo 2008).
When powers are introduced too, then the problems become equivalent to finding "moments" of
spherical simplices, e.g. their center of mass, their "moments of inertia" etc:
</p>
<center>
(&frac12;)K<sup>-[N+A+B+&hellip;]/2</sup>&Gamma;([N+A+B+&hellip;]/2)
&int;<sub>spherical (N-1)-simplex</sub> 
[x<sub>1</sub><sup>A</sup>x<sub>2</sub><sup>B</sup>&hellip;]
d<sup>N-1</sup>Area 
= <br> =
&int;<sub>infinite flat-space N-simplex "cone" with apex at 0</sub> 
[x<sub>1</sub><sup>A</sup>x<sub>2</sub><sup>B</sup>&hellip;]
exp(-K|x|<sup>2</sup>) 
dx<sub>1</sub>dx<sub>2</sub>&hellip;dx<sub>N</sub>
, 
&nbsp;&nbsp;
K&gt;0.
</center>
<p>
These moment questions apparently have essentially never been studied.
</p><p>
In 2005, for the first time, Murakami and Yano found a reasonably nice formula,
involving the <i>dilogarithm</i>,
for the nonEuclidean volume of a tetrahedron (in a nonEuclidean geometry with
3 curved dimensions; this is 4 flat dimensions for the normal distribution integration problem).  
Although it had been realized already by J.Bolyai (1802-1860) and N.Lobachevsky (1792-1856)
that such formulae exist,
nobody had previously managed to
simplify it to a tolerably digestible form.
While M&amp;Y's formula is still rather horribly large, it's finally within the grasp of a human.
M&amp;Y's paper did not mention, however, the fact that
developments already known to Schl&auml;fli, Sommerville, and Coxeter meant that their 3-volume
formula also could
be used a finite number of times to obtain the 4-volume of a nonEuclidean <i>4-simplex.</i>
(Even-dimensional nonEuclidean simplex volumes are expressible as a finite sum of 
Schl&auml;fli functions of lower dimensionality, and Schl&auml;fli functions in dimension d
can be written as 1D integrals of  Schl&auml;fli functions 
in 2 fewer dimensions; see the next subsection.)
</p><p>
In a perhaps even more fantastic accomplishment, Ruth Kellerhals
in 1995 showed how, in principle, the nonEuclidean volume of a 5-simplex (5 curved dimensions, 
e.g. drawn on the
surface of a sphere in 6 flat dimensions)
could be expressed, in closed form
in terms of its dihedral angles, with the aid of the <i>tri</i>logarithm.   Specifically, 
she invoked dissections by C.H.Sah and H.E.Debrunner
showing that any hyperbolic n-simplex with n&ge;3 odd
could be divided into a bounded number of "doubly asymptotic orthoschemes."
"Orthoschemes" are simplices all of whose 2-faces are right-triangles.
The non-right dihedrals form a "path"
in the dual edge-graph and the two path-endpoints are the two "apex" vertices; 
the dihedral-angles-cosines matrix for
an orthoscheme is <i>tridiagonal</i>.
"Doubly asymptotic"
means that the two apex vertices both 
lie on the "sphere at hyperbolic infinity"; and finally the "subdivision" may involve
negative volumes, i.e. you both add and subtract 
the doubly asymptotic orthoschemes to get the desired simplex.
Then she found a volume formula for doubly asymptotic orthoschemes.   
Finally, if the simplex lies in spherical, not
hyperbolic, nonEuclidean geometry, then her volume formula must still work provided it
is appropriately "analytically continued" (see analytic continuation principle below).
</p><p>
Again, Kellerhals' work yields formulas in 1 dimension higher also.
</p><p>
Kellerhals has stated in print, though, that she doubts that
nonEuclidean <i>7</i>-simplex volumes are expressible in closed form using 
Li<sub>4</sub> and lower polylogarithms.  
(Apparently this question remains open as of 2008, but see Aomoto 1977.)
If so, then the exact closed formulas may end at dimension 6.
</p><p>
<b.Warning:</b>
Although <i>in principle</i> 
these results show that closed formulas exist for nonEuclidean simplex volumes
in every nonEuclidean dimension&le;6, there are a number of practical obstacles.
<b>First</b>, the formulas can involve analytic functions with multiple <i>branches</i>
such as (most simply) ln<i>z</i>.  
Complex analysts often wave that off
as a "minor issue."  
However, in a formula with, say, 100 terms each of which might
be in one of 3 plausible branches, that is 3<sup>100</sup> different branches!
Thus a naive user of such a formula might have to try 
3<sup>100</sup> branches of the formula before finding the right one in any
specific numerical instance!   [After going to this enormous effort, that person could
then write down some simple unambiguous expression as a fait accompli.]
Clearly, this by itself is unacceptable.
To <i>really</i> understand Schl&auml;fli functions,
a complete understanding of branching and how to handle it efficiently and correctly, 
needs to be presented.  This is probably doable but so far has not happened.
<b>Second</b>,
although in principle any simplex can be "dissected" into various simpler
kinds of simplices with the aid of "mere" linear algebra, in practice that too
is not a trivial matter.  Each such dissection (in, say, 6 dimensions)
involves various operations with 6&times;6 or 7&times;7 matrices
going on "behind the scenes," plus there may be various inequalities being tested 
to see if some vertex lies inside or outside some region, say, with different
actions being taken in the two cases.   Any attempt to write down in full a single formula
that does all these dissections and tests would result in a truly <i>immense</i> formula
so nobody ever actually does that.  Better would be to construct an
<i>algorithm</i>, not a formula, for evaluating Schl&auml;fli functions, 
but (a) algorithms are more difficult to analyse and write well than formulas, and (b) so
far nobody has done an acceptable job writing down such an algorithm anyhow (although
clearly this would be a doable feat).
</p><p>
We aren't going to overcome these complaints either here (and there is no way we could
do so without rendering the present paper unpublishable, anyhow); we are, however, going
to be more honest than the previous authors in that we do not pretend these issues are
minor.  We now resume the usual course of ignoring these issues.
</p><p>
So the powerless version of the problem can now be considered solved in closed form, 
at least in principle, if
the number of (flat) dimensions is at most 7.   
We shall now discuss the more general "powerful" problem
version and in particular see that pure-linear moments can be got in closed form in
flat space dimensions at most 8.
</p><p>
<b>The powerful problem version</b> is <i>reducible</i>
to the powerless one, because, 
<ol>
<li>
E.g.
</p>
<center>
(d<sup>k</sup>/da<sup>k</sup>) exp(-ax<sup>2</sup>-by<sup>2</sup>-cz<sup>2</sup>)
=
(-x<sup>2</sup>)<sup>k</sup> exp(-ax<sup>2</sup>-by<sup>2</sup>-cz<sup>2</sup>)
</center>
<p>
allowing us to get rid of any <i>even</i> number of powers of coordinates at the 
(comparatively trivial) cost of differentiating the answer with respect to a parameter; and 
</li><li>
We can introduce a factor of x by differentiating in this different way
</p>
<center>
(d/dx) exp(-x<sup>2</sup>-y<sup>2</sup>-z<sup>2</sup>)
=
-2x exp(-x<sup>2</sup>-y<sup>2</sup>-z<sup>2</sup>)
</center>
<p>
which, considering the new integrand is an exact partial-differential, allows us
<i>immediately</i> to integrate 
over that coordinate <i>indefinitely</i>, 
thus reducing the dimensionality of the problem by 1 &ndash; the 
integration is now over the <i>faces</i> rather than the interior of the simplex and 
note that the new,
lower-dimensional integrand does not involve the x factor, i.e. in this 
case is a Schl&auml;fli function in
1 fewer dimension.  (This can also be regarded as an application of Gauss's divergence theorem.
The divergence theorem can also be used to reduce the dimensionality of integration in
Schl&auml;fli function evaluation by 1, but at the cost of complicating the integrand and 
this approach
in most cases is less powerful than Schl&auml;fli's own reduce-dimension-by-2 trick.) We get
as a result (where f is the unit-length vector outward-normal to F)
<center>
&int;<sub>N-dimensional infinite simplicial cone S with apex at 0</sub> 
(a&middot;x)
exp(-|x|<sup>2</sup>/2) d<sup>N</sup>x
= <br> =
-&sum;<sub>Faces F of S</sub>
&int;<sub>F</sub>
(a&middot;f)
exp(-|x|<sup>2</sup>/2) d<sup>N-1</sup>x
</center>
<p>
(As the simplest example of this formula in action, the reader could use it to rederive 
the formulas in
section 3 of the table of integrals in appendix B.)
</li>
</ol>
Thus, in principle, <i>both</i> the powerful and powerless versions of the problem
are solved in closed form (in terms of the dilogarithm and its derivatives)
if the number of (flat) dimensions is at most 7;
and for pure-linear weighting functions (such as x<sub>1</sub>+3x<sub>2</sub> <i>without</i> 
a constant term) if the number is at most 8.
Further, solutions expressed in terms of <i>1D integrals</i> of elementary functions, dilogs,
and trilogs, are in principle available in dimensions up to 9
and thus in flat space dimensions up to 9
there is no difficulty in principle to evaluate everything to enormous
accuracy (N decimal places in time bounded by a polynomial in N).
</p><p>
That is excellent for us because for the 3-candidate
voting systems considered in this paper, the
Bayesian Regrets are 6-(flat)dimensional integration problems for
pure-linear moments,
i.e. <i>exactly</i> the maximum
humanity currently knows how to do in closed form using dilogs;
and 4 candidates similarly would be covered if we permit trilogs.
But unfortunately, the number of terms in closed form expressions
tends to suffer a <i>combinatorial explosion</i>
as the dimension is raised.
Because our BR closed forms are rather large &ndash; each would have over 1000 terms if
fully expanded &ndash; we are only going to evaluate the simplest ones fully
explicitly; for the rest
we are only going to <i>describe</i> how a sufficiently dedicated reader could do so,
and then just compute the results accurate to 5 decimal places by numerical integration.
</p>
<p>
<b>ANALYTIC CONTINUATION PRINCIPLE:</b>
Given a  formula expressing the volume of a spherical n-curved-dimensional
simplex analytically
in terms of its dihedral angles.
Then the same formula will also work for a hyperbolic simplex (up to branching) except that
it now will yield i<sup>n</sup> times the volume.
</p>
<p>
<b>Proof sketch:</b>
Arises for tiny simplices (and all we need to do is prove it with relative error that 
goes to zero as the simplex is made tinier;
then for non-tiny simplices it arises via dissection into smaller ones)
by expressing the volumes as integrals inside Euclidean "models" of nonEuclidean geometry;
also arises via induction on dimension via the Schl&auml;fli volume differential (discussed next
subsection).
<b>QED.</b>
</p>
<p>
<b>RATIONAL ANGLES CONJECTURE (J. Cheeger &amp; J. Simons):</b>
The content of a spherical tetrahedron (or higher-dimensional simplex)
with dihedral angles that each are <i>rational</i> 
multiples of 2&pi;, usually is <i>not</i>
a rational multiple of the whole content of the spherical space.
</p>
<p>
<b>Evidence:</b>
We mention this because it is (or should be) a 
famous conjecture and it is related to the key question for us
of whether simple closed formulas exist in nice cases.
Every spherical simplex which tiles the sphere (perhaps "multiply tiles" k-thick
for some number k&ge;1) has rational fractional volume.  One might initially
imagine that every rational-angled simplex <i>does</i> tile the surface of the sphere...
and this dream, while indeed true for spherical triangles,
appears to be false in every nonEuclidean dimension&ge;3:<br>
Let s=0.0033866503594829157714855987765394750920152423...
be the volume (relative to the volume 2&pi;<sup>2</sup>
of the whole of spherical 3-space)
of the spherical tetrahedron with (symmetric) dihedral angle matrix
<pre>
[*      2/5     19/47   7/17 ]
[2/5    *       15/37   12/29]
[19/47  15/37   *       17/43] &pi;
[7/17   12/29   17/43   *    ]
</pre>
I computed s to 1100 decimals and then computed 1000 partial quotients of
its simple continued fraction
</p><center>
[0; 295, 3, 1, 1, 1, 1, 3, 2, 2, 1, 2, 33, 5, 1, 39, 1, 3, 7, 4, 5, 5, 2, 5, 17, 4, 1,...]
</center><p>
Because the continued fraction did not terminate,
s, if rational, has denominator at least about 1000 digits long.
Therefore, it is almost certainly irrational, confirming the Cheeger-Simons conjecture.
</p>

<h3> C2. NonEuclidean (spherical and hyperbolic) geometry and simplices </h3>

<p>
(n-1)-dimensional "spherical geometry" may be regarded as
the spherical surface
</p>
<center>
(x<sub>1</sub>)<sup>2</sup>
+
(x<sub>2</sub>)<sup>2</sup>
+
&hellip;
+
(x<sub>n</sub>)<sup>2</sup>
=
1
</center>
<p>
in real n-dimensional space [which is n-dimensional "Euclidean geometry"].
Similarly (n-1)-dimensional "hyperbolic geometry" may be regarded
as the (upper hyperboloid) surface
</p>
<center>
x<sub>1</sub>
=
[1 + (x<sub>2</sub>)<sup>2</sup>
+ (x<sub>3</sub>)<sup>2</sup>
+&hellip;+ (x<sub>n</sub>)<sup>2</sup>]<sup>1/2</sup>.
</center>
<p>
A <b>simplex</b>
in Euclidean n-dimensional geometry means the convex hull of n+1
points (which are its "vertices").
But in the two nonEuclidean (n-1)-dimensional geometries, a
simplex shall instead mean this.
It has n vertices, which each are points lying on the geometry's defining
surface.
Take the convex hull of these n points and the additional
point (0,0,&hellip;,0).  This is a Euclidean n-simplex.
Now multiply every point (regarded as a real n-vector)
in that n-simplex by every positive real scaling factor.  The resulting point
set is an "infinite simplicial cone."
Finally, intersect this cone with the surface to get the nonEuclidean
simplex with the given n vertices.
</p>
<p>
Define D to be the n&times;n
diagonal <b>signature matrix</b>
</p>
<center>
D = diag(1, &plusmn;1, &plusmn;1,&hellip;, &plusmn;1).
</center>
<p>
where we use the plus sign for spherical and minus sign
for hyperbolic geometry.  (Then the equations of the
defining surfaces are just  x&middot;Dx=1.)
</p><p>
The <b>nonEuclidean volume</b>
of the simplex shall simply mean its
Euclidean surface area.
If we use only a subset of k of the n vertices, then we get a sub-simplex
which is a (k-1)-dimensional "face" of the simplex.
The "spherical <b>distance</b>" between points A and B is
arccos(A&middot;B)=2arcsin(|A-B|/2), 
and the hyperbolic distance is
arccosh(A&middot;DB)=2arcsinh(|(A-B)&middot;D(A-B)|<sup>1/2</sup>/2).
</p><p>
The "dihedral angle" between two faces of a <i>spherical</i>
nonEuclidean simplex is precisely the same as the Euclidean
angle between the corresponding flats of the simplicial cone &ndash;
but this usually does not work in hyperbolic geometry... except that it <i>does</i> work
if the intersection of those two flats 
happens to include the x<sub>1</sub> axis.  
That observation plus SO(1,n-1) invariance of the Minkowski inner product
leads to this unified result:
</p>
<p>
<b>HOW TO FIND DIHEDRAL ANGLES AND FACE-DEFINING HYPERPLANES FROM VERTEX COORDINATES:</b>
Let the coordinates (as n-dimensional real vectors) of the n vertices
of a nonEuclidean (n-1)-simplex (or the n vertices other than 0 of a Euclidean
n-simplex whose (n+1)<sup>th</sup> vertex is the origin) be the rows
of the n&times;n matrix X.
</p>
<p>
The face-defining hyperplanes are 
</p>
<center>
h<sub>1</sub>x<sub>1</sub> + h<sub>2</sub>x<sub>2</sub> + ... + h<sub>n</sub>x<sub>n</sub> &ge; 0
</center>
<p>
say, where each h vector specifies a different face and the signs are chosen so each h points
outwards.  To find the h vectors, compute the matrix inverse transpose
</p>
<center>
H = -X<sup>-T</sup>
</center>
<p>
and then the <i>k</i>th row of H is the h vector defining the face <i>not</i> containing vertex k.
<p>
Compute 
</p>
<center>
C 
= (XDX<sup>T</sup>)<sup>-1</sup>
= HDH<sup>T</sup>
</center>
<p>
which is a k&times;k symmetric matrix if
X is k&times;n with 0&lt;k&le;n.
(Normally k=n, but if we consider lower-dimensional subsimplices then k&lt;n.)
We now claim: the dihedral angle &theta;<sub>jk</sub>
between faces j and k of the simplex (i.e. between the face omitting
vertex j, and the face omitting vertex k) is
</p>
<center>
&theta;<sub>jk</sub>
=
&pi;-arccos(
C<sub>jk</sub>[C<sub>jj</sub>C<sub>kk</sub>]<sup>-1/2</sup>
)  &nbsp;&nbsp;&nbsp; [spherical]
</center>
<center>
&theta;<sub>jk</sub>
=
arccos(
C<sub>jk</sub>[C<sub>jj</sub>C<sub>kk</sub>]<sup>-1/2</sup>
) &nbsp;&nbsp;&nbsp; [hyperbolic]
</center>
<center>
&theta;<sub>jk</sub>
=
&pi; - arccos(
&plusmn; C<sub>jk</sub>[C<sub>jj</sub>C<sub>kk</sub>]<sup>-1/2</sup>
) &nbsp;&nbsp;&nbsp; [unified with + for spherical and - for hyperbolic]
</center>
where j&ne;k (and &theta;<sub>jj</sub>=0).
<p>
<b>HOW TO FIND NONEUCLIDEAN EDGE LENGTHS FROM VERTEX COORDINATES:</b>
Compute the symmetric n&times;n matrix E with
</p>
<center>
E<sub>jk</sub> =
arccos( (X<sup>T</sup>X)<sub>jk</sub> )
 &nbsp;&nbsp;&nbsp; [spherical]
</center>
<center>
E<sub>jk</sub> =
|argcosh( (X<sup>T</sup>DX)<sub>jk</sub> )| 
 &nbsp;&nbsp;&nbsp; [hyperbolic]
</center>
<center>
E<sub>jk</sub> =
(&plusmn;)<sup>-1/2</sup> arccos( (X<sup>T</sup>DX)<sub>jk</sub> )
 &nbsp;&nbsp;&nbsp; [unified with + for spherical and - for hyperbolic]
</center>
<p>
and then (as a consequence of one of the distance formulas above)
the nonEuclidean edge length from vertex j to vertex k is
E<sub>jk</sub>.
</p>
<p>
The <b>N-volume</b> and <b>surface</b> (N-1)-area of the <b>sphere</b>
&sum;<sub>1&le;k&le;N</sub>(x<sub>k</sub>)<sup>2</sup>&le;r<sup>2</sup>
are respectively
(for N&ge;0)
</p>
<center>
Vol<sub>N</sub>(r)=&pi;<sup>N/2</sup>r<sup>N</sup>/(N/2)!
, &nbsp; &nbsp; &nbsp;
Surf<sub>N</sub>(r)=N&pi;<sup>N/2</sup>r<sup>N-1</sup>/(N/2)!=2&pi;<sup>N/2</sup>r<sup>N-1</sup>/&Gamma;(N/2).
</center>
<p>
The fact that r&middot;Surf=N&middot;Vol  is immediate by differentiating with respect to r;
and the Surf formula is best proven by the following trick
</p>
<center>
&pi;<sup>N/2</sup>
=
&int;...&int; exp(-&sum;<sub>1&le;k&le;N</sub>(x<sub>k</sub>)<sup>2</sup>) dx<sub>1</sub>...dx<sub>n</sub>
=
Surf<sub>N</sub>(1) &middot; &int;<sub>r&gt;0</sub> exp(-r<sup>2</sup>) r<sup>N-1</sup> dr
=
Surf<sub>N</sub>(1) &middot; &Gamma;(N/2)/2.
</center>
<p>
For brevity write O<sub>N</sub>=2&pi;<sup>N/2</sup>/&Gamma;(N/2)
so that  
Surf<sub>N</sub>(r)=O<sub>N</sub>r<sup>N-1</sup> 
and
</p>
<center>
O<sub>0</sub>=0,
&nbsp;
O<sub>1</sub>=2,
&nbsp;
O<sub>2</sub>=2&pi;,
&nbsp;
O<sub>3</sub>=4&pi;,
&nbsp;
O<sub>4</sub>=2&pi;<sup>2</sup>,
&nbsp;
O<sub>5</sub>=8&pi;<sup>2</sup>/3,
&nbsp;
...
</center>
<p>
The recurrence 
O<sub>N</sub>=O<sub>N-2</sub>2&pi;/(N-2)
is an immediate consequence of our definition, but also arises directly from the Schl&auml;fli
volume differential (see below).
</p>

<h3> C3. Schl&auml;fli function formulary </h3>

<p>
Amazingly, nobody seems to have invented a good notation for Schl&auml;fli functions before.
Therefore we do it.
The task is a little difficult because people want to compute simplex volumes from
<i>either</i>
<ol type="i">
<li>
The symmetric N&times;N
matrix giving the (internal) dihedral angles &theta;<sub>jk</sub>
</li><li>
The vertex coordinates given by the rows of the N&times;N matrix X.
</li><li>
The face-defining hyperplanes (encoded by the rows of the N&times;N matrix H).
</li><li>
The symmetric N&times;N matrix E of the nonEuclidean edge-lengths.
</li>
</ol>
<p>
It seems best to make the argument of the Schl&auml;fli function be the vertex coordinates X.
The others are easily deducible from X (see above) but not the reverse (since it is
a many-to-one map); albeit
suitable X's can be back-deduced via D-modified Cholesky matrix factorization.
<p>
So let the Schl&auml;fli function S<sub>N</sub>(X) be the (N-1)-volume 
of the simplex (drawn on a sphere of radius=1 or in hyperbolic geometry of constant curvature 
<nobr>-1</nobr>) with vertices that are the rows of X.
The subscript N gives the size of the matrix, which is the same as the
flat-space-dimensionality, 
which is 1 plus the curved-space dimensionality.
Then:
</P>
<center>
<b>S<sub>1</sub>(X)</b> = 1,
<br><br>
<b>S<sub>2</sub>(X)</b> = E<sub>12</sub> = E<sub>21</sub>.
</center>
<p>
Somewhat illegitimately, people often refer to E<sub>12</sub> as &theta;<sub>12</sub>,
i.e. the "dihedral angle" of a nonEuclidean 1-simplex is the same as its length.
This convention simplifies various formulae. 
</p>
<!-- |arccos(A&middot;DB)| = 2|arcsin([(A-B)&middot;D(A-B)]<sup>1/2</sup>/2)|
<br>
where A and B are the 2-vectors giving the two vertices of the 1-simplex,
i.e. the two rows of X,
<br>
and D=diag(1, &plusmn;1)  is the signature matrix-->
<center>
<b>S<sub>3</sub>(X)</b>
= &plusmn;(&theta;<sub>12</sub> 
+ &theta;<sub>13</sub> 
+ &theta;<sub>23</sub> 
- &pi;)  &nbsp;&nbsp;&nbsp; (this is <b>"angle defect"</b>; + for spherical, - for hyperbolic)
</center>
<p>
To describe (my version of) the <b>Murakami-Yano-Ushijima formulas</b> 
for S<sub>4</sub>:
There are two &ndash; beautifully related &ndash;
versions of the formula, one based on dihedral angles 
and the other based on nonEuclidean edge lengths, but we shall only describe the former.
</p><p>
Let &xi;<sub>jk</sub>=exp(i&theta;<sub>jk</sub>) where i<sup>2</sup>=-1.
Denote the dilogarithm by
L(z) = Li<sub>2</sub>(z)
for brevity.
<!--
Let
</p><center>
A=&theta;<sub>12</sub>,
B=&theta;<sub>13</sub>, 
C=&theta;<sub>23</sub>,
D=&theta;<sub>34</sub>,
E=&theta;<sub>24</sub>,
F=&theta;<sub>14</sub>,
</center><p>
</p><center>
a=&xi;<sub>12</sub>,
b=&xi;<sub>13</sub>, 
c=&xi;<sub>23</sub>,
d=&xi;<sub>34</sub>,
e=&xi;<sub>24</sub>,
f=&xi;<sub>14</sub>,
</center><p>
and
<center>
Define the function Q(a,b,c) (which is invariant under permutations of its three arguments) via
<center>
-4 Q(a,b,c) 
= 
L(-ab/c)+L(-ac/b) + L(-bc/a)
+ L(-1/(abc)) 
+ (ln a)<sup>2</sup> 
+ (ln b)<sup>2</sup> 
+ (ln c)<sup>2</sup>.
</center><p>
-->
Define the function U(z) <!--and &Delta;(z)--> via
</p><center>
U(z) = 
L(z) 
+ L(&xi;<sub>12</sub>&xi;<sub>13</sub>&xi;<sub>34</sub>&xi;<sub>24</sub>z) 
+ L(&xi;<sub>12</sub>&xi;<sub>23</sub>&xi;<sub>34</sub>&xi;<sub>14</sub>z) 
+ L(&xi;<sub>13</sub>&xi;<sub>23</sub>&xi;<sub>24</sub>&xi;<sub>14</sub>z) 
- L(-&xi;<sub>12</sub>&xi;<sub>13</sub>&xi;<sub>23</sub>z) 
- L(-&xi;<sub>12</sub>&xi;<sub>24</sub>&xi;<sub>14</sub>z) 
- L(-&xi;<sub>13</sub>&xi;<sub>34</sub>&xi;<sub>14</sub>z) 
- L(-&xi;<sub>23</sub>&xi;<sub>34</sub>&xi;<sub>24</sub>z).
<!-- this is intentionally off the Murakami defn by factor of 2-->
</center><p>
Of course, U is really a function of the 
&xi;<sub>jk</sub> as well as of z, but for notational convenience we act as though it 
depends only on z and the &xi;<sub>jk</sub> are extraneous parameters.
The formula for U can be remembered easily via the graphical mnemonic
</p>
<center>
U(z) = L(z) + &sum;<sub>&#9723;</sub> L() - &sum;<sub>&Delta;</sub> L().
</center>
<p>
<!--
and
</p><center>
&Delta;(z) = 
Q(a,b,c) + Q(a,e,f) + Q(b,d,f) + Q(c,d,e) + [ln(a)ln(d)+ln(b)ln(e)+ln(c)ln(f)]/2.
</center><p>
-->
Define the 4&times;4 symmetric "Grammian matrix" G by 
<!--
G<sub>jk</sub> = &plusmn;C<sub>jk</sub>[C<sub>kk</sub>C<sub>jj</sub>]<sup>-1/2</sup>
for j&ne;k (and G<sub>jj</sub>=1) with + for spherical and - for hyperbolic.
Then our previous formulas for the dihedral angles were
&theta;<sub>jk</sub>=arccos(-G<sub>jk</sub>) 
in spherical and hyperbolic geometry respectively, so that
-->
<nobr>G<sub>jk</sub> = -cos(&theta;<sub>jk</sub>)</nobr> if j&ne;k
and G<sub>jj</sub>=1.
Let z<sub>&plusmn;</sub> be 
</p>
<pre>
                          sin&theta;<sub>12</sub>sin&theta;<sub>34</sub>+sin&theta;<sub>13</sub>sin&theta;<sub>24</sub>+sin&theta;<sub>14</sub>sin&theta;<sub>23</sub> &plusmn; det(G)<sup>1/2</sup>
z<sub>&plusmn;</sub> = -2 ------------------------------------------------------------------------------------
        &xi;<sub>12</sub>&xi;<sub>34</sub> + &xi;<sub>13</sub>&xi;<sub>24</sub> + &xi;<sub>23</sub>&xi;<sub>14</sub> + &xi;<sub>12</sub>&xi;<sub>13</sub>&xi;<sub>14</sub> + &xi;<sub>12</sub>&xi;<sub>23</sub>&xi;<sub>24</sub> + &xi;<sub>13</sub>&xi;<sub>23</sub>&xi;<sub>34</sub> + &xi;<sub>14</sub>&xi;<sub>24</sub>&xi;<sub>34</sub> + &xi;<sub>12</sub>&xi;<sub>13</sub>&xi;<sub>14</sub>&xi;<sub>23</sub>&xi;<sub>24</sub>&xi;<sub>34</sub>
</pre>
which can also be remembered via analogous mnemonics, e.g. the denominator is "// + Y + all."
<!--
Let z<sub>&plusmn;</sub> be the two nontrivial solutions of the (basically quadratic) equation
ARE THEY REAL???
</p><center>
(d/dz) U(z) = &pi;ik/z
</center><p>
where k is a small integer (different k arise if we go to another "branch"
of the function).
-->
Define
</p><center>
MYU(&theta;, z) = U(z) - z U'(z) ln(z) 
</center><p>
Then
</p><center>
<b>S<sub>4</sub>(X)</b> = [ MYU(&theta;, z<sub>+</sub>) - MYU(&theta;, z<sub>-</sub>) ] (&plusmn;)<sup>1/2</sup> / 4
</center><p>
with + sign for spherical and - for hyperbolic geometry.
Of course on the right hand side z<sub>&plusmn;</sub> are really just a function of
the &theta;
and hence so is the entire right hand side, call it
S<sub>4</sub>(X)=<b>F<sub>4</sub>(&theta;)</b>; again the only reason we act otherwise
is notational convenience.
The value of S<sub>4</sub> will be
pure-real (and the  formula requires that the correct 
branch be taken such that this happens,
and such a branch always exists).
It appears empirically in my tests so far that simply using the standard branches for ln 
(slit along negative real axis) and Li<sub>2</sub> (slit on ray from +1 to +&infin;)
works.
</p>
<center>
<b>S<sub>5</sub>(X) </b>
= (2/3)&sum;<sub>1&le;a&le;5</sub> F<sub>4</sub>(&theta;<sup>row &amp; col a omitted</sup>)
- (&pi;/3)&sum;<sub>1&le;a&lt;b&le;5</sub> &theta;<sub>ab</sub>
+ 4&pi;<sup>2</sup>/3
<br>
&nbsp;&nbsp;&nbsp;
(Max Dehn's "Zerlegungsinvariant" on his p.572)
</center>
<p>
Although we have written our S<sub>n</sub>(X) formulae using &plusmn; signs to
handle spherical (+) and hyperbolic (-), they could instead have been written using 
absolute value
signs |x+iy|=(x<sup>2</sup>+y<sup>2</sup>)<sup>1/2</sup>
because the answer is always nonnegative real.
</p>
<a name="DimRed"></a>
<p>
<b>A DIMENSION-REDUCTION PRINCIPLE:</b>
A spherical D-curved-dimensional spherical 
simplex is normally defined by D+1 bounding hyperplanes,
all passing through the origin in (D+1)-dimensional flat space.
However, if there are <i>fewer</i> such hyperplanes, then the volume of the resulting object,
relative to the volume of the entirety of the spherical space, is
the same as that of the lower-dimensional simplex with the same dihedral angles.
</p>
<p>
The simplest example of that is a "lune" or "2-gon" drawn on the 2-dimensional surface of
an ordinary ball in &ge;3 dimensions.  
(I.e. cut a sphere with two hyperplanes through its center.)
Its area (relative to
the surface of the whole sphere)
is the same as its dihedral angle divided by 2&pi;, <i>no matter how many dimensional</i>
the sphere is.
</p>
<p>
<b>AN IMPORTANT IDENTITY</b>
obeyed by Schl&auml;fli functions arises from the 
following trivial geometrical observation.
Consider two abutting (n-1)-simplices sharing a common (n-2)-dimensional face.  
This polytope P can either be regarded as
two simplices sharing a face, <i>or</i>, by splitting 
along a line joining the "antipodal" vertices of the two simplices,
as n different simplices all interior-disjoint and all sharing a common edge.
Either way of looking at it must yield the same total (n-1)-volume.
Thus, letting Y denote the (n+1)&times;n matrix whose rows give the
coordinates of the n+1 vertices (regarding the first and last rows as the two
"antipodal" vertices), we have
</p>
<center>
S<sub>n</sub>(Y<sup>(1)</sup>) &plusmn; S<sub>n</sub>(Y<sup>(n+1)</sup>)
=
&plusmn;
S<sub>n</sub>(Y<sup>(2)</sup>) 
&plusmn;
S<sub>n</sub>(Y<sup>(3)</sup>) 
&plusmn;&hellip;&plusmn;
S<sub>n</sub>(Y<sup>(n)</sup>) 
</center>
<p>
where Y<sup>(b)</sup> means "Y with row b omitted."
The second simplex
could be on the opposite or same side of the shared face, 
which is the reason for the &plusmn; sign on the left hand side.  
The identity is only claimed to work if all the &plusmn; signs are chosen correctly;
in the case where P is convex, e.g. where all dihedral angles 
to the common face are acute, all signs are +.
At least two sign-assignments always will be valid.
</p>
<p>
<b>FORMULAE FOR DOUBLY-ASYMPTOTIC ORTHOSCHEMES:</b>
A 2-dimensional orthoscheme means a right-triangle.
An "orthoscheme" is a n-simplex all of whose lower-dimensional faces
are also orthoschemes.   
An n-dimensional orthoscheme is characterized by an n-tuple of
dihedral angles 
&alpha;<sub>1</sub>, &alpha;<sub>2</sub>, ..., &alpha;<sub>n</sub>
forming a "simple path" linking n+1 successive faces of the simplex,
and 
&alpha;<sub>j</sub>=&theta;<sub>jk</sub>
with k=j+1.
Every dihedral not on this path is automatically a right angle.
Every non-right angle of an orthoscheme is automatically an <i>acute</i> angle
(B&ouml;hm &amp; Hertel, Hilfsatze 2 page 155).
If, instead of the path of faces, we consider the vertices <i>not</i> on each face, then
we instead get a (dual) path of edges joining n successive vertices.
A singly- or doubly-asymptotic orthoscheme means one such that one (respectively both) of
the dual-path-endpoints lie on the sphere at hyperbolic infinity.
(And it is impossible for any other vertex to lie at infinity, so "doubly" is the most-asymptotic
an orthoscheme can be.)
</p><p>
Kellerhals (her page 646) showed 
that 
in order for an n-orthoscheme (n&ge;3) to be doubly-asymptotic, it was necessary and 
sufficient that it satisfy 
the (n-3)-deck continued-fraction identity
</p>
<pre>
             cos<sup>2</sup>&alpha;<sub>1</sub>  cos<sup>2</sup>&alpha;<sub>2</sub>     cos<sup>2</sup>&alpha;<sub>n-3</sub>
cos<sup>2</sup>&alpha;<sub>0</sub> = 1 - ------  ------ ... --------  cos<sup>2</sup>&alpha;<sub>n-2</sub>
              1 -     1 -         1 -
</pre>
<p>
<i>and</i> all the n+1 cyclically-shifted versions of this identity
got by adding any fixed integer k to every subscript modulo n+1.
(Here &alpha;<sub>0</sub>
is regarded as being <i>defined</i> by the first such identity. )
Thus in the doubly-asymptotic case,
an orthoscheme is specified by only n-2 of its n nontrivial dihedrals.
[If n=2 then
the identities that must be satisfied instead are merely 
&alpha;<sub>1</sub>=&alpha;<sub>2</sub>=0.]
</p><p>
<!--
This is actually an astonishing (n-2)-variable identity satisfied by Schl&auml;fli functions.
It generalizes 
the astounding "pentagonal" identity 
</p>
<center>
F(x) + F(y) = F(x(1-y)/(1-xy)) + F(xy) + F(y(1-x)/(1-xy))
</center>
<p>
found by L.J.Rogers in 1907 where F(z)=Li<sub>2</sub>(z)+ln(1-z)ln(z)/2.
-->
</p><p>
Any n-dimensional simplex can be divided into at most (n+1)! 
n-dimensional orthoschemes
(some perhaps having negative volume); and any n-dimensional 
orthoscheme in hyperbolic geometry with n&ge;3 <i>odd</i> may
be expressed as a sum of (a number at most quadratic in n of) 
<i>doubly-asymptotic</i> orthoschemes (again with some perhaps having negative volume),
while if n is <i>even</i> we can express its volume as a sum of lower dimensional
orthoscheme volumes.
Therefore, to compute nonEuclidean simplex volumes,
it suffices in principle
merely to know formulas for computing volumes of
<i>doubly-asymptotic</i> odd-dimensional orthoschemes.
</p><p>
That is good because simplex volume formulae
can simplify dramatically if we restrict attention to orthoschemes,
and even more dramatically if they are doubly-asymptotic.
Let
</p>
<center>
Orth<sub>n</sub>(&alpha;<sub>1</sub>, &alpha;<sub>2</sub>,&hellip;, &alpha;<sub>n</sub>)
</center>
<p>
denote the n-volume of the 
nonEuclidean orthoscheme with dihedral angles
(in order along the "path") &alpha;<sub>1</sub>, &alpha;<sub>2</sub>,&hellip;, &alpha;<sub>n</sub>,
and write
DAO<sub>n</sub>
instead of
Orth<sub>n</sub>
in situations where the orthoscheme is known to be 
doubly-asymptotic. The subscript n <i>now</i> denotes the <i>curved-space</i> dimensionality
of the simplex, which is the same as the number of arguments of the function.
</p><p>
<!--The hyperbolic area of a doubly-asymptotic right triangle is just 
DAO<sub>2</sub>=&pi;/2.-->
Define the &pi;-periodic "diLobachevsky function" 
<p><center>
&#1051;<sub>2</sub>(&alpha;) 
=
-&#1051;<sub>2</sub>(-&alpha;) 
= 
(i/4) [Li<sub>2</sub>(e<sup>-2i&alpha;</sup>) - Li<sub>2</sub>(e<sup>2i&alpha;</sup>)] 
=
(-1/2) &int;<sub>0&lt;u&lt;&alpha;</sub> ln(4sin<sup>2</sup>u) d<i>u</i>.
</center><p>
("&#1051;" is the first letter of Lobachevsky's name.)
Then Lobachevsky's formula (rederived by Milnor) for the hyperbolic 3-volume of a 
doubly-asymptotic 3-orthoscheme is just <!--Kellerhals; Milnor p198 eq11 agrees-->
</p>
<center>
DAO<sub>3</sub> = (1/2) &#1051;<sub>2</sub>(&alpha;)
</center>
<p>
where &alpha;=&alpha;<sub>1</sub>=&alpha;<sub>3</sub>=&pi;/2-&alpha;<sub>2</sub>
(and these equalities must hold, otherwise the orthoscheme could not have been doubly-asymptotic).
</p>
<p>
Kellerhals' formula for the volume of a
doubly-asymptotic 5-orthoscheme is as follows.  
First, she defines &alpha;<sub>0</sub>
and &lambda; by
</p>
<center>
 &lambda; 
= cot(&alpha;<sub>0</sub>) tan(&alpha;<sub>3</sub>) 
= tan(&alpha;<sub>1</sub>) cot(&alpha;<sub>4</sub>) 
= cot(&alpha;<sub>2</sub>) tan(&alpha;<sub>5</sub>) 
</center>
<p>
(and these equalities must hold otherwise the orthoscheme could not have been doubly-asymptotic).
Then (perhaps up to branching)
</p>
<center>
32 DAO<sub>5</sub> 
=
<nobr>- 4 K(1/&lambda;,0; &alpha;<sub>1</sub>)</nobr>
<nobr>- 2 K(&lambda;,0;&alpha;<sub>2</sub>)</nobr>
<nobr>+ 4 K(1/&lambda;,0;&pi;/2-&alpha;<sub>0</sub>)</nobr>
<nobr>- 2 K(&lambda;,0;&alpha;<sub>4</sub>)</nobr>
<nobr>- 4 K(1/&lambda;,0;&alpha;<sub>5</sub>)</nobr>
<nobr>+ K(&lambda;,-&pi;/2-&alpha;<sub>1</sub>;&pi;/2+&alpha;<sub>1</sub>+&alpha;<sub>2</sub>)</nobr>
<nobr>+ K(&lambda;,-&pi;/2+&alpha;<sub>1</sub>;&pi;/2-&alpha;<sub>1</sub>+&alpha;<sub>2</sub>)</nobr>
<nobr>- K(&lambda;,-&pi;/2-&alpha;<sub>1</sub>;&pi;+&alpha;<sub>1</sub>)</nobr>
<nobr>- K(&lambda;,-&pi;/2+&alpha;<sub>1</sub>;&pi;-&alpha;<sub>1</sub>)</nobr>
<nobr>- K(&lambda;,-&pi;/2-&alpha;<sub>5</sub>;&pi;+&alpha;<sub>5</sub>)</nobr>
<nobr>- K(&lambda;,-&pi;/2+&alpha;<sub>5</sub>;&pi;-&alpha;<sub>5</sub>)</nobr>
<nobr>+ K(&lambda;,-&pi;/2-&alpha;<sub>5</sub>;&pi;/2+&alpha;<sub>5</sub>+&alpha;<sub>4</sub>)</nobr>
<nobr>+ K(&lambda;,-&pi;/2+&alpha;<sub>5</sub>;&pi;/2-&alpha;<sub>5</sub>+&alpha;<sub>4</sub>)</nobr>
</center>
<p>
where 
</p>
<center>
K(a,b;x) = &int;<sub>&pi;/2&lt;v&lt;x</sub>  &#1051;<sub>2</sub>(arctan(tan(v)/a)-b) dv
</center>
<p>
which, as Kellerhals showed, may be expressed as a complicated closed formula 
(about two pages long)
involving 
Li<sub>3</sub>, Li<sub>2</sub>, ln, trig, and arctrig.
Rather than trying to write down that formula, we shall explain how to derive it.
</p>
The first step in doing the K(a,b;x) integral indefinitely is to rewrite it is
</p>
<center>
&int; &#1051;<sub>2</sub>(u) d arctan(a&middot;tan(b+u))
</center>
<p>
then "integrate by parts" to get
</p>
<center>
&#1051;<sub>2</sub>(u) arctan(a&middot;tan(b+u))
+
(1/2) &int; ln(4sin<sup>2</sup>u) arctan(a&middot;tan(b+u)) du.
</center>
<p>
We then use the addition formula for tangent to replace the integral in the above by
</p>
<center>
&int; ln(4sin<sup>2</sup>u) arctan(a[cot(u)+c]/[c&middot;cot(u)-1]) du
</center>
<p>
where c=cot(b).  We now change variables from u to t=cot(u), where du=-dt/(1+t<sup>2</sup>).
The integral above now becomes
</p>
<center>
&int; ln([1+t<sup>2</sup>]/4) arctan(a[t+c]/[ct-1])  dt/(1+t<sup>2</sup>).
</center>
<p>
Now use arctan(z)=(i/2)[ln(1-iz)-ln(1+iz)], ln(1/x)=-ln(x), ln(fg)=ln(f)+ln(g),
1+t<sup>2</sup>=(1-it)(1+it), and -2/(1+t<sup>2</sup>)=1/[1-it] + 1/[1+it]
to reduce the problem to integrals of the forms
</p>
<center>
&int; ln(ax+b) ln(cx+d) dx / (1+kx)
&nbsp;&nbsp; and &nbsp;&nbsp;
&int; ln(ax+b) dx / (1+kx)
</center>
<p>
which Mathematica knows how to do immediately using polylogs of order&le;3.
[Neither Mathematica nor Maple (as of late 2008) can do the original K(a,b;x)
integral or any of the intermediate integrals directly, though.]
</p>
<a name="FormLen"></a>
<p>
<b>Note on computer programs and <i>formula length</i>:</b>
As part of the research for this paper,
I wrote the first 
<a href="SchlafliProgram">computer program</a> &ndash; in MAPLE &ndash; for exact evaluation of
Schl&auml;fli functions S<sub>n</sub>(X)
for all n&le;5.  
When asked to print the formula for  S<sub>5</sub>(X) for 
a 5&times;5 matrix X consisting of (hopefully fairly generic)
1-digit integers (and in the x<sub>1</sub> coordinate sometimes integer square roots as required to 
get a legitimate hyperbolic 4-simplex),
it (after an 83-second delay) prints out a 
result 78 pages long, involving many integers about 80 digits long each.
This is despite the fact that MAPLE prints the formula in a somewhat-condensed form
involving 48 common subexpressions printed in a seperate section (some expressed in
terms of others recursively) &ndash; the fully-expanded formula would be longer.
For simplices with high symmetry, however, the formulas can be a lot shorter because
many terms can be combined.
</p><p>
Using Kellerhals' formula, it should in principle be possible 
to extend the program to handle all n&le;7.  
However, because nobody has (so far) explicitly written down the coordinates of the 
requisite simplex "dissections," nor have theorems been proven making it maximally explicit what
is the correct "branch" to use in these formulae,
this job would not be completely trivial.
If it were done, then in the generic n=6 case the simplex would be dissected into a 
sum/difference
of about 1000 doubly-asymptotic orthoschemes (or more precisely,
an appropriately analytically continued version of them; only 24 would be
needed had we been able to drop the doubly-asymptoticity demand)
each of whose volumes would be expressed as a weighted sum of 13 K-functions, where the formula
for a K function is about 2 pages long.  So, in net, I estimate the resulting formula
for S<sub>6</sub>(X) for any given generic X would about 25,000 pages long.
Then the formula for S<sub>7</sub>(X) (which could be produced
using the even-parity dimension-reduction 
formula we'll discuss below) would be 1-to-20 times larger still &ndash; perhaps as
long as 500,000 pages and with a delay before the computer prints it out
(crudely assuming runtime scales linearly with the formula length) of 6 days.
</p>
<p>
It is possible that some unknown technique might enable these
nonEuclidean volume formulae to be simplified considerably.  However, the formula
for the <I>Euclidean</i> volume of a 7-simplex is an 8&times;8 determinant
with 1's in the first row, 
which if fully expanded into monomials would involve 5040 terms, which would 
fill about 50 pages.   I therefore do not believe  that any fully-expanded
form of the nonEuclidean formula could be shorter than 300 pages.
</p>
<p>
The reason I am mentioning all this is that some readers of this paper have been asking
"You claim all your voting-system regrets are available as exact closed formulas... so what 
are they?"  The answer is that we <i>have</i> made it clear those formulas exist and 
how any (sufficiently-determined) reader could write them down, but <i>we</i> have
only written them down in cases where the formula is particularly short.
</p>
<a name="SVDD"></a>
<p>
<b>Schl&auml;fli's volume differential</b> formula states that, if we consider a process 
that continuously and smoothly distorts our simplex's dihedral angles, then
</p><center>
dS<sub>N</sub>(X)  &nbsp;  = &nbsp;  (&plusmn;1)/(N-2) &nbsp; &middot; &nbsp; 
&sum;<sub>1&le;b&le;N</sub>&sum;<sub>1&le;a&lt;b</sub> 
S<sub>N-2</sub>(X<sup>{ab}</sup>) 
d&theta;<sub>ab</sub>
</center>
<p>
where &plusmn;1 is the curvature of the nonEuclidean space and where
X<sup>{ab}</sup> denotes the (N-2)&times;(N-2) matrix of coordinates of the N-2
non-a non-b vertices of the nonEuclidean simplex,
<i>projected</i> into the subspace with zero inner product with the 2-space spanned
by vertices a and b (using the signature=[+&plusmn;&plusmn;&hellip;&plusmn;]
inner product) and <i>renormalized</i>
to lie on the unit sphere in N-2 flat dimensions; since this subspace is "spacelike"
it contains a unit sphere consisting of the points whose inner product with themselves is 1.
[And we may similarly projectively define 
X<sup>s</sup> where s is <i>any</i> subset of the N vertices, in which case
S<sub>N-|s|</sub>(X<sup>s</sup>)
would be the measure of the face of our simplex not containing vertices in the set s.
Here |s| is the cardinality of s.]
Thus the term S<sub>N-2</sub>(X<sup>{ab}</sup>) represents the nonEuclidean volume of the
codimension-1 <i>face</i> of the simplex not containing vertices a and b.
This allows the volume of a nonEuclidean simplex to be expressed as an integral of
Schl&auml;fli functions in 2 fewer dimensions [make the path of integration start at some
simplex of known volume, such as S<sub>N</sub>=0 for an infinitesimal regular one, for which 
&theta;<sub>jk</sub>=arcsec(N-1)
for all j&ne;k; and end at the desired simplex].
<!--; and
the theorem (due to me) that if nonEuclidean or Euclidean simplices are parameterized by
cos(&theta;<sub>jk</sub>/2)<sup>2</sup>
then the set of simplices is a convex set,
allows
suitable paths to be found.-->
How is this proven?  Two proofs are given by Kneser 1936 and Milnor.
To sketch yet another proof idea:
the volume differential is "really" 
just the 2D angle-defect formula, and it may be proven in basically the same
way. 
First we see trivially
that it is (as it should be) additive for a simplicial subdivision.
To complete the proof, it suffices to
prove its validity for tiny (near-Euclidean) simplices, at least
up to relative error which goes to zero as we get tinier. 
In this limit the nonEuclidean volumes reduce to mere Euclidean volumes
and the result will be a consequence of certain matrix determinant identities.
<!--
liner algebra
facts that ACTUALLY JUST EXPN BY MINORS???
<ol type="i">
<li>
The volume V of
the <i>Euclidean</i> n-simplex with vertices 
X<sub>0</sub>, X<sub>1</sub>,..., X<sub>n</sub> (each an n-vector)
is 1/(n+1)! times
the determinant of the (n+1)&times;(n+1) matrix with <i>k</i>th row (1, X<sub>k</sub>).
</li><li>
Let M be the integral of r<sup>2</sup> within this simplex (the "second moment about the origin").
Then
<center>
M = [(n+1)(n+2)]<sup>-1</sup>&sum;<sub>0&le;j&le;n</sub> |X<sub>j</sub>|<sup>2</sup>
+ (n+1)Q<sup>2</sup>/(n+2)
</center>
where (n+1)Q=&sum;<sub>0&le;j&le;n</sub> X<sub>j</sub>, i.e. Q is the centroid.
</li>
</ol>
-->
<!--
Schl&auml;fli indeed observed (which can make life a good deal easier)
that it suffices to prove it for "orthoschemes," a special type of simplex 
that generalizes the notion of a "right triangle" to multidimensions.
-->
</p><p>
[Formulas such as Murakami-Yano's can be proven by demonstrating their validity for 
a few particular simplices, and 
then by differentiation verifying that they agree with the Schl&auml;fli volume differential.]
</p>
<p>
<b>If N&ge;1 is odd</b>, then S<sub>N</sub>(X) may be expressed in terms of
lower dimensional Schl&auml;fli functions via the Brianchon-Gram-Sommerville identity
</p>
<center>
S<sub>N</sub>(X) &middot; 2/O<sub>N</sub>
&nbsp; = &nbsp;
|&sum;<sub>s&sub;{1,2,...,N}</sub>
(-1)<sup>N-|s|</sup> 
S<sub>N-|s|</sub>(X<sup>s</sup>) / O<sub>N-|s|</sub>|
</center>
<p>
where the sum is over all 2<sup>N</sup>-1 subsets s of {1,2,...,N}
and |s| denotes the cardinality of s (and X<sup>s</sup> is defined above, in
the <a href="#SVDD">discussion</a> of Schl&auml;fli's volume differential)
and we agree to use the conventions
</p>
<center>
S<sub>1</sub>()/O<sub>1</sub>=1/2,
&nbsp; &nbsp; &nbsp;
S<sub>0</sub>()/O<sub>0</sub>=1.
</center>
<p>
The reason this only works for <i>odd</i> N is that the coefficient "2" on the left hand side
is really [1+(-1)<sup>N-1</sup>];
this whole relation is really a discrete form 
(an "angle-sum relation") of the "Gauss-Bonnet theorem" from
topology.  See McMullen's paper for discussion.  
We now provide a <b>proof</b> by following a brilliantly simple
probabilistic idea by Welzl 1994.
</p><p>
If a convex n-polytope P is orthogonally projected in a random direction
(i.e. chosen uniformly at random on the sphere)
into an (n-1)-dimensional subspace, then we get an (n-1)-dimensional convex polytope P'.
The number of vertices of P' is either the same or smaller (the latter happens
when a P-vertex projects
into the <i>interior</i> of P', hence is no longer a vertex).  
What is the expected number of vertices of P'?  
Well, the probability a given vertex of P <i>fails</i> to be an extreme point (i.e. vertex) of the 
new polytope, is precisely <i>twice</i> the internal solid angle at that vertex
measured on a scale in which "the whole spherical-sky is 1."  
Therefore by linearity of expectations we may compute that the expected 
number of "missing" vertices of P' is precisely
twice the (unit-normalized) angle sum at the vertices of P.
More generally, the expected number of missing k-flats of P' is precisely twice the
unit-normalized solid angle sum of
the solid angles at all the k-flats of P, for <i>any</i> k with 0&le;k&le;n-2.
Therefore from any <i>combinatorial</i>/topological
linear-identity obeyed by the <i>numbers</i> of k-flats of convex polytopes
(and this same proof technique
also works for infinite single-vertex polytopal <i>cones</i>, which is what matters if we 
are interested in
spherical rather than flat space) we may derive a geometrical
<i>angle-sum identity</i>!  
It is amazing that we get a profound geometrical result 
essentially without needing to think about geometry at all.
</p><p>
We now apply this technique to derive two angle-sum relations, including the one above.
</p><p>
Suppose we start from the Euler-Schl&auml;fli formula
</p>
<center>
&sum;<sub>0&le;k&le;n</sub> (-1)<sup>k</sup> F<sub>k</sub> 
= 
1
</center>
<p>
obeyed by the numbers F<sub>k</sub> of k-flats of a convex n-polytope.
This is the n-dimensional generalization
of Euler's 3-dimensional 
<nobr>V-E+F=2</nobr>
formula obeyed by the numbers of  vertices, edges, and faces of a 
polyhedron with simply-connected non-empty interior.
It may be proven inductively on the dimension
and number of faces of the polytope by considering removing one face.
The base of the induction is the formula's validity 
if F<sub>k</sub>=binomial(n+1, k+1)
[which is the number of k-flats of 
an n-dimensional simplex] &ndash; which is immediate from the binomial theorem.
Applying the Welzl proof-procedure, 
we derive
</p>
<center>
2&sum;<sub>0&le;k&le;n-2</sub> (-1)<sup>k</sup> A<sub>k</sub>/O<sub>n-k</sub> 
= 
(-1)<sup>n</sup> [F<sub>n-1</sub> - 2]
</center>
<p>
where A<sub>k</sub>/O<sub>n-k</sub> is the 1-normalized sum of interior solid angles at the k-flats of
an arbitrary convex n-polytope and F<sub>n-1</sub> is its number of faces.
</p>
<p>
The analogue of the Euler formula for infinite convex polytopal <i>cones</i> with a
single vertex (at the origin) in Euclidean n-space
[which is what matters for considering polytopes in spherical (n-1)-dimensional space]
is
</p>
<center>
&sum;<sub>0&le;k&le;n</sub> (-1)<sup>k</sup> F<sub>k</sub> 
= 
0
</center>
<p>
This again may be proven
inductively on the dimension
and number of faces of the polytope by considering removing one face;
but now the base of the induction is the formula's validity when
F<sub>k</sub>=binomial(n, k)
[which is the number of k-flats of 
an n-dimensional infinite simplicial cone with exactly one vertex].
This formula is not immediately usable because the projection of 
an n-dimensional infinite simplicial cone with exactly one vertex
might <i>not</i> be
an (n-1)-dimensional infinite simplicial cone with exactly one vertex
(since it might be the whole subspace, which has zero vertices).
However we can rewrite it as
</p>
<center>
&sum;<sub>0&le;k&le;n</sub> (-1)<sup>k</sup> F<sub>k</sub> 
= 
(-1)<sup>n</sup> (1 - F<sub>0</sub>)
</center>
<p>
valid for
a nonempty n-dimensional infinite simplicial cone with exactly one <i>or zero</i> vertices.
The Welzl proof-procedure applied to <i>that</i> &ndash; more precisely we subtract this formula 
for the projected polytopal cone in n-1 dimensions from the original formula for the original
n-dimensional cone, then take expectation values of both sides &ndash;
yields
</p>
<center>
2&sum;<sub>0&le;k&le;n-2</sub> (-1)<sup>k</sup> A<sub>k</sub>/O<sub>n-k</sub> 
= 
(-1)<sup>n</sup> [F<sub>n-1</sub> - 2 + 2 A<sub>0</sub>/O<sub>n</sub>]
</center>
<p>
where A<sub>k</sub>/O<sub>n-k</sub> is the 1-normalized sum of interior solid angles
at the k-flats of
an arbitrary convex n-polytopal infinite cone with one vertex, and F<sub>n-1</sub> 
is its number of faces.
In the simplicial case F<sub>n-1</sub>=n this 
(rewritten to solve for A<sub>0</sub>/O<sub>n</sub>)
is equivalent to the formula to be proven.
</p><p>
The proof has been for spherical geoemtry only (and the absolute value signs
in the original formula are then irrelevant).  However, we can
extend the result to hyperbolic geometry via analytic continuation, and then
the absolute value signs matter.
In both cases all the Schl&auml;fli functions on the right hand side
are for spherical-space simplices &ndash; "solid angles" &ndash;
even though the one on the left hand side may not be.  
The identity we gave also works in Euclidean space
if we regard Euclidean simplices as infinitesimal &ndash; zero volume &ndash; nonEuclidean ones.
<b>QED.</b>
</p>
<!-- Sommerville only did the spherical and Euclidean cases; for hyperbolic I presume there is an analogue too -->
<p>
<b>Historical remark:</b>
Welzl's proof idea had already been known  (essentially, albeit expressed in different language)
to M.A.Perles &amp; G.C.Shephard in the late 1960s.
Welzl traces the Euclidean version of the identity to
J.P. de Gua de Malves (1783) for tetrahedra, Brianchon (1837) for 3-polytopes, and J.P.Gram (1874);
see also Hopf (1953);
nonEuclidean polytopes were treated by Sommerville 1927
and earlier (but just for nonEuclidean tetrahedra) by Max Dehn in 1905.
Others have credited this to H.Poincare (1905) and H.Hopf (1925).
Welzl did not actually prove the nonEuclidean result we just proved, only the Euclidean one;
but as we just saw,
his proof-idea suffices to do so.
</p><p>
The Brianchon-Gram-Sommerville identity is not the only angle-sum identity; others
also can work to
reduce odd-N Schl&auml;fli functions to sums of lower-dimensional ones.
</p>
<!--
<p>
An inclusion-exclusion argument requiring no 
geometry whatever shows that for spherical simplices
<center>
2&sum;<sub>2&le;k&le;2&lfloor;N-1)/2&rfloor;</sub>(-1)<sup>k</sup>&sum;<sub>|s|=k</sub>S<sub>N</sub>(H<sup>s</sup>)
- (N-2) O<sub>N</sub> 
</center>
<p>
is equal to 4S<sub>N</sub>(H) or 0 if N is odd or even respectively.
In this expression we have cheated on the notation by regarding S<sub>N</sub> as
a function of the face-defining hyperplanes vai the N&times;N matrix H, instead of
as a function of X.
But there is no dimension-reduction going on here.
</p>
--
--
Would be the "Dehn-Sommerville relations" in flat space, but we are curved.
-->
In particular, we can make the sum on the right hand side <i>only</i> contain S<sub>k</sub> 
with k <i>even</i>
by repeatedly using the original identity to get rid of the odd-k terms.  
That is how one can reach Dehn's
expression above for S<sub>5</sub>(X) and the angle-defect formula for S<sub>3</sub>(X),
but note that these are apparently the <i>only</i> cases where the
hyperbolic simplex volumes are in general expressible as sums of lower-dimensional simplex
volumes based on the <i>same</i> dihedral angles.  In higher
dimensions, the 
<a href="#SVDD">projection</a>
operators hidden in the X<sup>s</sup> notation mess up the angles.
Via some impressive combinatorics
already known to Schl&auml;fli (see Peschl 1955 and Zehrt 2008 for more modern and/or extensive
treatments) this approach is seen to yield the <b>single-parity reduction identity</b>
</p>
<center>
S<sub>2m+1</sub>(X)/O<sub>2m+1</sub> =
|&sum;<sub>0&le;j&le;m</sub> 
&sum;<sub>s&sub;{1,2,...,2m+1} with |s|=2j+1</sub> 
t<sub>2j</sub> 
S<sub>2m-2j</sub>(X<sup>s</sup>)/O<sub>2m-2j</sub>|
</center>
<p>
where we agree to regard S<sub>0</sub>()/O<sub>0</sub>=1 
and where the magic rational coefficients 
</p>
<center>
t<sub>0</sub>=1/2,
t<sub>2</sub>=-1/4,
t<sub>4</sub>=1/2,
t<sub>6</sub>=-17/2,
t<sub>8</sub>=31/2,
t<sub>10</sub>=-691/4,
t<sub>12</sub>=5461/2,
t<sub>14</sub>=-929569/16,
&hellip;
</center>
<p>
arise from the generating function
</p>
<center>
(1/z) tanh(z/2) = &sum;<sub>j&ge;0</sub> t<sub>2j</sub> z<sup>2j</sup> / (2j+1)!.
</center>

<!--
<h3> C4. Some facts about spherical triangles </h3>

<p>
We now write out, with a considerable degree of explicitness, solutions
to these integration problems in 3 (flat) dimensions.  
</p>
<p>
<b>AREA:</b>
The <b>area</b> of a spherical triangle (drawn using geodesic arcs on the surface of the
sphere x<sup>2</sup>+y<sup>2</sup>+z<sup>2</sup>=1)
is the same thing as its "angle defect" &alpha;+&beta;+&gamma;-&pi;
where &alpha;,&beta;,&gamma; are the triangle's angles.
</p>
<p>
This is well known and one proof involves noting that the angle defect (like area) is <i>additive</i>
when considering a triangle subdivided into a mesh of smaller ones, and also noting that the
formula is asymptotically correct for very small right-triangles.
</p>
<p>
<b>CENTER OF MASS:</b>
The center of mass of a spherical triangle (where equal areas have equal mass) is
located at the intersection of its three "median" geodesics (the median goes through
a vertex and the midpoint of the opposite edge).
This is only
true up to a radial rescaling (of course the real center of mass lies <i>inside</i> the sphere
but we rescale it to lie on the surface).
Equivalently (also up to a radial rescaling) the center of mass, as a 3-vector
in xyz coordinates, is the mean of the 3 vertices.
Finally, note each median bisects the area of the triangle.
</p>
<p>
Proof:
Divide the spherical triangle into an infinite number of infinitesimal-width "slabs" each of 
which is the region between two "parallel" circular arcs
(neither of which is geodesic, in general).  The center of mass of each such slab is
obviously at its midpoint.  Hence the median geodesic passes through the C.O.M.s of
each slab, the median bisects area, and hence the C.O.M. of the triangle must lie on each median.
The median geodesic is the same (up to a radial rescaling) as the median line through the
flat triangle in xyz-space with the same vertices.  Hence the intersection of the three
flat medians (which is the C.O.M. of the flat triangle and is the mean of
its 3 vertices) is the same up to a radial rescale as the C.O.M. of the spherical triangle.
<b>QED.</b>
</p>
<p>
Sometimes <b>general spherical triangles</b> can be difficult to handle directly.
Fortunately one can always first
split the triangle into 6 spherical <i>right</i> triangles (with some interior-point
as a common hypotenusic angle for them all).
This is the only way I was able to compute
the "area moment of inertia" of a spherical triangle about an axis-line (meaning
the integral dArea of the squared Euclidean distance to that line):
</p>
<p>
<b>AREA MOMENT OF INERTIA OF A SPHERICAL RIGHT TRIANGLE:</b>
Let I be the area moment of inertia (about an axis passing though both the sphere center and
triangle vertex <i>a</i>) of a spherical right triangle abc, where c is the right angle.
The triangle sides are A,B,C with lengths measured in radians.
Then
</p>
<center>
3I 
=
2a
-
2arctan(tan(a)cos(B)[1+tan(a)<sup>2</sup>sin(B)<sup>2</sup>]<sup>-1/2</sup>)
-
tan(a)sin(B)<sup>2</sup>cos(B)[1+tan(a)<sup>2</sup>sin(B)<sup>2</sup>]<sup>-1/2</sup>.
</center>
<p>
Proof sketch:
Using the correct dArea element with the gnomonic projection of the spherical triangle onto
a flat plane touching the sphere at <i>a</i>, we find
</p>
<center>
3I 
=
3&int;<sub>0&lt;x&lt;tan(B)</sub>&int;<sub>0&lt;y&lt;xtan(a)</sub> 
(x<sup>2</sup>+y<sup>2</sup>)(1+x<sup>2</sup>+y<sup>2</sup>)<sup>-5/2</sup> dy dx
<br>
=
&int;<sub>0&lt;x&lt;tan(B)</sub>
x<sup>3</sup> 
[3x<sup>2</sup>+3+3tan(a)<sup>2</sup>x<sup>2</sup>+tan(a)<sup>2</sup>] 
tan(a) 
[1+x<sup>2</sup>]<sup>-2</sup> 
[1+x<sup>2</sup>+tan(a)<sup>2</sup>x<sup>2</sup>]<sup>-3/2</sup>
</center>
<p>
Now this integral can be done and then after <i>tremendous</i> algebraic simplication with the aid
of 
sin<sup>2</sup>&theta;+cos<sup>2</sup>&theta;=1
and
arctan(1/x)+arctan(x)=&pi;/2
we find the formula claimed.  
As a check, one may expand it in a Maclaurin series  for B
to find
<center>
12I = tan(a) [3+tan(a)<sup>3</sup>] B<sup>4</sup> + O(B<sup>6</sup>)
</center>
agreeing with the (previously known) result for flat triangles.
</p>
<p>
Hope springs eternal that there might be some nice way to rewrite the I-formula
in some form which would be simple even for a fully general triangle.
But I do not know it.
</p>
<p>
<b>INTEGRAL OF LINEAR(x,y,z) OVER A SPHERICAL RIGHT-TRIANGLE:</b>
The integral of z over a spherical right triangle abc with vertex a located
on the z-axis, and vertex c being the right angle, is given by
</p>
<center>
3L 
= 
3&int;&int; z dArea
=
 sin(a)sin(B)<sup>2</sup>[tan(B)<sup>2</sup>+cos(a)<sup>2</sup>]<sup>-1/2</sup>
- arctan(sin(a)[tan(B)<sup>2</sup>+cos(a)<sup>2</sup>]<sup>-1/2</sup>)
+ a.  
</center>
This arises from
<center>
L = &int;<sub>0&lt;x&lt;tan(B)</sub>&int;<sub>0&lt;y&lt;tan(a)x</sub>
(1+x<sup>2</sup>+y<sup>2</sup>)<sup>-5/2</sup>
dy dx
</center>
yielding
<center>
3L
= 
tan(a)
&int;<sub>0&lt;x&lt;tan(B)</sub>
(3x<sup>2</sup>+3+2tan(a)<sup>2</sup>x<sup>2</sup>)
(1+x<sup>2</sup>+tan(a)<sup>2</sup>x<sup>2</sup>)<sup>-3/2</sup>
x/(1+2x<sup>2</sup>+x<sup>4</sup>) 
dx
</center>
whereupon again this integral can be done and after tremendous simplification reduces to the formula
claimed.
</p>


--
z-integral about vertex a,  with opp sidelen B, of right sph triangle (c=90)
use gnomonic model

MOI
=
int(int(1/(1+x^2+y^2) *  (1+x^2+y^2)^(-3/2), y = 0 .. tan(a)*x), x = 0 .. tan(B));
=
int(int( (1+x^2+y^2)^(-5/2), y = 0 .. tan(a)*x), x = 0 .. tan(B));
=
int( 1/3*(3*x^2+3+2*tan(a)^2*x^2)*tan(a)*x/(1+2*x^2+x^4)/(1+x^2+tan(a)^2*x^2)^(3/2), x = 0 .. tan(B));  
=
1/6*(2*arctan(((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/sin(a)*cos(a))*tan(a)*((1-
cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)-tan(a)*((1-cos(B)^2+cos(a)^2*cos(B)^2)
/cos(a)^2/cos(B)^2)^(1/2)*cos(a)*Pi+2*tan(a)*((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1
/2)*cos(a)*a+2*tan(a)*sin(a)-2*sin(a)*tan(a)*cos(a)^2-2*sin(a)*tan(a)*cos(B)^2+2*sin(a)*tan(a)*cos
(a)^2*cos(B)^2-2*sin(a)*arctan(((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/(sin(a)^2/
cos(a)^2)^(1/2))*((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)^2+sin(a)*((1-cos(
B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)^2*Pi-2*sin(a)*((1-cos(B)^2+cos(a)^2*cos(B)
^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)^2*a)/cos(a)/((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)
^(1/2)/sin(a)^2/(sin(a)^2/cos(a)^2)^(1/2)
=
1/6*(2*arctan(((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/sin(a)*cos(a))*tan(a)*((1-
cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)-tan(a)*((1-cos(B)^2+cos(a)^2*cos(B)^2)
/cos(a)^2/cos(B)^2)^(1/2)*cos(a)*Pi+2*tan(a)*((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1
/2)*cos(a)*a+2*tan(a)*sin(a)-2*sin(a)*tan(a)*cos(a)^2-2*sin(a)*tan(a)*cos(B)^2+2*sin(a)*tan(a)*cos
(a)^2*cos(B)^2-2*sin(a)*arctan(((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/sin(a)*cos
(a))*((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)^2+sin(a)*((1-cos(B)^2+cos(a)^
2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)^2*Pi-2*sin(a)*((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2
/cos(B)^2)^(1/2)*cos(a)^2*a)/((1-cos(B)^2+cos(a)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/sin(a)^3
=
1/6*(2*arctan((1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a))*tan(a)*(1-cos(B)^2+cos(a)^2*cos(
B)^2)^(1/2)/cos(B)-tan(a)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)*Pi+2*tan(a)*(1-cos(B)^2+cos(
a)^2*cos(B)^2)^(1/2)/cos(B)*a+2*tan(a)*sin(a)-2*sin(a)*tan(a)*cos(a)^2-2*sin(a)*tan(a)*cos(B)^2+2*
sin(a)*tan(a)*cos(a)^2*cos(B)^2-2*sin(a)*arctan((1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a)
)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)/cos(B)+sin(a)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*
cos(a)/cos(B)*Pi-2*sin(a)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)/cos(B)*a)/((1-cos(B)^2+cos(a
)^2*cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/sin(a)^3
=
1/6*(2*arctan((1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a))*tan(a)*(1-cos(B)^2+cos(a)^2*cos(
B)^2)^(1/2)/cos(B)-tan(a)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)*Pi+2*tan(a)*(1-cos(B)^2+cos(
a)^2*cos(B)^2)^(1/2)/cos(B)*a+2*tan(a)*sin(a)-2*sin(a)*tan(a)*cos(a)^2-2*sin(a)*tan(a)*cos(B)^2+2*
sin(a)*tan(a)*cos(a)^2*cos(B)^2-2*sin(a)*arctan((1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a)
)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)/cos(B)+sin(a)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*
cos(a)/cos(B)*Pi-2*sin(a)*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)/cos(B)*a)/(1-cos(B)^2+cos(a)
^2*cos(B)^2)^(1/2)*cos(a)*cos(B)/sin(a)^3
=
-1/6/sin(a)^2*(-2*arctan((1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a))*(1-cos(B)^2+cos(a)^2*
cos(B)^2)^(1/2)+(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*Pi-2*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*a-2
*cos(B)*sin(a)+2*cos(a)^2*sin(a)*cos(B)+2*sin(a)*cos(B)^3-2*sin(a)*cos(a)^2*cos(B)^3+2*arctan((1-
cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a))*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)^2-(1-
cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)^2*Pi+2*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*cos(a)^2*a)/(
1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)
=
flip the arctan???
use cos^2+sin^2=1 a lot
=
-1/6/sin(a)^2*(-2*arctan((sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a))*(sin(B)^2+cos(a)^2*
cos(B)^2)^(1/2)+(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)*Pi-2*(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)*a-2
*cos(B)*sin(a)+2*cos(a)^2*sin(a)*cos(B)+2*sin(a)*cos(B)^3-2*sin(a)*(1-sin(a)^2)*cos(B)^3+2*arctan((1-
cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)/cos(B)/sin(a))*(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)*(1-sin(a)^2)-(1-
cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*(1-sin(a)^2)*Pi+2*(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)*(1-sin(a)^2)*a)/(
sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)
=
1/6*(2*cos(B)-2*cos(a)^2*cos(B)-2*cos(B)^3+2*cos(B)^3*cos(a)^2+2*arctan((1-cos(B)^2+cos(a)^2*cos(B
)^2)^(1/2)/cos(B)/sin(a))*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*sin(a)-(1-cos(B)^2+cos(a)^2*cos(B)^
2)^(1/2)*Pi*sin(a)+2*(1-cos(B)^2+cos(a)^2*cos(B)^2)^(1/2)*a*sin(a))/(1-cos(B)^2+cos(a)^2*cos(B)^2)
^(1/2)/sin(a)
=
1/6*( 2*cos(B)*(-sin(B)^2)*(-sin(a)^2)
+2*arctan((sin(B)^2+cos(a)^2*cos(B
)^2)^(1/2)/cos(B)/sin(a))*(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)*sin(a)-(sin(B)^2+cos(a)^2*cos(B)^
2)^(1/2)*Pi*sin(a)+2*(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)*a*sin(a))/(sin(B)^2+cos(a)^2*cos(B)^2)
^(1/2)/sin(a)
=
1/3/(sin(B)^2+cos(a)^2*cos(B)^2)^(1/2)/sin(a)*cos(B)*sin(B)^2*sin(a)^2+1/3*arctan((sin(B)^2+cos(a)
^2*cos(B)^2)^(1/2)/cos(B)/sin(a))-1/6*Pi+1/3*a
=
1/3/(tan(B)^2+cos(a)^2)^(1/2)/sin(a)*sin(B)^2*sin(a)^2+1/3*arctan((tan(B)^2+cos(a)
^2)^(1/2)/sin(a))-1/6*Pi+1/3*a
=
1/3/(tan(B)^2+cos(a)^2)^(1/2)*sin(a)*sin(B)^2+1/3*arctan((tan(B)^2+cos(a)^2)^(1/2)/sin(a))-1/6*Pi+
1/3*a
=
1/3/(tan(B)^2+cos(a)^2)^(1/2)*sin(a)*sin(B)^2+Pi/6-1/3*arctan(sin(a)/(tan(B)^2+cos(a)^2)^(1/2))-1/6*Pi+
1/3*a
=
1/3/(tan(B)^2+cos(a)^2)^(1/2)*sin(a)*sin(B)^2-1/3*arctan(1/(tan(B)^2+cos(a)^2)^(1/2)*sin(a))+1/3*a
=
(1/3) * ( 1/(tan(B)^2+cos(a)^2)^(1/2)*sin(a)*sin(B)^2-arctan(1/(tan(B)^2+cos(a)^2)^(1/2)*sin(a))+a  )
--


<p>
<b>INTEGRAL OF LINEAR(x,y,z) OVER A SPHERICAL TRIANGLE:</b>
Let the linear function be
</p>
<center>
f(x,y,z)
=
k 
+
(m<sub>x</sub>x + m<sub>y</sub>y + m<sub>z</sub>z)q
+
(t<sub>x</sub>x + t<sub>y</sub>y + t<sub>z</sub>z)
</center>
<p>
where the unit-length 3-vector m passes through
the center of mass of the spherical triangle,
while t is some other constant 3-vector perpendicular to m.
</p><P>
Then the integral of f over a spherical triangle (on the standard unit-radius sphere) is
</p>
<center>
&int;&int;f(x,y,z) dArea
=
k&middot;Area
+
q&middot;&sum;<sub>6</sub>L<sub>j</sub>
</center>
<p>
where we split the triangle into 6 right spherical triangles with common vertex at
the center of mass m, and 
L<sub>j</sub> is the "L" formula above for the jth of these right-triangles
(with "z-axis" mentally taken for that purpose to be in the m direction, although
one does not need to actually do any explicit coordinate rotation since the L formula had been
expressed in terms of sidelengths and angles only).
</p>

--
mom of inertia about vertex a,  with opp sidelen B, of right sph triangle (c=90)
use gnomonic model

MOI
=
int(int((x^2+y^2)/(1+x^2+y^2) * (1+x^2+y^2)^(-3/2), y = 0 .. tan(a)*x), x = 0 .. tan(B));
=
int(int( (x^2+y^2)/(1+x^2+y^2)^(5/2), y = 0 .. tan(a)*x), x = 0 .. tan(B));
=
int( 
1/3*x^3*(3*x^2+3+3*tan(a)^2*x^2+tan(a)^2)*tan(a)/(1+x^2)^2/(1+x^2+tan(a)^2*x^2)^(3/2),
x = 0 .. tan(B));        
=
needed to go indef then sub endpoints
=
1/3*(2*arctan((1+tan(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))*(1+tan(B)^2+tan(a)^2*tan(B)^2)^(1/2)+2*
arctan((1+tan(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))*(1+tan(B)^2+tan(a)^2*tan(B)^2)^(1/2)*tan(B)^2-
tan(a)*tan(B)^2)/(1+tan(B)^2)/(1+tan(B)^2+tan(a)^2*tan(B)^2)^(1/2)-2/3*arctan(1/tan(a)
=
1/3*(2*arctan((sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))*(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)+2*
arctan((sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))*(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)*tan(B)^2-
tan(a)*tan(B)^2)/(sec(B)^2)/(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)-2/3*arctan(1/tan(a))
=
1/3*(2*arctan(((cos(a)^2*cos(B)^2+1-cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/sin(a)*cos(a))*((cos(a)^2*
cos(B)^2+1-cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)-sin(a)+sin(a)*cos(B)^2-((cos(a)^2*cos(B)^2+1-
cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)*cos(a)*Pi+2*((cos(a)^2*cos(B)^2+1-cos(B)^2)/cos(a)^2/cos(B)^2)^
(1/2)*cos(a)*a)/((cos(a)^2*cos(B)^2+1-cos(B)^2)/cos(a)^2/cos(B)^2)^(1/2)/cos(a)
=
1/3*(2*arctan((sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))*(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)+2*
arctan((sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))*(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)*tan(B)^2-tan(
a)*tan(B)^2)/sec(B)^2/(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)-1/3*Pi+2/3*a
=
series   tan(a)*(3+tan(a)^3) * B^4 / 12 + O(B^6) = the flat triangle result + O(B^6)
=
2/3/sec(B)^2*arctan((sec(B)^2+tan(a)^2*sin(B)^2*sec(B)^2)^(1/2)/tan(a))+2/3*arctan((sec(B)^2+tan(a
)^2*sin(B)^2*sec(B)^2)^(1/2)/tan(a))*sin(B)^2-1/3/(sec(B)^2+tan(a)^2*sin(B)^2*sec(B)^2)^(1/2)*tan(
a)*sin(B)^2-1/3*Pi+2/3*a
=
2/3*cos(B)^2*arctan((sec(B)^2+tan(a)^2*sin(B)^2*sec(B)^2)^(1/2)/tan(a))+2/3*arctan((sec(B)^2+tan(a
)^2*sin(B)^2*sec(B)^2)^(1/2)/tan(a))*sin(B)^2-1/3/(sec(B)^2+tan(a)^2*sin(B)^2*sec(B)^2)^(1/2)*tan(
a)*sin(B)^2-1/3*Pi+2/3*a
=
2/3*arctan((sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))-1/3/sec(B)^2/(sec(B)^2+tan(a)^2*tan(B)^2)^(1
/2)*tan(a)*tan(B)^2-1/3*Pi+2/3*a
=
2/3*arctan((sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)/tan(a))-1/3/(sec(B)^2+tan(a)^2*tan(B)^2)^(1
/2)*tan(a)*sin(B)^2-1/3*Pi+2/3*a
=
Pi/3-2/3*arctan( tan(a)/(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2) )-1/3/(sec(B)^2+tan(a)^2*tan(B)^2)^(1
/2)*tan(a)*sin(B)^2-1/3*Pi+2/3*a
=
-2/3*arctan(tan(a)/(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2))-1/3/(sec(B)^2+tan(a)^2*tan(B)^2)^(1/2)*tan(
a)*sin(B)^2+2/3*a
=
-2/3*arctan(tan(a)*cos(B)/(1+tan(a)^2*sin(B)^2)^(1/2))-1/3/(1+tan(a)^2*sin(B)^2)^(1/2)*tan(a)*sin(
B)^2*cos(B)+2/3*a

One also can use the fact that for a spherical right triangle ABC (C=right) 
cos(b)=sin(a)*cos(B)
so that
cos(b)/cos(a)=tan(a)*cos(B)
to get
MOI
=
-2/3*arctan(cos(b)/cos(a)/(1+tan(a)^2*sin(B)^2)^(1/2))-1/3/(1+tan(a)^2*sin(B)^2)^(1/2)*cos(b)*sin(
B)^2/cos(a)+2/3*a




dArea(Flat) = r * dr * dth

dArea(Curv) = dr/(1+r^2) * r/(1+r^2)^(1/2) * dth

dArea(Curv)/dArea(Flat) = (1+r^2)^(-3/2)   -- looks correct

MAPLE cannot do the above?
foo := int((x^2+y^2)*(1-x^2-y^2)^(1/2),y);
subs( y=x*tan(a), foo ) - subs(y=0, foo);
dah := int( %, x);
subs( x=sin(B), dah ) - subs(x=0, dah);
momi := simplify(%);
get something very complicated and perhaps complex
--

<p>
<b>INTEGRAL OF LINEAR(x,y,z) OVER A SPHERICAL TRIANGLE, II:</b>
We can also solve this problem by a different method &ndash; instead of direct integration
we employ the indirect attack based on Gauss's divergence theorem outlined in the previous
subsection.
???
</p>
-->

<blockquote>
<b>References for appendix C:</b>
<br>
My computer program for evaluating Schl&auml;fli functions
is available at
<a href="../../SchlafliProgram">http://rangevoting.org/SchlafliProgram</a>.
<br>
Kazuhiko Aomoto:
Analytic structure of Schl&auml;fli function,
Nagoya Math. J. 68 (1977) 1-16.
<br>
Johannes B&ouml;hm &amp; Eike Hertel:
Polyedergeometrie in N-Dimensionalen R&auml;umen Konstanter Kr&uuml;mmung,
Birkhauser 1981.
<br>
H.S.M.Coxeter:
The functions of Schl&auml;fli and Lobachevsky,
Quart. J. Math. 6 (1935) 13-29 (reprinted pp. 3-20 of <i>Twelve geometric essays</i>, 
Southern Illinois Univ. Press, Carbondale, 1968).
<br>
Max Dehn:
Die Eulersche Formel im Zusammenhang mit dem Inhalt in der nichteuklidisches Geometrie,
Math. Annalen 61 (1905) 561-586.
<br>
D.A.Derevnin &amp; A.D.Mednykh:
A formula for the volume of a hyperbolic tetrahedon,
Russian Math. Surveys 60 (2005) 346-348.
<br>
J.D.H. Donnay:
Spherical trigonometry after the Ces&agrave;ro method,
Interscience NY 1945, reprinted 2007 by Church Press.
<br>
Branko Gr&uuml;nbaum:
Convex Polytopes,
1967 and as of 2003 a second edition
extended by Volker Kaibel, Victor Klee, and G&uuml;nter M. Ziegler
is available from Springer.
<br>
Heinz Hopf: &Uuml;ber Zusammenh&auml;nge zwischen Topologie und Metrik im Rahmen der elementaren Geometrie,
Mathematisch-Physikalische Semester Berichte 3 (1953) 16-29.
<br>
Ruth Kellerhals: 
Volumes in hyperbolic 5-space, Geometric &amp; Functional Analysis 5,4 (1995) 640-667.
<br>
<!--Ruth Kellerhals: 
On the volumes of hyperbolic 5-orthoschemes and the trilogarithm, 
Commentarii Math. Helvetica 67 (1992) 648-663.
Kellerhals, R., Shape and size through hyperbolic eyes. Math. Intelligencer. v17 i2. 21-30.
<br>
-->
Ruth Kellerhals: 
On Schl&auml;fli's reduction formula, Mathematische Zeithschrift 206,1 (Jan. 1991) 193-210.
<br>
A. Ya. Khinchin: Continued Fractions 1935 (English translation by University of Chicago Press 1961).
<br>
Hellmuth Kneser:
Der Simplexinhalt in der nichteuklidischen Geometrie,
Deutsche Math. 1 (1936) 337-340.
<br>
Leonard Lewin: Polylogarithms and associated functions,
North-Holland, Amsterdam, 1981.
<br>
Feng Luo:
Continuity of the Volume of Simplices in Classical Geometry,
<a href="http://arxiv.org/abs/math/0412208v1">arXiv:math/0412208v1</a>.
<br>
Peter McMullen: Angle-sum relations for polyhedral sets, Mathematika 33,2 (1986) 173-188.
<br>
A. D. Mednykh &amp; M. G. Pashkevich:
Elementary formulas for a hyperbolic tetrahedron, Sibirsk. Mat. Zh. 47,4 (2006) 831-841.
<br>
John Milnor:
Hyperbolic geometry: the first 150 years, Bull. Amer. Math. Soc. 6 (1982) 9-24
and reprinted in his <i>Collected Papers</i>, Volume 1 ("Geometry") 243-260.
<br>
John Milnor:
The Schl&auml;fli differential equality,
in his <i>Collected Papers</i>, Volume 1 ("Geometry") 281-295.
<br>
John Milnor:
How to compute volumes in hyperbolic space,
in his <i>Collected Papers</i>, Volume 1 ("Geometry") 189-212.
<br>
Jun Murakami &amp; Masakazu Yano: On the volume of a hyperbolic and spherical tetrahedron,
Communications Anal. Geometry 13,2 (2005) 379-400.
<!-- http://www.f.waseda.jp/murakami/papers/tetrahedronrev4.pdf -->
<br>
Jun Murakami &amp; Akira Ushijima: 
A volume formula for hyperbolic tetrahedra in terms of edge lengths,
J. Geometry 83, 1-2 (Dec. 2005) 153-163.
<!-- http://arxiv.org/pdf/math/0402087v1 -->
<!-- http://arxiv.org/pdf/math/0309216 -->
<br>
Harold Parks &amp; Dean C. Willis:
An Elementary Calculation of the Dihedral Angle of the Regular n-Simplex,
American Mathematical Monthly 109,8 (Oct. 2002) 756-758.
<br>
M.A.Perles &amp; G.C.Shephard:
Acta Math. 119
(1967) 113-145;  Math. Scand. 21 (1967) 199-218.
<br>
Ernst Peschl:
Winkelrelationen am Simplex und die Eulersche Charakteristik,
Sitzungsber. Math.-Naturw. Kl. Bayer. Akad. Wiss. M&uuml;nchen 1955 (1956) 319-345.
<!--
<br>
L.J.Rogers:
On function sums connected with the series &sum; x<sup2</sup>/n<sup>2</sup>, 
Proc London Mathl Soc. II4 (1907) 169-189
-->
<br>
Chih-Han Sah: Hilbert's third problem: scissors congruence.
San Francisco: Pitman (research notes in maths #33) 1979; extended in these papers
I: The Gauss-Bonnet map, Math. Scand. 49 (1981) 189-210 corrections 53 (1983) 62;
II: (with Johan L. Dupont) J. Pure Appl. Algebra 25 (1982) 159-195;
(posthumous with Dupont) Three questions about
simplices in spherical and hyperbolic 3-space,
p. 49-76 in
"The Gelfand Mathematical Seminars 1996-1999" Birkhauser volume
in memory of Sah.
<br>
William F. Reynolds:  Hyperbolic Geometry on a Hyperboloid, 
American Mathematical Monthly 100 (May 1993) 442-455.
<br>
Kenzi Sato:
Spherical simplices and their polars,
Quarterly J. Math 58,1 (2007) 107-126.
<br>
Ludwig Schl&auml;fli:
Theorie der vielfachen Kontinuit&auml;t, 
posthumously published book 
in his
<I>Gesammelte mathematische Abhandlungen</i>, 
3 vols. (Verlag Birkh&auml;user, Basel, 1950-1956).
<br>
D.M.Y. Sommerville:
The Relations Connecting the Angle-Sums and Volume of a Polytope in Space of n Dimensions,
Proceedings Royal Society of London A 115, 770 (June 1927) 103-119. 
[Correct results, but proof contains gap.]
<br>
Emo Welzl: Gram's Equation, a Probabilistic Proof,
pp. 422-424 in Springer Lecture Notes in Computer Science #812 (1994).
<br>
Thomas Zehrt:
Schl&auml;fli numbers and reduction formula,
European J. Combinatorics 29,3 (April 2008) 601-616.
</blockquote>

<!--
<h3>  About Monte Carlo methods </h3>

<p>
Some pseudorandom number generators are weak in the sense that they consistently 
fail simple randomness tests after emitting only a small amount of output.
Others are strong in the sense that a large amount of output and/or computing
by the tester is required to get a failure.   What I wish to argue here
is that one can achieve speeds comparable to the fastest generators while
still having strength comparable to the strongest ones.
</p>
<p>
It is rare that a generator W is so weak that 
some statistical test only requires 1001 random numbers before 
seeing failure.    
We believe that it is possible to construct extremely fast
generators that 
<ol>
<li> 
survive tests for 1000 outputs
</li>
exhibit perfect uniformity over an entire period.
</ol>
The idea, then, is to run W for 1000 outputs, then <i>re-seed</i>
W with random numbers from
a stronger (but 10&times; slower) generator S (which, say, survives
testing for 10<sup>9</sup> outputs).
The resulting generator should be at least as strong as S but only 1% slower than W.
We can continue the chain by re-seeding S occasionally with bits from an ultrastrong
generator U.  Then we are still nearly as fast as W but nearly as strong as U. 
And so on.
Generators are known which are conjectured to survive <i>every</i> polynomial-time
randomness test, so the chain can terminate quite quickly.
</p>
<p>
One can make this precise by defining the "strength" of a generator
to be the expected compute time T (where each random is got in 1 time unit)
before an adversary can successfully
predict its future output
[e.g. by learning the internal state of the generator;
it would probably suffice to ask only for the next 100log<sub>2</sub>(T+9) output bits].
If W has strength A and S has strength B&gt;A,
then the combined generator "S/W" has strength at least B (and probably usually
closer to AB).
</p><p>
This is a very simple idea, but for some reason the Monte Carlo community has 
not used it (or at least it is very little used).
In high performance Monte Carlo computations, 
speed and strength are what matter.  The "pyramid" method we have outlined will with
little effort yield speed within 20% of optimum and enough strength 
(under well known computational complexity conjectures) to resist every
computationally feasible statistical test.
</p>
-->

<a name="AppD"></a>
<h3> Appendix D: Glossary of Terminology </h3>

<p>
This appendix collects together definitions of background concepts from several different areas
(voting, special functions, geometry, matrices, and Bayesian statistics), hopefully rendering
the paper readable by those unfamiliar with the jargon from some of these areas.
Some of the terms are standard, but others are new or less common.
</p>

<dl>
<dt><b>AntiPlurality Voting:</b></dt>
<dd>
Each voter names a candidate (as her vote) that she would <i>not</i> like to see elected.
The candidate named the <i>fewest</i> times is then elected.
</dd>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/rangeVapp.html">Approval Voting</a>:</b></dt>
<dd>
Voting system where a voter <i>approves</i> (+1)
or  <i>disapproves</i> (-1) each candidate, and the
candidate with the most approvals wins.
This is a degenerate form of range voting arising when only <i>two</i> numerical
values (the range-<i>endpoints</i>, which in this paper will be &plusmn;1) are allowed scores.  
It is also the same as plurality voting with "overvoting" allowed.
Invented in the modern era by <a href="https://rangevoting.org/WarrenSmithPages/homepage/OttewellEndorse.html">Guy Ottewell</a> in 1968,
but already used, e.g, during 1294-1621 as a component of the process of electing Catholic Popes.
</dd>

<dt><b><a href="ArrowThm.html">Arrow's Impossibility Theorem</a>:</b></dt>
<dd>
Arrow's (1950) theorem states that no voting method 
whose inputs are rank-orderings of the candidates 
(one from each voter) and
whose output also is a rank-ordering,
can satisfy the following short list of conditions:
<ol>
<li>
There is no "dictator" (who alone controls the winner regardless of the other voters).
</li><li>
If every voter prefers A to B then so does the group.
</li><li>
The relative positions of A and B in the group ranking depend on their
relative positions in the individual rankings, but do not depend on the
individual rankings of any irrelevant alternative C.
</li>
</ol>
</dd>
<dt><b>BR=<a href="https://rangevoting.org/WarrenSmithPages/homepage/BayRegDum.html">Bayesian Regret</a>:</b><a name="BayRegDefn"></a></dt>
<dd>
The "Bayesian regret" of an election method E is the "expected avoidable 
human unhappiness" caused by using E
(within a certain mathematical/probabilistic model &ndash; no actual humans are involved).
Better voting systems have smaller regret values.
The regret value of any given election system in any given probabilistic
scenario can be measured.  This gives a quantitative way to compare 
the quality of two election methods.
<br>
To be more precise:
To determine the BR of an election method, one generates a zillion artificial elections 
each involving artificial voters, artificial candidates, and utility values for the 
candidates in the view of each voter.  The voters then vote (based on their utility values,
employing their voting strategies) and a winner W wins.  If W is not the maximum-summed-utility 
candidate, then
there is positive "regret" (the difference between that maximum sum, 
and the achieved sum).  BR is simply the expected value of regret.
Note that BR depends on the rules of the voting method, the number of voters, 
the number of candidates, the voters' strategies, and the probability distribution 
generating the utilities.  It can be evaluated by computer to
arbitrary accuracy.  BRs are always nonnegative.
<br>
The reason I regard "regret" as superior to "expected utility" for purposes of
talking about and comparing voting systems is this.  Since
</p>
<center>
Regret &nbsp; = &nbsp;  Max Attainable Utility - Actual Utility,
</center>
<p>
regret=0 if we achieve perfection, otherwise it is positive.
The goal is to decrease regret, while the goal for utility is to <i>in</i>crease it.
The greater elegance of regret versus utility then arises from
<br>
<b>INVARIANCE STATEMENT:</b>
If every voter adds some voter-dependent constant to her utilities for every
candidate, that alters the utility of the election <i>but does not</i> alter the regret.
(Also, the min-attainable regret is 0, a fact invariant both to translating and
to rescaling  utilities.)
</dd>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/rangeVborda.html">Borda Voting</a>:</b></dt>
<dd>
Voting system where each vote is a rank-ordering of all the <i>N</i> candidates. 
The "even symmetry" convention of the present paper is that the
<i>k</i>th-ranked candidate gets score <i>(N+1)/2-k</i>.  
(Any linear transformation of this convention yields an equivalent voting system,
but the even-symmetry convention is the most convenient for our mathematical analysis purposes.)
The candidate with
the greatest score-sum is elected.
<br>
Attributed to 
<a href="http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Borda.html">Jean-Charles de Borda</a> 
(1733-1799) although now believed to have been known earlier.
This is the most symmetric <a href="#WeightedPos">weighted positional</a> voting system.
</dd>

<dt><b>BRBH:</b></dt>
<dd>
Our abbreviation for "Best Rating-Based voting system for Honest voters,"
see
<a href="#Sec6">section 6</a>.
</dd>

<dt><b>Cholesky factorization:</b><a name="CholeskyDefn"></a></dt>
<dd>
Given an n&times;n
positive definite symmetric matrix A, there exists an n&times;n lower
triangular matrix L with nonnegative diagonal entries
such that A=LL<sup>T</sup>.
It may be found via the following algorithm:
<pre>
for(i=1,...,n){
   L<sub>ii</sub> = (A<sub>ii</sub> - &sum;<sub>1&le;k&lt;i</sub> (L<sub>ik</sub>)<sup>2</sup>)<sup>1/2</sup>;
   for(j=i+1,...,n){
      L<sub>ji</sub> = (A<sub>ji</sub> - &sum;<sub>1&le;k&lt;i</sub> L<sub>jk</sub>L<sub>ik</sub>)/L<sub>ii</sub>;
   }
}
</pre>
If A is merely positive <i>semi</i>definite, then such an L also exists 
arising from an appropriate limit
of positive-definite A &ndash; for example, add &epsilon; to each diagonal entry of A,
then take the limit as &epsilon;&rarr;0+.
If one is trying to factor a symmetric A which 
(due to being contaminated by noise) has
one or more negative eigenvalues &lambda;<sub>k</sub>, 
then it is useful to know that the nearest (in the Frobenius norm) nonnegative definite matrix to A is
<nobr>A+&sum;<sub>k</sub>|&lambda;<sub>k</sub>|v<sub>k</sub>v<sub>k</sub><sup>T</sup></nobr>
where v<sub>k</sub> is the (unit-norm column) eigenvector of A corresponding to the 
negative eigenvalue 
&lambda;<sub>k</sub>.
</p><p>
It is much less commonly discussed in the literature, but it also sometimes is possible to 
find lower-triangular L such that 
A=LDL<sup>T</sup>
where D is any given <i>diagonal</i> matrix with nonzero entries having the same signature as A.
Call this <b>D-modified Cholesky</b>.
The algorithm then is
<pre>
for(i=1,...,n){
   L<sub>ii</sub> = [(A<sub>ii</sub> - &sum;<sub>1&le;k&lt;i</sub> D<sub>kk</sub>(L<sub>ik</sub>)<sup>2</sup>)/D<sub>ii</sub>]<sup>1/2</sup>
   for(j=i+1,...,n){
      L<sub>ji</sub> = (A<sub>ji</sub> - &sum;<sub>1&le;k&lt;i</sub> L<sub>jk</sub>D<sub>kk</sub>L<sub>ik</sub>)/(D<sub>ii</sub>L<sub>ii</sub>);
   }
}
</pre>
In the present paper we shall only be essentially interested in D of form
diag(&plusmn;1,  1, 1,  &hellip; 1).
In that case the algorithm becomes exactly equivalent to plain Cholesky once the i=1 
loop iteration is complete.
</dd>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/CandCloning.html">Cloning</a>:</b></dt>
<dd>
"Cloning" a candidate is the hypothetical operation of creating a candidate
almost exactly the same as the original one in every important way, and adding him as a new
contender to the race.  More precisely: for voting systems based on rank-order ballots, 
we postulate that no
voter ever ranks a candidate X between two clones C<sub>1</sub>,
C<sub>2</sub>  on any ballot (unless X is another clone of the same candidate).
For voting systems based on continuum-ratings ballots, 
we instead postulate that all clones are rated within
&epsilon; of each other on every ballot, in the limit &epsilon;&rarr;0.
<br>
Many voting systems react very badly to cloning.  For
example, in the plurality system, if a candidate who is clearly the best spawns
imitators ("clones") with mild deviations &ndash; exactly
<i>because</i> his stances are so clearly the best &ndash;
that often causes all the clones to lose (due to vote-splitting)
causing a bad candidate to win.  Range voting, in contrast, has no problem with cloning
and vote-splitting simply does not exist with range voting.
</dd><a name="condmeths"></a>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/rangeVcond.html">Condorcet</a>:</b></dt>
<dd>
A wide class of voting systems are called "Condorcet systems" if they
always elect the "Condorcet winner" if he exists (but do various other things,
depending on which system it is, when and if he does not exist). 
The original concept and the first Condorcet voting system (the "least reversal"
system) both were invented by
Marie Jean Antoine Nicolas de Caritat, the 
<a href="http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Condorcet.html">Marquis de Condorcet</a> 
(1743-1794).
</dd>

<dt><b><a name="condwin"></a>Condorcet Winner (traditional definition):</b></dt>
<dd>
Consider an election system in which votes can be used 
to deduce the voter's
preference within each candidate pair.  If a candidate A is preferred over
each other candidate B by a majority of the voters, then A is a "Condorcet Winner"
or "beats-all winner." (There is no necessity
that a Condorcet winner exist, however. 
Empirically, one exists somewhere between 80
and 100% of the time in practical elections.)
<br><br>
It is also possible to define Condorcet winner in 
<a href="https://rangevoting.org/WarrenSmithPages/homepage/CondDQ.html">inequivalent nontraditional ways</a>, e.g.
"if all candidates except A and B are deleted from all ballots, and A beats B in the resulting
modified election, then A 'pairwise defeats' B.  A candidate who pairwise defeats every rival is
a 'Condorcet winner'."
Range voting is a Condorcet voting method under
this second definition, but not with the traditional one.  (The two definitions
are in fact equivalent on every voting method that Condorcet himself ever considered,
i.e. all "ranked ballot" methods.  Hence, it is not possible for us to tell which
definition-version Condorcet himself would have preferred, nor is it possible for us to 
tell whether
Condorcet would have agreed that Range Voting meets his criterion.)
</dd>
<dt><b>Convex Polytope (and polytopal cone):</b></td>
<dd>
A "polytope" is the N-dimensional generalization of "polygon" (2D)
and "polyhedron" (3D).
A convex polytope is the intersection of half-spaces and when we use the word polytope we generally
only are talking about <i>nondegenerate bounded</i> polytopes 
(i.e. such that this intersection has finite nonzero N-volume).
A "polytopal cone" shall mean an unbounded convex polytope with only a <i>single</i> vertex.
</dd>
<dt><b><a name="Correl"></a>Correlation:</b></dt>
<dd>
The correlation between random variables X and Y (both of which have expectation value 0)
is E(X&middot;Y)/[E(X<sup>2</sup>) E(Y<sup>2</sup>)]<sup>1/2</sup>.
Correlation is always a real in [-1,+1] and is zero if X and Y are independent.
Note that correlations are unaffected by scalings of X and/or Y by positive constant factors.
</dd>
<dt><b>"Dilogarithm":</b></dt>
<dd>
is the function
</p>
<center>
Li<sub>2</sub>(z) 
&nbsp;
= 
&nbsp;
&sum;<sub>n&ge;1</sub> n<sup>-2</sup>z<sup>n</sup>
=
-&int; ln(1-t)/t dt
, 
<br>
(series converges when |z|&lt;1;
defined elsewhere by analytic continuation accomplished <br>
via the integral 
along an appropriate path
of integration from t=0 to t=z in the complex plane)
</center>
<p>
Like the plain logarithm ln(z) and also like arctan(z), 
the dilog is a "multiply-branched" analytic function, and in formulas involving dilogs,
ln, and/or arctan you need to make sure to use the correct <b>branch.</b>  
Usually this is not very difficult,
but you cannot ignore it.
<br><br>
Specifically, 
&plusmn;z<sup>1/2</sup> are the two branches of the square-root function;
ln(z)+2&pi;ik for <i>any</i> integer k yield an infinite set of branches of the function ln(z);
while arctan(z)+&pi;k for any integer k yields an infinite set of branches of arctan(z).
Identities such as ln(a)+ln(b)=ln(ab) do <i>not</i> necessarily hold for general complex a,b 
<i>unless</i> we agree always magically to take the "correct branch," which might keep changing.
Similarly
Li<sub>2</sub>(z)+2&pi;ikln(z) 
for any integer k is an infinite number of branches of
Li<sub>2</sub>(z).
In many applications there is a clear notion of what the
"correct" branch is.  
Namely, for a formula which we know must depend smoothly on certain parameters,
consider a path along which those
parameters are distorted, starting from a known location, to reach the desired location, and with
every intermediate parameter-set being "legitimate."  This will
allow one and only one branch.
<br><br>
Dilogs, trilogs, etc obey a vast number of identities, far too many to discuss here, e.g. relating
Li<sub>n</sub>(1/z) to 
Li<sub>n</sub>(z).
There also are many series expansions for them.  In particular,
Li<sub>2</sub>([a+bz]/[c+dz])
and
Li<sub>2</sub>(e<sup>-kz</sup>) 
both have nice power-series expansions which can be got by expanding their derivatives
<center>
(d/dz) Li<sub>2</sub>(e<sup>-kz</sup>) = k&middot;ln(1-e<sup>-kz</sup>),
&nbsp;&nbsp;
(d/dz) Li<sub>2</sub>([a+bz]/[c+dz]) = ln( 1-[a+bz]/[c+dz] ) &middot; (ad-bc) / [(a+bz)(c+dz)]
</center>
in power series, then integrating.
</dd>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/FBCexecSumm.html">Favorite Betrayal</a>:</b></dt>
<dd>
The Favorite Betrayal Criterion: Voters should have no incentive to 
vote someone else over their favorite.  
Range, approval, and antiPlurality voting obey this criterion; but
Borda, IRV, and all Condorcet systems and nearly all weighted positional systems
fail it.
</d>
<dt><b>Gender convention:</b></dt>
<dd>
For linguistic convenience,
this paper regards <i>voters</i> as <i>female</i> and <i>candidates</i> as <i>male</i>.
</dd>
<dt><b>God:</b><a name="GodDefn"></a></td>
<dd>
In this paper the word "God" stands for whatever pre-election events shaped the voters' perceptions
of the relative winning chances of all the candidates; the voters then <i>use</i> these
perceptions to help
devise their "voting strategies."
</dd>
<dt><b>"Honest" versus "Strategic" Voting:</b></dt>
<dd>
If a voter ranks all candidates in best-to-worst (perceived utility) order, we shall
call that "honest" voting (in any rank-order-ballot-based voting method).
For ratings ballots, the practice of rating the best (greatest perceived utility)
candidate with the maximum
allowable rating
and the worst with the minimum, and the others linearly interpolated in between
according to their utilities, shall be called "honest" voting. 
Honest approval voting for us shall mean approving the candidates with above-average utility and
disapproving those with below-average utility (having exactly average utility will 
be a probability=0
event in the models considered in this paper, so we shall not need to worry about that).
Any method of generating votes that differs from honesty,
shall be called "strategic."  The present paper focuses on some particularly
simple and plausible (and comparatively good) kinds of strategy &ndash; which seem
to be best for voters confident that only two known so-called "frontrunner"
candidates have non-negligible winning chances &ndash; although in principle 
arbitrary strategies could be considered, including randomized ones.
</dd>
<a name="irv"></a>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/rangeVirv.html">IRV</a>=Instant Runoff Voting:</b></dt>
<dd>
Each "vote" is a rank ordering of all the <i>N</i> candidates.  
The election proceeds in <i>N-1</i> "rounds": each round, the candidate top-ranked by 
the fewest votes is eliminated (both from the election, and from all orderings inside votes).
After <i>N-1</i> rounds only one candidate remains, and is declared the winner.
(Some countries permit "truncated ballots" where only the first k candidates are ranked with
the remaining N-k regarded as co-equal last.  We shall not consider that.)
</dd>
<dt><b>Normal:</b></dt>
<dd>
A "standard normal" random deviate is a real x with probability density 
P(x)=(2&pi;)<sup>-1/2</sup>exp(-x<sup>2</sup>/2)
and has mean=0 and variance=1.
A 1-dimensional "normal" random deviate is ax+b where x is a standard normal 
deviate and a and b are real constants; it then has mean b and variance a<sup>2</sup>.
The sum (or difference) of two independent normal deviates,
with means m<sub>1</sub> and m<sub>2</sub>
and variances v<sub>1</sub> and v<sub>2</sub>,
is another, 
having mean m<sub>1</sub>&plusmn;m<sub>2</sub>
and variance v<sub>1</sub>+v<sub>2</sub>.
An N-dimensional normal deviate is an N-vector consisting of N constant nonzero
linear combinations
of N independent standard 1D normal deviates.
<p>
One method for <i>generating</I> standard random normal deviates [assuming
a subroutine Rand1() is available for generating random reals uniform in (-1,1)]
is the "Box-Muller polar method":
<pre>
  repeat{
    x &larr; Rand1();    y &larr; Rand1();
    w &larr; x<sup>2</sup> + y<sup>2</sup>;
  }until( 0&lt;w&lt;1 );
  w &larr; [-2ln(1-w)/w]<sup>1/2</sup>;   (My use of ln(1-w) not ln(w) improves quality in finite-precision arithmetic)
  x &larr; x&middot;w;
  y &larr; y&middot;w;    (Now x and y are two fresh independent normal deviates)
</pre>
However, for high-performance computing where vast quantities of random normals need to 
be generated, substantially faster methods exist.
<!--
If a,b,c,d are independent standard normals, then the following pseudocode fragment
will replace (x,y,z) with a uniformly randomly rotated version of itself
<pre>
     a2 &larr; a&middot;a;     b2 &larr; b&middot;b;     c2 &larr; c&middot;c;     d2 &larr; d&middot;d;
     rs &larr; 2/(a2+b2+c2+d2);
     ab &larr; a&middot;b;     ac &larr; a&middot;c;     ad &larr; a&middot;d;
     bc &larr; b&middot;c;     bd &larr; b&middot;d;     cd &larr; c&middot;d;
     x &larr; x - rs&middot;( x&middot;(c2+d2) - y&middot;(bc-ad) - z&middot;(ac+bd) );
     y &larr; y - rs&middot;( y&middot;(b2+d2) - x&middot;(bc+ad) - z&middot;(cd-ab) );
     z &larr; z - rs&middot;( z&middot;(b2+c2) - x&middot;(bd-ac) - y&middot;(cd+ab) );
</pre>
If x,y,z also are
independent standard normals, this will replace them with three new ones.
[Our mysterious 3D rotation formula arises from the theory of "quaternions," cf. Coxeter 1946.]
The new ones have the same sum of squares as x,y,z but are otherwise 
independent of them; and in particular each new variable has exactly zero correlation
with each old variable.
The transformation preserves exact normality of each of x,y, and z 
even if a,b,c,d are not normal; and if x,y,z are independent but not normal, then
the new x,y,z each will be "closer to normality."
I made a procedure which updates a set of 588 normals using
196 such transformations on disjoint triples, then
permutes the 588 according to the permutation of {0,1,2,&hellip;,586,&infin;}
<center>
x&larr;(x+r)<sup>-1</sup> mod 587
</center>
where r is generated randomly mod 587 using an auxiliary generator.
Finally,  about 10 among the 588 are replaced by normals
generated by Box-Muller from the auxiliary generator, and 501
are output.
</p><p>
The point is that each such cycle generates 501 pseudorandom normals
while calling Box-Muller only 10 times.  The net result is a generator about 5???
times faster than Box-Muller per random number output &ndash; but its statistical quality
seems at least as good
for the purposes in this paper.
</p><p>
We can build still-faster generators.  The idea is <i>usually</i> to use
still-cheaper normality-preserving transformations and only to resort to the more-expensive ones
occasionally (and the still-more expensive task of ab initio generation of a new normal,
is done still more rarely).   As an example of a "cheaper" transformation, two 
normals x,y can be multiplied by
one of these 16 random 2&times;2 matrices
<pre>
     &plusmn; [ &plusmn;c  +s ]       &plusmn; [ +s &plusmn;c ]
       [ -s  &plusmn;c ]  ,      [ &plusmn;c -s ]      where c=0.6 and s=0.4 
</pre>
and just which of the 16 is to be used, is determined
using an auxiliary generator.  By doing three cheap passes (basically
consisting of these 2&times;2 transforms on pairs followed by the 
permutation x&larr;8x mod 587) for every one
expensive pass, the generator is sped up by another factor of &asymp;2???
while apparently still having equally good statistical quality
for the relatively simple applications in this paper.
(No guarantees are offered about <i>other</i> applications.)
Using the cheapest methods all the time might not
yield output with good-enough statistical quality, which is why,
after we've cheaped as long as we dare,
we resort to a more expensive method.
-->
</dd>
<dt><b>Plurality Voting:</b></dt>
<dd>
Each voter names a candidate (as her vote).
The candidate named the most times is elected.
</dd>
<dt><b>Probability background:</b><a name="ProbBackgnd"></a></dt>
<dd>
For the "strong law of large numbers" see Feller section 10.7;
the "central limit theorem" is also heavily discussed by Feller;
for "Chernoff bounds" see, e.g.
Hagerup &amp; R&uuml;b.
</dd>
<dt><b>RNEM:</b></dt>
<dd>
Random Normal Elections/Utilities Model.  Defined in <a href="#Sec2">section 2</a>.
</dd>
<dt><b><a href="https://rangevoting.org/WarrenSmithPages/homepage/RangeVoting.html">Range Voting</a>:</b></dt>
<dd>
Voting system in which each voter provides a numerical score within a given
<i>range</i>, which in the present paper will be the real interval <nobr>[-1, +1]</nobr>,
to each candidate and the candidate with the greatest score-sum wins.  
(Any linear transformation of the range and all scores yields an equivalent voting system,
but we find <nobr>[-1, +1]</nobr> most convenient for our mathematical analysis purposes.)
A range ballot will be called "<i>normalized</i>" if that voter rated some choice
(presumably her favorite) maximum, i.e. +1, and another (presumably her most-hated) minimum, i.e. -1. 
</dd>
<dt><b><a name="rankrate"></a>
Ranking versus Rating systems:</b></dt>
<dd>
In a "rank ballot" voting system such as Borda, each vote is a rank-ordering of the candidates
from best to worse, such as "Gandhi>Churchill>Hitler."  
In "pure" or "strict" rank-ballot systems, no rank equalities are permitted.
However, one could also consider voting systems in which each vote is a rank-ordering with
equalities (optionally) permitted, e.g. "Coolidge=Gore>Bush=Harding."
That issue is irrelevant if we only consider honest voters (since equalities then are a 
probability=0 event) but can matter a lot for strategic ones.
In a "rating" based voting system such as range voting,
each vote awards a score selected (with replacement) 
from some fixed set to each candidate, e.g.
"Gandhi=1, Churchill=0.2, Hitler=-1."
Rating based systems can allow expressing not just preferences, but also preference
<i>strengths</i>.
For the form of range voting  used
in this paper, the "fixed set" is the real interval [-1, 1];
in "approval voting," it is the 2-element set {-1, +1}.
</dd>
<dt><b>"Trilogarithm" and higher polylogarithms:</b></dt>
<dd>
Similarly to the dilogarithm Li<sub>2</sub>(z) we may for n=3,4,5,... define
</p>
<center>
Li<sub>n</sub>(z) 
&nbsp;
= 
&nbsp;
&sum;<sub>k&ge;1</sub> k<sup>-n</sup>z<sup>k</sup>
=
-&int; Li<sub>n-1</sub>(s) ds/s
, 
<br>
(series converges when |z|&lt;1;
defined elsewhere by analytic continuation accomplished <br>
via the integral 
along an appropriate path
of integration from s=0 to s=z in the complex plane)
</center>
<p>
We can even define 
Li<sub>0</sub>(z)=z/(1-z) and
Li<sub>1</sub>(z)=-ln(1-z) and start from them instead of
Li<sub>2</sub>(z).
Adding 2&pi;ik(lnz)<sup>n-1</sup>/(n-1)!, where k is any integer, yields a different branch of 
Li<sub>n</sub>(z).
The "trilogarithm" is Li<sub>3</sub>(z).  
Three other integral representations are
<center>
n! Li<sub>n</sub>(e<sup>-z</sup>) = &int;<sub>0&lt;t&lt;&infin;</sub> t<sup>n-1</sup> dt / [exp(t+z)-1],
</center>
<center>
-n! Li<sub>n</sub>(-e<sup>-z</sup>) = &int;<sub>0&lt;t&lt;&infin;</sub> t<sup>n-1</sup> dt / [exp(t+z)+1],
</center>
<center>
(n-1)! Li<sub>n</sub>(z) = (-1)<sup>n</sup> &int;<sub>0&lt;t&lt;1</sub> (ln<i>t</i>)<sup>n-1</sup>/(t - 1/z) d<i>t</i>.
</center>
<p>
One can use
</p>
<center>
(d/dz) Li<sub>n</sub>(e<sup>-kz</sup>) = -k&middot;Li<sub>n-1</sub>(e<sup>-kz</sup>),
&nbsp;&nbsp;
(d/dz) Li<sub>n</sub>([a+bz]/[c+dz]) = Li<sub>n-1</sub>([a+bz]/[c+dz]) &middot; (bc-ad) / [(a+bz)(c+dz)]
</center>
<p>
to obtain power series expansions of the lefthand quantities.
In nonEuclidean volume computations (appendix C) many of the polylogarithms that arise have
arguments lying on the unit circle in the complex plane, Li<sub>n</sub>(e<sup>i&theta;</sup>).
</dd>
<dt><b><a name="votingsystem"></a>
Voting system:</b></dt>
<dd>
A function mapping a set of V votes (each concerning N candidates) to the <i>winner</i>
(who is one of the N candidates).
Optionally, one could also (although we shall not)
allow the output to be more than merely the name of the winner, e.g. a 
societal rank-ordering
or rating for each candidate.
Voting systems could also output <i>tied winner sets</i> in which case the ties would
be broken by, e.g, a coin toss.  For the purposes in this paper
ties are irrelevant because 
we are considering probabilistic scenarios with V&rarr;&infin; in which ties
are neglectibly unlikely.   However, if and when we do consider finite V, and hence
nonzero tie-probability, we agree to break ties randomly in such a way
that every tied-winner's
selection chance is equal.
</dd>
<dt><b><a name="WeightedPos"></a>
<a href="https://rangevoting.org/WarrenSmithPages/homepage/WtPositnl.html">Weighted positional system:</a></b></dt>
<dd>
Voting system where a vote is a rank-ordering of all the <i>N</i> candidates. 
The <i>k</i>th-ranked candidate gets score <i>W<sub>k</sub></i> for some fixed
set of "weights" W<sub>1</sub>&ge;W<sub>2</sub>&ge;W<sub>3</sub>&ge;...&ge;W<sub>N</sub>.
The candidate with
the greatest score-sum is elected.  
(For example, Borda arises as the weighted positional system
with W<sub>k</sub>=N-k, while plain plurality voting is 
weighted positional with 
W<sub>1</sub>=1 and W<sub>k</sub>=0 for 2&le;k&le;N.)
For mathematical-analysis purposes it is convenient to consider <i>standardized weights</i>
with 
<center>
<nobr>&sum;<sub>1&le;k&le;N</sub> W<sub>k</sub> = 0</nobr>
&nbsp;&nbsp;&nbsp; and &nbsp;&nbsp;&nbsp;
<nobr>(1/N)&sum;<sub>1&le;k&le;N</sub> (W<sub>k</sub>)<sup>2</sup> = 1.</nobr>
</center>
</dd>
<dt><b>"Wrong winner:"</b></dt>
<dd>
An election-winner who
is not the candidate with maximum summed (over the voters) utility.
</dd>
</dl>

<blockquote>
<b>References for appendix D:</b>
<br>
Lars V. Ahlfors: Complex analysis, McGraw-Hill (3rd ed, 1979).
<br>
Kenneth J. Arrow:
A Difficulty in the Concept of Social Welfare,
Journal of Political Economy 58, 4 (August 1950) 328-346.
<br>
Steven J. Brams &amp; Peter C.  Fishburn: Approval Voting, Birkhauser, Boston 1983.
<br>
J.M. Colomer &amp; Iain McLean: Electing popes, approval balloting and qualified-majority rule, 
J.Interdisciplinary History 29,1 (1998) 1-22; 
reprinted in Politics and Political Change (MIT Press 2001, R.I.Rotberg ed.) 47-68.
<br>
<!--
H.S.M.Coxeter:
Quaternions and reflections,
Amer. Mathl. Monthly 53,3 (1946) 136-146.
<br>
-->
William Feller:
An Introduction to Probability Theory and Its Applications, Wiley, 2 vols, 1968;
3rd ed. 1971.
<!-- Strong law of large numbers in sec 10.7. -->
<br>
P.C.Fishburn: 
Arrow's Impossibility Theorem: Concise Proof and Infinite Voters,
J. Economic Theory 2,1 (March 1970) 103-106. 
<br>
Gene H. Golub &amp; Charles F. Van Loan:
Matrix computations (3rd ed.), Johns Hopkins University Press. 
<br>
Branko Gr&uuml;nbaum:
Convex Polytopes,
1967 and as of 2003 a second edition
extended by Volker Kaibel, Victor Klee, and G&uuml;nter M. Ziegler
is available from Springer.
<br>
Torben Hagerup &amp; Christine R&uuml;b:
A guided tour of Chernoff bounds,
Information Processing Letters 33,6 (February 1990) 305-308.
<br>
Leonard Lewin: Polylogarithms and associated functions,
North-Holland, Amsterdam, 1981.
<br>
Hannu J. Nurmi: Comparing Voting Systems, Kluwer 1987.
<br>
T.N.Tideman: Independence of clones as a criterion for voting rules,
Social Choice and Welfare 4 (1987) 185-206.
<br>
</blockquote>

<!-- TO DO:
2 add computer sims psucode, numbers, and graphs
3 rewrite?
4 add bibliography
5 subscript Ws
regrets from computer:
6 do range vs best honest rank order 4cand, 5cand, etc systems
7 do range vs weighted range
8 do limit range, approval, borda
9 do approval v borda with variable honesty fraction
10 DO G table including table of sum of sqs
-->

<!--
???Puzzles:
asymp behavior of Q(N).
The normal sample std dev N-1 thing.

Brams: I would carefully justify your measures (BR), probabilistic model (RNEM)--which 
Regenwetter et al., Behavioral Social Choice (Cambridge, 2006), among others, question
-->
<hr>
<br>
<p><a href="https://rangevoting.org/WarrenSmithPages/homepage/RangeVoting.html">Return to main page</a></p>
<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
var sc_project=1613646; 
var sc_invisible=1; 
var sc_partition=15; 
var sc_security="a35ff8fb"; 
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a href="http://www.statcounter.com/" target="_blank"><img  src="http://c16.statcounter.com/counter.php?sc_project=1613646&amp;java=0&amp;security=a35ff8fb&amp;invisible=1" alt="php hit counter" border="0"></a> </noscript>
<!-- End of StatCounter Code to be inserted immediately before the /body command near end of your page -->
</body>
</html>


