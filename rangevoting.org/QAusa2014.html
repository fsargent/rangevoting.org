<html>
<head>
<link rel="stylesheet" href="/assets/css/original-layout.css">

<title>
RangeVoting.org -  Questions &amp; Answers about study "2014 USA elections manipulated"
</title>
</head>
<body style="font-family: Arial, sans-serif">

<H2> Questions &amp; Answers about my <a href="USA2014.html">study</a>
 indicating 2014 USA elections manipulated </H2>

<p><small>
All these questions are based on actual questions/comments I received,
albeit edited.
</small></p>

<p><b>Q.</b> You started with the premise that
the polls were correct. I disagree with your initial premise, so the rest is garbage.
</p><p>
<b>A.</b> Wrong &ndash; that premise not needed:
The "nonparametric" tests still are valid even if all polls complete
random junk.  (Which is quite
a nice trick; you might naively have not thought this possible.)
In fact, the questioner reveals a fundamental lack of understanding of our nonparametric methods.
He <i>thinks</i> this is a matter of
a <i>conflict</i> between two sides &ndash; the polls and the official election results,
and so if he sides with one side, the other is wrong.
But actually, these tests reveal (with high confidence)
the official results must be manipulated <i>even if the polls are
regarded as completely random junk.</i>
</p><p>
A premise like the one the questioner has in mind
<i>is</i>  however, needed for the tests that assume normal-distributed errors.
So a reader with this view could ignore <i>that</i> part of the paper. 
(We do, however, protect outselves by using a highly pessimistic &sigma;-estimate
before computing normal probabilities.  All that part of the paper really assumes, 
then, is that the normal tail probabilities
computed using this &sigma;-overestimator, are an upper bound on the true tail probabilities.)
But anyway, I do not recommend the view that polls are "complete random junk."  
E.g, they were extremely
successful in the immediately preceding (2012 and 2008) USA elections.
For example, media statistician Nate Silver in 2008 by aggregating publicly available poll data
correctly predicted the presidential contest result in 49 out of 
the 50 US states, plus got all 35 senator predictions right. 
In the 2012 contest he correctly predicted
the presidential contest (Obama v. Romney) in all 50 states plus Distict of Columbia &ndash; 
a feat also accomplished
by Sam Wang at <tt>election.princeton.edu</tt>.
This was not because the polls were complete random garbage.
</p>
<p><b>Q.</b>
You're a crazy conspiracy theorist, right?  Or you've got some nasty biases?
</p><p>
<b>A.</b>
I've got a PhD in Applied Math (Princeton 1988) and have quite a lot of expertise &amp;
many years experience with election forensics, voting methods, etc.
Main author of this web site, one of the best, if not the best, in the 
world on voting methods at this time (2014).
That is not to say you necessarily should trust me.  
I'm open to possible corrections, etc. &ndash; please email them to me.
However, let me make a few points:
</p><ol><li>
Was my data set biased or "cherrypicked"? No.  All the discrepancy figures 
between poll averages and subsequent official election results were taken directly,
without alteration, from RealClearPolitics.com using polls compiled by them, 
using their choices, of polls from a wide variety of pollsters funded by a
wide variety of sources.  So any such "bias" is their fault not mine.
</li><li>
Similarly the selection of which races were "close" was chosen not by me, but by
<i>Cook Political Report</i> well before the election.   Any bias is due to them,
not me, and they'd have had to predict I was going to use their data for this purpose
to bias it in their evil way, also predicting what funny stuff would happen in the elections to 
work in conjunction with my analysis to make evil conclusions happen.
Sorry, just didn't happen. Cook has a good record.  Here's some bragging
they just put on their web page:
<blockquote>
 In a new academic paper, Dr. James E. Campbell, Chairman of the Political Science Department at the State University of New York/Buffalo has analyzed The Cook Political Report's pre-Labor Day House ratings going back to the Report's founding in 1984. In 11 of the 13 elections in which the Cook Political Report published new ratings between July 1 and then end of August (all except 1986 and 1990), 99.8 percent of the 3,387 races rated by the Cook Political Report as Solid Republican or Solid Democratic in July or August of an election year went by way of that party, 94.9 percent of the 641 races rated as Likely Democratic or Likely Republican fell the way the Cook Political Report predicted, and 85.7 percent of the 441 races rated Lean Democratic or Lean Republican broke in favor of the leaning party. Of the 130 Democratic-held seats rated as Toss Up, 49.2 percent went for Democrats, and 55.0 percent of the 160 Republican held seats rated as Toss Up were won by the GOP.
</blockquote>
</li><li>
Similarly the selection of which states 
had poor post-election audit procedures was made, not by me, but
by VerifiedVoting.org, 5 years prior.
They'd have had to predict 5 years in future I'd use their data, then cleverly bias it to
make me draw evil conclusions, also predicting the elections, and the polls, too.
OK?  If you believe that crap, it is you who are the nutty conspiracy theorist, not me.
</li></ol>
<p>
And statistical significance figures speak louder than words (or should).
If I computed 99.91% statistical significance for some conclusion,
then if I calculated it right, you'd better worry.  Doesn't matter how evil and nasty I am.
That's irrelevant.  99.91% is a pretty solid conclusion.  Period.   
You'd better concentrate on the facts, not on generating aspersions about me.
</p><p>
If on the other hand, my calculations were wrong, then find the errors, 
notify me, and we can try to correct them. 
I will publish retractions here if any serious errors are found. 
I'll probably also do something constructive even about non-serious errors.
I also would expect/hopes others to confirm my analyses
hopefully also using different methods, in the fullness of time.
Or to deny them and publish refutations.   
(I warn you in the past I've gotten a lot of bullshit "refutations" of political analyses
I've done, generally provided by highly pre-biased and incompetent people, so watch out.)
</p>
<p><b>Q.</b> Is the USA now a "banana republic"?
</p><p>
<b>A.</b> Some of those whining about this study see
it (apparently) as a matter of patriotism to claim the
USA has the best elections in the world, or something.
Actually, the USA is quite bad in many respects, 
such as gerrymandering among the worst, if not the worst, in the world;
and Secretaries of
State in charge of elections who are <i>intentionally</i> chosen to be the most partisan/biased
person in the entire state, and who (it is now clear, in case it wasn't already) use
their positions to bias elections.  Other countries consider these things ludicrous.
True patriotism is to "recognize the problems, point them out, and try to fix them,"
not "try to cover it up."
But anyhow, for this class of whiners, I would suggest the following. 
Pick your favorite pundit who complains about election fraud and/or
appearance thereof in other (non-USA)
countries. (Or perhaps you <i>are</i> that pundit.)  Compare the level of evidence they've got
for alleged frauds they publicly complained about in other country,
versus the level of evidence for manipulation in the present case.   
It depends, but in at least some cases (Iran 2009 comes to mind), I think you'll find 
there's more-solid evidence against USA 2014.  If so, USA 2014 accusations
deserve at least as much press,
etc, as Iran 2009 accusations got.
</p>
<p><b>Q.</b>
So did the Republicans not deserve their official
US senate majority of (presumably) 54 seats?
</p><p>
<b>A.</b>
My analysis does not tell us the Republicans should not have got 54 seats, 
nor how many they should have got.   Indeed, possibly
they even deserved every seat they got, I have no idea right now
(8 Nov. 2014).  I am claiming the elections were manipulated, and in their favor.
I am not necessarily claiming this manipulation caused a large (or any) 
change in the #seats; that simply is not a question I looked at.  
I do not know how many seats were undeserved.  Also, that is a considerably 
harder question to answer.  My analysis takes advantage of data 
from <i>many</i> states to get significance.  If we only were considering
1 state (e.g: did Roberts really 
deserve to win in Kansas?) then I cannot take advantage of that.
</p>
<p><b>Q.</b> As you pointed out at the end of your <a href="USA2014.html">study</a>,
celebrity statistician Nate Silver seems to agree with you.  And disagree with you.
</p><p>
<b>A.</b> That indeed was kind of strange. 
</p>
<p><b>Q.</b> Silver seems to 
<a href="http://fivethirtyeight.com/features/the-polls-were-skewed-toward-democrats/">think</a>
"pollster herding" is the most likely explanation of concerted
skews by many polls in the same direction.  
Not election manipulation.  (Indeed he does
not even <i>mention</i> even the <i>possibility</i> it was election
manipulation for even 1 sentence.)
</p><p>
<b>A.</b> 
The problem with the "pollster herding" hypothesis is, 
reputable pollsters usually actually describe their methodology.  (Not completely, but
in broad strokes.)  In those descriptions, they never include "and
then we cooked the books to make it agree with a different poll."
In fact, I've never seen any even mention examining anybody's other
contemporaneous poll and using it in any way.
Tell me, O questioner: did Silver actually produce 
evidence for "pollster herding"? Or was this "most likely explanation" 
just a wild guess by him with no evidentiary support?  
Here's my explanation 
(which actually does have a ton of evidentiary support) &ndash; polls tend to 
agree with each other because the underlying data agrees with each other.
Kind of a stunningly simple boring and obvious hypothesis, but I'm going with it.  And
when polls do not agree with each other, that is a symptom of something being wrong.
</p>
<p><b>Q.</b> Unfortunately manipulation, e.g. requiring voter IDs,
strategically reducing voting hours, placing fewer 
polling places &amp; voting machines in some areas, 
placing "error detecting helpful 'please try again'" voting machines
in some areas while turning off said warnings on the machines in other areas,
suddenly changing polling places, making "accidental clerical mistakes," 
conducting intentionally biased "voter purges" from registration lists,
... often is not illegal.
</p><p>
<b>A.</b> Yes.  And it in many legal and illegal forms unfortunately
has been <a href="FraudHist.html">common</a>
through US and world history.
 But a lesson of this study, is it <i>should</i> be illegal.
We need uniform procedures, and elections supervised by nonpartisan independent agency,
and districts drawn in <a href="SplitLR.html">unbiased</a> ways... cf. Canada.
</p>

<br>
<p><a href="RangeVoting.html">Return to main page</a></p>
<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
var sc_project=1613646; 
var sc_invisible=1; 
var sc_partition=15; 
var sc_security="a35ff8fb"; 
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a href="http://www.statcounter.com/" target="_blank"><img  src="http://c16.statcounter.com/counter.php?sc_project=1613646&amp;java=0&amp;security=a35ff8fb&amp;invisible=1" alt="php hit counter" border="0"></a> </noscript>
<!-- End of StatCounter Code to be inserted immediately before the /body command near end of your page -->
</body>
</html>
